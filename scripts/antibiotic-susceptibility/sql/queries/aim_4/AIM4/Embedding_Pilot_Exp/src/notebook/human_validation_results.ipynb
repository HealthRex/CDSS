{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_label = pd.read_csv('../data/LLM Labels.csv').head(200)\n",
    "LLM_label = pd.read_csv('/Users/wenyuanchen/Library/CloudStorage/Box-Box/Data/Labled_Data_to_Validate/LLM Labels(Sheet1).csv').head(143)\n",
    "Physician_label = pd.read_csv('/Users/wenyuanchen/Library/CloudStorage/Box-Box/Data/Labled_Data_to_Validate/Stephen Labels(Sheet1).csv')\n",
    "Physician_label_human = Physician_label[Physician_label[\"Source\"] == \"Human\"]\n",
    "Physician_label_human = Physician_label_human[Physician_label_human[\"Index\"].isin(LLM_label[\"Index\"])]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lables = pd.concat([LLM_label, Physician_label_human], ignore_index=True).sort_values(by=\"Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_lables[\"Index\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def ensure_sources(df, index_col='Index', source_col='Source'):\n",
    "    # Set of unique indices\n",
    "    indices = df[index_col].unique()\n",
    "    # For each index, ensure all \"Human\" ,\"Baseline\" and \"Enhanced\" exist\n",
    "    needed_rows = []\n",
    "    for idx in indices:\n",
    "        current_sources = set(df.loc[df[index_col]==idx, source_col])\n",
    "        # If \"Human\" is missing, add row\n",
    "        if \"Human\" not in current_sources:\n",
    "            new_row = {col: np.nan for col in df.columns}\n",
    "            new_row[index_col] = idx\n",
    "            new_row[source_col] = \"Human\"\n",
    "            needed_rows.append(new_row)\n",
    "        # If \"Baseline\" is missing, add row (if you want to ensure Baseline too)\n",
    "        if \"Baseline\" not in current_sources:\n",
    "            new_row = {col: np.nan for col in df.columns}\n",
    "            new_row[index_col] = idx\n",
    "            new_row[source_col] = \"Baseline\"\n",
    "            needed_rows.append(new_row)\n",
    "        if \"Enhanced\" not in current_sources:\n",
    "            new_row = {col: np.nan for col in df.columns}\n",
    "            new_row[index_col] = idx\n",
    "            new_row[source_col] = \"Enhanced\"\n",
    "            needed_rows.append(new_row)\n",
    "    # Append needed rows, if any\n",
    "    if needed_rows:\n",
    "        df = pd.concat([df, pd.DataFrame(needed_rows)], ignore_index=True)\n",
    "    df = df[df[\"Source\"].isin([\"Human\", \"Baseline\", \"Enhanced\"])]\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lables_ensured = ensure_sources(full_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_baseline = full_lables_ensured[(full_lables_ensured[\"Source\"] == \"Human\") | (full_lables_ensured[\"Source\"] == \"Baseline\")]\n",
    "human_enhanced = full_lables_ensured[(full_lables_ensured[\"Source\"] == \"Human\") | (full_lables_ensured[\"Source\"] == \"Enhanced\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Source</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Subdomain</th>\n",
       "      <th>Error Code</th>\n",
       "      <th>Rationale</th>\n",
       "      <th>Free Text Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2432</td>\n",
       "      <td>Human</td>\n",
       "      <td>Clinical Reasoning</td>\n",
       "      <td>Workflow Recommendations</td>\n",
       "      <td>Violation of Standard Workflows</td>\n",
       "      <td>Clinic appears to schedule directly via messag...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5598</td>\n",
       "      <td>Enhanced</td>\n",
       "      <td>Clinical Reasoning</td>\n",
       "      <td>Comprehension of Patient Query</td>\n",
       "      <td>Off-topic or Irrelevant Reply to Patient Query</td>\n",
       "      <td>The response gives unrelated information about...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11928</td>\n",
       "      <td>Enhanced</td>\n",
       "      <td>Communication Quality &amp; Readability</td>\n",
       "      <td>Clarity</td>\n",
       "      <td>Ambiguous or Conflicting Instructions</td>\n",
       "      <td>The instructions are contradictory since they ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11928</td>\n",
       "      <td>Enhanced</td>\n",
       "      <td>Clinical Reasoning</td>\n",
       "      <td>Clinical Recommendations</td>\n",
       "      <td>Inappropriate or Omitted Diagnostic Test Recom...</td>\n",
       "      <td>The reply incorrectly advises a new blood draw...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11928</td>\n",
       "      <td>Human</td>\n",
       "      <td>Clinical Reasoning</td>\n",
       "      <td>Comprehension of Patient Context</td>\n",
       "      <td>Incorrect Clinical Information</td>\n",
       "      <td>LLM did not realize that the CBC had already b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>119042</td>\n",
       "      <td>Human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>120351</td>\n",
       "      <td>Human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>120351</td>\n",
       "      <td>Enhanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>124222</td>\n",
       "      <td>Human</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>124222</td>\n",
       "      <td>Enhanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index    Source                               Domain  \\\n",
       "1      2432     Human                   Clinical Reasoning   \n",
       "3      5598  Enhanced                   Clinical Reasoning   \n",
       "5     11928  Enhanced  Communication Quality & Readability   \n",
       "6     11928  Enhanced                   Clinical Reasoning   \n",
       "7     11928     Human                   Clinical Reasoning   \n",
       "..      ...       ...                                  ...   \n",
       "253  119042     Human                                  NaN   \n",
       "254  120351     Human                                  NaN   \n",
       "255  120351  Enhanced                                  NaN   \n",
       "256  124222     Human                                  NaN   \n",
       "258  124222  Enhanced                                  NaN   \n",
       "\n",
       "                            Subdomain  \\\n",
       "1            Workflow Recommendations   \n",
       "3      Comprehension of Patient Query   \n",
       "5                             Clarity   \n",
       "6            Clinical Recommendations   \n",
       "7    Comprehension of Patient Context   \n",
       "..                                ...   \n",
       "253                               NaN   \n",
       "254                               NaN   \n",
       "255                               NaN   \n",
       "256                               NaN   \n",
       "258                               NaN   \n",
       "\n",
       "                                            Error Code  \\\n",
       "1                      Violation of Standard Workflows   \n",
       "3       Off-topic or Irrelevant Reply to Patient Query   \n",
       "5                Ambiguous or Conflicting Instructions   \n",
       "6    Inappropriate or Omitted Diagnostic Test Recom...   \n",
       "7                       Incorrect Clinical Information   \n",
       "..                                                 ...   \n",
       "253                                                NaN   \n",
       "254                                                NaN   \n",
       "255                                                NaN   \n",
       "256                                                NaN   \n",
       "258                                                NaN   \n",
       "\n",
       "                                             Rationale Free Text Comments  \n",
       "1    Clinic appears to schedule directly via messag...                NaN  \n",
       "3    The response gives unrelated information about...                NaN  \n",
       "5    The instructions are contradictory since they ...                NaN  \n",
       "6    The reply incorrectly advises a new blood draw...                NaN  \n",
       "7    LLM did not realize that the CBC had already b...                NaN  \n",
       "..                                                 ...                ...  \n",
       "253                                                NaN                NaN  \n",
       "254                                                NaN                NaN  \n",
       "255                                                NaN                NaN  \n",
       "256                                                NaN                NaN  \n",
       "258                                                NaN                NaN  \n",
       "\n",
       "[140 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_stats(df):\n",
    "    sources = [\"Human\", \"Baseline\", \"Enhanced\"]\n",
    "    stats = {}\n",
    "    total_cases = len(df[\"Index\"].unique())\n",
    "    print(\"===== Basic Statistics =====\\n\")\n",
    "    print(f\"Total cases (unique indices): {total_cases}\\n\")\n",
    "    for source in sources:\n",
    "        source_rows = df[df[\"Source\"] == source]\n",
    "        # Error cases: at least one non-null domain per index\n",
    "        error_cases = source_rows.groupby(\"Index\")[\"Domain\"].apply(lambda x: x.notnull().any())\n",
    "        n_error_cases = error_cases.sum()\n",
    "        error_rate = n_error_cases / total_cases\n",
    "        print(f\"{source}:\")\n",
    "        print(f\"  Cases flagged as error: {n_error_cases} ({error_rate:.1%})\")\n",
    "        # Error type breakdowns (total counts, not index-level)\n",
    "        domain_counts = source_rows[\"Domain\"].value_counts(dropna=True)\n",
    "        subdomain_counts = source_rows[\"Subdomain\"].value_counts(dropna=True)\n",
    "        errorcode_counts = source_rows[\"Error Code\"].value_counts(dropna=True)\n",
    "        print(f\"  Error Domain breakdown:\")\n",
    "        for k, v in domain_counts.items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "        print(f\"  Error Subdomain breakdown:\")\n",
    "        for k, v in subdomain_counts.items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "        print(f\"  Error Code breakdown:\")\n",
    "        for k, v in errorcode_counts.items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "        print(\"\")\n",
    "        stats[source] = {\n",
    "            \"n_error_cases\": n_error_cases,\n",
    "            \"error_rate\": error_rate,\n",
    "            \"domain_counts\": domain_counts.to_dict(),\n",
    "            \"subdomain_counts\": subdomain_counts.to_dict(),\n",
    "            \"errorcode_counts\": errorcode_counts.to_dict()\n",
    "        }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concordance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_analysis(\n",
    "    df, source, breakdown=False, index_level_breakdown=False, error_level_concordance=False\n",
    "):\n",
    "    from collections import Counter, defaultdict\n",
    "\n",
    "    cols = [\"Index\", \"Source\", \"Domain\", \"Subdomain\", \"Error Code\"]\n",
    "    df = df[cols]\n",
    "    indices = df[\"Index\"].unique()\n",
    "    n_total = len(indices)\n",
    "    n_nan_domain, n_domain, n_subdomain, n_error = 0, 0, 0, 0\n",
    "\n",
    "    # Breakdown counters\n",
    "    domain_concord = Counter()\n",
    "    subdomain_concord = Counter()\n",
    "    errorcode_concord = Counter()\n",
    "    # Index-level concordance\n",
    "    index_domain_concord = defaultdict(set)\n",
    "    index_subdomain_concord = defaultdict(set)\n",
    "    index_errorcode_concord = defaultdict(set)\n",
    "    # Error-level concordance\n",
    "    error_level_count = 0\n",
    "\n",
    "    for idx in indices:\n",
    "        temp = df[df[\"Index\"] == idx]\n",
    "        human_rows = temp[temp[\"Source\"] == \"Human\"]\n",
    "        baseline_rows = temp[temp[\"Source\"] == source]\n",
    "        \n",
    "        found_nan = found_error = found_subdomain = found_domain = False\n",
    "\n",
    "        for _, hr in human_rows.iterrows():\n",
    "            for _, br in baseline_rows.iterrows():\n",
    "                # NaN Domain\n",
    "                if pd.isna(hr[\"Domain\"]) and pd.isna(br[\"Domain\"]):\n",
    "                    found_nan = True\n",
    "                # Error Code\n",
    "                if pd.notna(hr[\"Error Code\"]) and hr[\"Error Code\"] == br[\"Error Code\"]:\n",
    "                    found_error = True\n",
    "                    if breakdown:\n",
    "                        errorcode_concord[hr[\"Error Code\"]] += 1\n",
    "                    if index_level_breakdown:\n",
    "                        index_errorcode_concord[hr[\"Error Code\"]].add(idx)\n",
    "                # Subdomain\n",
    "                if pd.notna(hr[\"Subdomain\"]) and hr[\"Subdomain\"] == br[\"Subdomain\"]:\n",
    "                    found_subdomain = True\n",
    "                    if breakdown:\n",
    "                        subdomain_concord[hr[\"Subdomain\"]] += 1\n",
    "                    if index_level_breakdown:\n",
    "                        index_subdomain_concord[hr[\"Subdomain\"]].add(idx)\n",
    "                # Domain\n",
    "                if pd.notna(hr[\"Domain\"]) and hr[\"Domain\"] == br[\"Domain\"]:\n",
    "                    found_domain = True\n",
    "                    if breakdown:\n",
    "                        domain_concord[hr[\"Domain\"]] += 1\n",
    "                    if index_level_breakdown:\n",
    "                        index_domain_concord[hr[\"Domain\"]].add(idx)\n",
    "                # --- Error-level concordance: all three match and non-null ---\n",
    "                if (\n",
    "                    pd.notna(hr[\"Domain\"]) and pd.notna(br[\"Domain\"])\n",
    "                    and hr[\"Domain\"] == br[\"Domain\"]\n",
    "                    and pd.notna(hr[\"Subdomain\"]) and pd.notna(br[\"Subdomain\"])\n",
    "                    and hr[\"Subdomain\"] == br[\"Subdomain\"]\n",
    "                    and pd.notna(hr[\"Error Code\"]) and pd.notna(br[\"Error Code\"])\n",
    "                    and hr[\"Error Code\"] == br[\"Error Code\"]\n",
    "                ):\n",
    "                    error_level_count += 1\n",
    "\n",
    "        if found_nan: n_nan_domain += 1\n",
    "        if found_error: n_error += 1\n",
    "        if found_subdomain: n_subdomain += 1\n",
    "        if found_domain: n_domain += 1\n",
    "\n",
    "    print(f\"Total indices: {n_total}\")\n",
    "    print(f\"Concordant (NaN Domain): {n_nan_domain}\")\n",
    "    print(f\"Concordant (Domain): {n_domain}\")\n",
    "    print(f\"Concordant (Subdomain): {n_subdomain}\")\n",
    "    print(f\"Concordant (Error Code): {n_error}\")\n",
    "\n",
    "    results = {\n",
    "        \"total\": n_total,\n",
    "        \"nan_domain\": n_nan_domain,\n",
    "        \"domain\": n_domain,\n",
    "        \"subdomain\": n_subdomain,\n",
    "        \"error_code\": n_error\n",
    "    }\n",
    "    if index_level_breakdown:\n",
    "        print(\"\\nBreakdown by Domain (unique indices):\")\n",
    "        for k, v in index_domain_concord.items():\n",
    "            print(f\"  {k}: {len(v)}\")\n",
    "        print(\"\\nBreakdown by Subdomain (unique indices):\")\n",
    "        for k, v in index_subdomain_concord.items():\n",
    "            print(f\"  {k}: {len(v)}\")\n",
    "        print(\"\\nBreakdown by Error Code (unique indices):\")\n",
    "        for k, v in index_errorcode_concord.items():\n",
    "            print(f\"  {k}: {len(v)}\")\n",
    "        results[\"domain_index_breakdown\"] = {k: len(v) for k, v in index_domain_concord.items()}\n",
    "        results[\"subdomain_index_breakdown\"] = {k: len(v) for k, v in index_subdomain_concord.items()}\n",
    "        results[\"error_code_index_breakdown\"] = {k: len(v) for k, v in index_errorcode_concord.items()}\n",
    "\n",
    "    if breakdown:\n",
    "        print(\"\\nBreakdown by Domain (pairwise matches):\")\n",
    "        for k, v in domain_concord.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "        print(\"\\nBreakdown by Subdomain (pairwise matches):\")\n",
    "        for k, v in subdomain_concord.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "        print(\"\\nBreakdown by Error Code (pairwise matches):\")\n",
    "        for k, v in errorcode_concord.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "        results[\"domain_breakdown\"] = dict(domain_concord)\n",
    "        results[\"subdomain_breakdown\"] = dict(subdomain_concord)\n",
    "        results[\"error_code_breakdown\"] = dict(errorcode_concord)\n",
    "    \n",
    "\n",
    "    if error_level_concordance:\n",
    "        print(f\"\\nConcordant at full error level (all three match): {error_level_count}\")\n",
    "        results[\"error_level_count\"] = error_level_count\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# results = concordance_analysis(df, source=\"Baseline\", breakdown=True, index_level_breakdown=True, error_level_concordance=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(30), np.int64(30), np.int64(33))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_human = full_lables_ensured[full_lables_ensured[\"Source\"] == \"Human\"]\n",
    "only_baseline = full_lables_ensured[full_lables_ensured[\"Source\"] == \"Baseline\"]\n",
    "only_enhanced = full_lables_ensured[full_lables_ensured[\"Source\"] == \"Enhanced\"]\n",
    "only_human[\"Domain\"].isnull().sum(), only_baseline[\"Domain\"].isnull().sum(), only_enhanced[\"Domain\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(30), np.int64(30), np.int64(33))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_human[\"Domain\"].isnull().sum(), only_baseline[\"Domain\"].isnull().sum(), only_enhanced[\"Domain\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Human-labeled as No Error, Baseline/Enhanced labeled as Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_noerror_model_error(df, model_source=\"Baseline\"):\n",
    "    cases = []\n",
    "    for idx in df[\"Index\"].unique():\n",
    "        human_rows = df[(df[\"Index\"] == idx) & (df[\"Source\"] == \"Human\")]\n",
    "        model_rows = df[(df[\"Index\"] == idx) & (df[\"Source\"] == model_source)]\n",
    "        # Human no error: All human rows have Domain==NaN\n",
    "        if human_rows[\"Domain\"].isnull().all():\n",
    "            # Model has at least one error\n",
    "            if model_rows[\"Domain\"].notnull().any():\n",
    "                cases.append(idx)\n",
    "    return cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model-labeled as No Error, Human labeled as Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_noerror_human_error(df, model_source=\"Baseline\"):\n",
    "    cases = []\n",
    "    for idx in df[\"Index\"].unique():\n",
    "        human_rows = df[(df[\"Index\"] == idx) & (df[\"Source\"] == \"Human\")]\n",
    "        model_rows = df[(df[\"Index\"] == idx) & (df[\"Source\"] == model_source)]\n",
    "        # Model no error: All model rows have Domain==NaN\n",
    "        if model_rows[\"Domain\"].isnull().all():\n",
    "            # Human has at least one error\n",
    "            if human_rows[\"Domain\"].notnull().any():\n",
    "                cases.append(idx)\n",
    "    return cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. When Human labels error and model also labels error, what is the average # of errors model encounters?\n",
    "## (For cases where Human labeled at least one error AND there’s at least one concordant error, count the number of model error rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_model_errors_when_human_error(df, model_source=\"Baseline\"):\n",
    "    error_counts = []\n",
    "    for idx in df[\"Index\"].unique():\n",
    "        human_rows = df[(df[\"Index\"] == idx) & (df[\"Source\"] == \"Human\")]\n",
    "        model_rows = df[(df[\"Index\"] == idx) & (df[\"Source\"] == model_source)]\n",
    "        # Human has error\n",
    "        if human_rows[\"Domain\"].notnull().any():\n",
    "            # At least one model row matches an error\n",
    "            found_match = False\n",
    "            for _, hr in human_rows.iterrows():\n",
    "                for _, mr in model_rows.iterrows():\n",
    "                    if (\n",
    "                        pd.notna(hr[\"Domain\"]) and pd.notna(mr[\"Domain\"])\n",
    "                        and hr[\"Domain\"] == mr[\"Domain\"]\n",
    "                        and pd.notna(hr[\"Subdomain\"]) and pd.notna(mr[\"Subdomain\"])\n",
    "                        and hr[\"Subdomain\"] == mr[\"Subdomain\"]\n",
    "                        and pd.notna(hr[\"Error Code\"]) and pd.notna(mr[\"Error Code\"])\n",
    "                        and hr[\"Error Code\"] == mr[\"Error Code\"]\n",
    "                    ):\n",
    "                        found_match = True\n",
    "            if found_match:\n",
    "                # How many error rows in model for this index?\n",
    "                error_counts.append(model_rows[\"Domain\"].notnull().sum())\n",
    "    if error_counts:\n",
    "        return sum(error_counts) / len(error_counts)\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Count how many cases have errors flagged by both, neither, only one source, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many cases have errors flagged by both, neither, only one source, etc.\n",
    "def case_level_confusion_matrix(df):\n",
    "    results = {\"both_error\": 0, \"only_human\": 0, \"only_model\": 0, \"neither\": 0}\n",
    "    for idx in df[\"Index\"].unique():\n",
    "        human_error = df[(df[\"Index\"] == idx) & (df[\"Source\"] == \"Human\")][\"Domain\"].notnull().any()\n",
    "        model_error = df[(df[\"Index\"] == idx) & (df[\"Source\"] == \"Baseline\")][\"Domain\"].notnull().any()\n",
    "        if human_error and model_error:\n",
    "            results[\"both_error\"] += 1\n",
    "        elif human_error and not model_error:\n",
    "            results[\"only_human\"] += 1\n",
    "        elif not human_error and model_error:\n",
    "            results[\"only_model\"] += 1\n",
    "        else:\n",
    "            results[\"neither\"] += 1\n",
    "    return results\n",
    "\n",
    "# Error count statistics by source\n",
    "def error_count_stats(df, source):\n",
    "    counts = []\n",
    "    for idx in df[\"Index\"].unique():\n",
    "        rows = df[(df[\"Index\"] == idx) & (df[\"Source\"] == source)]\n",
    "        counts.append(rows[\"Domain\"].notnull().sum())\n",
    "    return {\"mean\": np.mean(counts), \"median\": np.median(counts), \"max\": np.max(counts), \"min\": np.min(counts)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_report(df):\n",
    "    # Basic stats\n",
    "    basic_stats(df)\n",
    "\n",
    "    # Concordance analyses\n",
    "    print(\"===== Concordance Analysis: Baseline vs Human =====\\n\")\n",
    "    concordance_analysis(df, source=\"Baseline\", breakdown=True, index_level_breakdown=True, error_level_concordance=True)\n",
    "    \n",
    "    print(\"===== Concordance Analysis: Enhanced vs Human =====\\n\")\n",
    "    concordance_analysis(df, source=\"Enhanced\", breakdown=True, index_level_breakdown=True, error_level_concordance=True)\n",
    "\n",
    "    # Baseline analysis\n",
    "    print(\"===== Discrepancy/Agreement Analysis: Baseline =====\\n\")\n",
    "    baseline_noerror_cases = human_noerror_model_error(df, model_source=\"Baseline\")\n",
    "    print(f\"Cases where Human labeled as no error but Baseline labeled as error: {len(baseline_noerror_cases)}\")\n",
    "    if len(baseline_noerror_cases) > 0:\n",
    "        print(f\"  Indices: {baseline_noerror_cases}\")\n",
    "\n",
    "    baseline_humanerror_cases = model_noerror_human_error(df, model_source=\"Baseline\")\n",
    "    print(f\"Cases where Baseline labeled as no error but Human labeled as error: {len(baseline_humanerror_cases)}\")\n",
    "    if len(baseline_humanerror_cases) > 0:\n",
    "        print(f\"  Indices: {baseline_humanerror_cases}\")\n",
    "\n",
    "    avg_baseline_errors = avg_model_errors_when_human_error(df, model_source=\"Baseline\")\n",
    "    print(f\"Average # Baseline errors encountered in cases where Human labeled an error and there was concordance: {avg_baseline_errors:.2f}\")\n",
    "\n",
    "    baseline_conf_matrix = case_level_confusion_matrix(df)\n",
    "    print(\"\\nCase-level Confusion Matrix (Human vs Baseline):\")\n",
    "    for k, v in baseline_conf_matrix.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    baseline_err_stats = error_count_stats(df, source=\"Baseline\")\n",
    "    print(\"\\nBaseline Error Count Stats (per case):\")\n",
    "    for k, v in baseline_err_stats.items():\n",
    "        print(f\"  {k}: {v:.2f}\")\n",
    "\n",
    "    print(\"\\n-----\\n\")\n",
    "\n",
    "    # Enhanced analysis\n",
    "    print(\"===== Discrepancy/Agreement Analysis: Enhanced =====\\n\")\n",
    "    enhanced_noerror_cases = human_noerror_model_error(df, model_source=\"Enhanced\")\n",
    "    print(f\"Cases where Human labeled as no error but Enhanced labeled as error: {len(enhanced_noerror_cases)}\")\n",
    "    if len(enhanced_noerror_cases) > 0:\n",
    "        print(f\"  Indices: {enhanced_noerror_cases}\")\n",
    "\n",
    "    enhanced_humanerror_cases = model_noerror_human_error(df, model_source=\"Enhanced\")\n",
    "    print(f\"Cases where Enhanced labeled as no error but Human labeled as error: {len(enhanced_humanerror_cases)}\")\n",
    "    if len(enhanced_humanerror_cases) > 0:\n",
    "        print(f\"  Indices: {enhanced_humanerror_cases}\")\n",
    "\n",
    "    avg_enhanced_errors = avg_model_errors_when_human_error(df, model_source=\"Enhanced\")\n",
    "    print(f\"Average # Enhanced errors encountered in cases where Human labeled an error and there was concordance: {avg_enhanced_errors:.2f}\")\n",
    "\n",
    "    enhanced_conf_matrix = case_level_confusion_matrix(df)\n",
    "    print(\"\\nCase-level Confusion Matrix (Human vs Enhanced):\")\n",
    "    for k, v in enhanced_conf_matrix.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    enhanced_err_stats = error_count_stats(df, source=\"Enhanced\")\n",
    "    print(\"\\nEnhanced Error Count Stats (per case):\")\n",
    "    for k, v in enhanced_err_stats.items():\n",
    "        print(f\"  {k}: {v:.2f}\")\n",
    "\n",
    "    print(\"\\n=========================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Basic Statistics =====\n",
      "\n",
      "Total cases (unique indices): 50\n",
      "\n",
      "Human:\n",
      "  Cases flagged as error: 20 (40.0%)\n",
      "  Error Domain breakdown:\n",
      "    Clinical Reasoning: 23\n",
      "  Error Subdomain breakdown:\n",
      "    Workflow Recommendations: 11\n",
      "    Comprehension of Patient Query: 3\n",
      "    Comprehension of Medical Guidelines and Standard of Care: 3\n",
      "    Comprehension of Patient Context: 2\n",
      "    Triage: 2\n",
      "    Assessment: 1\n",
      "    Traige: 1\n",
      "  Error Code breakdown:\n",
      "    Violation of Standard Workflows: 9\n",
      "    Incorrect Clinical Guideline or Standard of Care: 3\n",
      "    Incorrect Clinical Information: 2\n",
      "    Incomplete Response to Patient Query: 2\n",
      "    Missed Escalation of Care: 2\n",
      "    Unverified Workflow Assumption: 2\n",
      "    Omitted Verification of Incomplete Patient Information: 1\n",
      "    Role-Based Scope Violation: 1\n",
      "    Misinterpretation of Clinical Query: 1\n",
      "\n",
      "Baseline:\n",
      "  Cases flagged as error: 20 (40.0%)\n",
      "  Error Domain breakdown:\n",
      "    Clinical Reasoning: 35\n",
      "    Communication Quality & Readability: 19\n",
      "    Bias & Stigmatization: 4\n",
      "    Privacy & Security: 3\n",
      "    Accessibility: 1\n",
      "  Error Subdomain breakdown:\n",
      "    Clinical Recommendations: 15\n",
      "    Clarity: 13\n",
      "    Comprehension of Patient Query: 11\n",
      "    Workflow Recommendations: 5\n",
      "    Empathy: 4\n",
      "    Identity & Respect: 4\n",
      "    Length: 2\n",
      "    Patient Data Integrity: 2\n",
      "    Triage: 2\n",
      "    HIPAA Compliance: 1\n",
      "    Language Accommodation: 1\n",
      "    Assessment: 1\n",
      "    Comprehension of Patient Context: 1\n",
      "  Error Code breakdown:\n",
      "    Ambiguous or Conflicting Instructions: 13\n",
      "    Incomplete Response to Patient Query: 6\n",
      "    Inappropriate Treatment or Medication Recommendation: 5\n",
      "    Lack of Empathy: 4\n",
      "    Incorrect Patient Name in Greeting: 4\n",
      "    Misinterpretation of Clinical Query: 3\n",
      "    Inconsistent with Prior Clinical Communications: 3\n",
      "    Incorrect Workflow Information: 2\n",
      "    Violation of Standard Workflows: 2\n",
      "    Chart Contamination / Wrong Patient Data: 2\n",
      "    Off-topic or Irrelevant Reply to Patient Query: 2\n",
      "    Message Too Short: 2\n",
      "    Inappropriate Specialist Referral Recommendation: 2\n",
      "    Inappropriate Follow-Up Recommendation: 2\n",
      "    Missing Safety Net Instructions: 2\n",
      "    Missed Escalation of Care: 1\n",
      "    Omitted Workflow Information: 1\n",
      "    Lack of Language Accommodation: 1\n",
      "    Delayed Urgency Recognition: 1\n",
      "    Omitted Differential Diagnosis: 1\n",
      "    Medication Error: 1\n",
      "    HIPAA Violation / Unintended Disclosure: 1\n",
      "    Omission of Pertinent Clinical Information: 1\n",
      "\n",
      "Enhanced:\n",
      "  Cases flagged as error: 17 (34.0%)\n",
      "  Error Domain breakdown:\n",
      "    Clinical Reasoning: 31\n",
      "    Communication Quality & Readability: 16\n",
      "    Privacy & Security: 4\n",
      "    Bias & Stigmatization: 3\n",
      "  Error Subdomain breakdown:\n",
      "    Clinical Recommendations: 13\n",
      "    Comprehension of Patient Query: 10\n",
      "    Clarity: 8\n",
      "    Empathy: 5\n",
      "    Comprehension of Patient Context: 4\n",
      "    Patient Data Integrity: 3\n",
      "    Identity & Respect: 3\n",
      "    Length: 3\n",
      "    Assessment: 2\n",
      "    Comprehension of Medical Guidelines and Standard of Care: 1\n",
      "    HIPAA Compliance: 1\n",
      "    Workflow Recommendations: 1\n",
      "  Error Code breakdown:\n",
      "    Ambiguous or Conflicting Instructions: 8\n",
      "    Incomplete Response to Patient Query: 6\n",
      "    Lack of Empathy: 5\n",
      "    Inappropriate Treatment or Medication Recommendation: 4\n",
      "    Off-topic or Irrelevant Reply to Patient Query: 3\n",
      "    Message Too Short: 3\n",
      "    Missing Safety Net Instructions: 3\n",
      "    Incorrect Patient Name in Greeting: 3\n",
      "    Chart Contamination / Wrong Patient Data: 3\n",
      "    Inconsistent with Prior Clinical Communications: 2\n",
      "    Incorrect Clinical Information: 2\n",
      "    Omission of Pertinent Clinical Information: 2\n",
      "    Inappropriate Follow-Up Recommendation: 2\n",
      "    Omitted Verification of Incomplete Patient Information: 1\n",
      "    Incorrect Clinical Guideline or Standard of Care: 1\n",
      "    Inappropriate or Omitted Diagnostic Test Recommendation: 1\n",
      "    Misinterpretation of Clinical Query: 1\n",
      "    HIPAA Violation / Unintended Disclosure: 1\n",
      "    Omitted Differential Diagnosis: 1\n",
      "    Inappropriate Specialist Referral Recommendation: 1\n",
      "    Omitted Workflow Information: 1\n",
      "\n",
      "===== Concordance Analysis: Baseline vs Human =====\n",
      "\n",
      "Total indices: 50\n",
      "Concordant (NaN Domain): 16\n",
      "Concordant (Domain): 6\n",
      "Concordant (Subdomain): 2\n",
      "Concordant (Error Code): 1\n",
      "\n",
      "Breakdown by Domain (unique indices):\n",
      "  Clinical Reasoning: 6\n",
      "\n",
      "Breakdown by Subdomain (unique indices):\n",
      "  Comprehension of Patient Query: 1\n",
      "  Workflow Recommendations: 1\n",
      "\n",
      "Breakdown by Error Code (unique indices):\n",
      "  Incomplete Response to Patient Query: 1\n",
      "\n",
      "Breakdown by Domain (pairwise matches):\n",
      "  Clinical Reasoning: 13\n",
      "\n",
      "Breakdown by Subdomain (pairwise matches):\n",
      "  Comprehension of Patient Query: 3\n",
      "  Workflow Recommendations: 1\n",
      "\n",
      "Breakdown by Error Code (pairwise matches):\n",
      "  Incomplete Response to Patient Query: 1\n",
      "\n",
      "Concordant at full error level (all three match): 1\n",
      "===== Concordance Analysis: Enhanced vs Human =====\n",
      "\n",
      "Total indices: 50\n",
      "Concordant (NaN Domain): 19\n",
      "Concordant (Domain): 6\n",
      "Concordant (Subdomain): 2\n",
      "Concordant (Error Code): 1\n",
      "\n",
      "Breakdown by Domain (unique indices):\n",
      "  Clinical Reasoning: 6\n",
      "\n",
      "Breakdown by Subdomain (unique indices):\n",
      "  Comprehension of Patient Query: 1\n",
      "  Workflow Recommendations: 1\n",
      "\n",
      "Breakdown by Error Code (unique indices):\n",
      "  Incomplete Response to Patient Query: 1\n",
      "\n",
      "Breakdown by Domain (pairwise matches):\n",
      "  Clinical Reasoning: 20\n",
      "\n",
      "Breakdown by Subdomain (pairwise matches):\n",
      "  Comprehension of Patient Query: 3\n",
      "  Workflow Recommendations: 1\n",
      "\n",
      "Breakdown by Error Code (pairwise matches):\n",
      "  Incomplete Response to Patient Query: 1\n",
      "\n",
      "Concordant at full error level (all three match): 1\n",
      "===== Discrepancy/Agreement Analysis: Baseline =====\n",
      "\n",
      "Cases where Human labeled as no error but Baseline labeled as error: 14\n",
      "  Indices: [np.int64(5598), np.int64(14858), np.int64(29023), np.int64(30451), np.int64(39933), np.int64(41322), np.int64(55744), np.int64(65791), np.int64(72081), np.int64(83153), np.int64(104179), np.int64(118469), np.int64(119042), np.int64(120351)]\n",
      "Cases where Baseline labeled as no error but Human labeled as error: 14\n",
      "  Indices: [np.int64(2432), np.int64(11928), np.int64(19667), np.int64(22789), np.int64(46039), np.int64(49823), np.int64(53391), np.int64(60920), np.int64(78318), np.int64(100157), np.int64(101519), np.int64(106367), np.int64(110718), np.int64(111440)]\n",
      "Average # Baseline errors encountered in cases where Human labeled an error and there was concordance: 3.00\n",
      "\n",
      "Case-level Confusion Matrix (Human vs Baseline):\n",
      "  both_error: 6\n",
      "  only_human: 14\n",
      "  only_model: 14\n",
      "  neither: 16\n",
      "\n",
      "Baseline Error Count Stats (per case):\n",
      "  mean: 1.24\n",
      "  median: 0.00\n",
      "  max: 6.00\n",
      "  min: 0.00\n",
      "\n",
      "-----\n",
      "\n",
      "===== Discrepancy/Agreement Analysis: Enhanced =====\n",
      "\n",
      "Cases where Human labeled as no error but Enhanced labeled as error: 11\n",
      "  Indices: [np.int64(5598), np.int64(14858), np.int64(39933), np.int64(41322), np.int64(49714), np.int64(55744), np.int64(65791), np.int64(70184), np.int64(104179), np.int64(118469), np.int64(119042)]\n",
      "Cases where Enhanced labeled as no error but Human labeled as error: 14\n",
      "  Indices: [np.int64(2432), np.int64(19667), np.int64(22789), np.int64(46039), np.int64(49823), np.int64(53391), np.int64(60920), np.int64(78318), np.int64(100157), np.int64(101519), np.int64(106367), np.int64(110718), np.int64(111440), np.int64(113473)]\n",
      "Average # Enhanced errors encountered in cases where Human labeled an error and there was concordance: 6.00\n",
      "\n",
      "Case-level Confusion Matrix (Human vs Enhanced):\n",
      "  both_error: 6\n",
      "  only_human: 14\n",
      "  only_model: 14\n",
      "  neither: 16\n",
      "\n",
      "Enhanced Error Count Stats (per case):\n",
      "  mean: 1.08\n",
      "  median: 0.00\n",
      "  max: 9.00\n",
      "  min: 0.00\n",
      "\n",
      "=========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_report(full_lables_ensured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage_recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
