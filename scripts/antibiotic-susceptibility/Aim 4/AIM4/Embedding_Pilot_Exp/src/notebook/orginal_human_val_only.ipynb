{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fecff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b597b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded from SPM's notebook\n",
    "first_n_indices = [2432,\n",
    " 19667,\n",
    " 21392,\n",
    " 22585,\n",
    " 22789,\n",
    " 25822,\n",
    " 27428,\n",
    " 38938,\n",
    " 39901,\n",
    " 44402,\n",
    " 46039,\n",
    " 49823,\n",
    " 53391,\n",
    " 60920,\n",
    " 63940,\n",
    " 78318,\n",
    " 79480,\n",
    " 82643,\n",
    " 94483,\n",
    " 100157,\n",
    " 101519,\n",
    " 106367,\n",
    " 106820,\n",
    " 110718,\n",
    " 111440,\n",
    " 117036,\n",
    " 124222,\n",
    " 134264,\n",
    " 140824,\n",
    " 146126,\n",
    " 149506,\n",
    " 160988,\n",
    " 173987,\n",
    " 190304,\n",
    " 208055,\n",
    " 217691,\n",
    " 223678,\n",
    " 231119,\n",
    " 239336,\n",
    " 241520,\n",
    " 241620,\n",
    " 248166,\n",
    " 265165,\n",
    " 265647,\n",
    " 283211,\n",
    " 285732,\n",
    " 290398,\n",
    " 295864,\n",
    " 305128,\n",
    " 314021,\n",
    " 5598,\n",
    " 11928,\n",
    " 14858,\n",
    " 29023,\n",
    " 30451,\n",
    " 39933,\n",
    " 41322,\n",
    " 49714,\n",
    " 55744,\n",
    " 65791,\n",
    " 72081,\n",
    " 83153,\n",
    " 85971,\n",
    " 89405,\n",
    " 99713,\n",
    " 104179,\n",
    " 108523,\n",
    " 110120,\n",
    " 113473,\n",
    " 118469,\n",
    " 120351,\n",
    " 124776,\n",
    " 135202,\n",
    " 139937,\n",
    " 140373,\n",
    " 145813,\n",
    " 147664,\n",
    " 159295,\n",
    " 160258,\n",
    " 166720,\n",
    " 171849,\n",
    " 176142,\n",
    " 180195,\n",
    " 184776,\n",
    " 188565,\n",
    " 190057,\n",
    " 197077,\n",
    " 205221,\n",
    " 207720,\n",
    " 214001,\n",
    " 231948,\n",
    " 233511,\n",
    " 238215,\n",
    " 240196,\n",
    " 248247,\n",
    " 251860,\n",
    " 258084,\n",
    " 262055,\n",
    " 279586,\n",
    " 281063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb92b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physician_validation_path = \"/Users/sandychen/Library/CloudStorage/Box-Box/Prospective Labeling V3/Data/Stephen Labels.xlsx\"\n",
    "llm_labels_path = \"/Users/sandychen/Library/CloudStorage/Box-Box/Prospective Labeling V3/Data/LLM Labels.xlsx\"\n",
    "codebook_path = \"/Users/sandychen/Library/CloudStorage/Box-Box/Prospective Labeling V3/Pipeline_v2_data/dedup_codebook.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032f704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Physician_label_all= pd.read_excel(physician_validation_path)\n",
    "LLM_label_all   = pd.read_excel(llm_labels_path)\n",
    "codebook_df = pd.read_csv(codebook_path)[[\"Dedup Error Code\", \"Dedup Subdomain\", \"Dedup Domain\", \"Dedup Definition\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489b1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_label       = LLM_label_all[LLM_label_all[\"Index\"].isin(first_n_indices)]\n",
    "Physician_label = Physician_label_all[Physician_label_all[\"Index\"].isin(first_n_indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe5b5a",
   "metadata": {},
   "source": [
    "# build training sets for DSPY prompt optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e27106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "repo_src = \"/Users/sandychen/Desktop/Healthrex_workspace/scripts/antibiotic-susceptibility/Aim 4/AIM4/Embedding_Pilot_Exp/src\"\n",
    "if repo_src not in sys.path:\n",
    "    sys.path.append(repo_src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27df233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _slug(text: str) -> str:\n",
    "    \"\"\"\n",
    "    File/identifier safe key for an error code.\n",
    "    - Preserves underscores inside each hierarchy segment.\n",
    "    - Uses \"__\" only to join Domain / Subdomain / Error Code boundaries.\n",
    "    \"\"\"\n",
    "    segments = [seg.strip().lower() for seg in re.split(r\"-+\", text) if seg.strip()]\n",
    "    slugged_segments = []\n",
    "    for seg in segments:\n",
    "        cleaned = re.sub(r\"[^\\w]+\", \"_\", seg)\n",
    "        cleaned = re.sub(r\"_+\", \"_\", cleaned).strip(\"_\")\n",
    "        if cleaned:\n",
    "            slugged_segments.append(cleaned)\n",
    "    return \"__\".join(slugged_segments)\n",
    "codebook = pd.read_csv(\"../data/input_data/dedup_codebook.csv\")\n",
    "codebook[\"code_key\"] = codebook.apply(\n",
    "    lambda r: _slug(f\"{r['Dedup Domain']}-{r['Dedup Subdomain']}-{r['Dedup Error Code']}\"), axis=1\n",
    ")\n",
    "all_code_keys = sorted(codebook[\"code_key\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a9a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_input_data_path = \"../DSPy_results_batch_previously_labeled_100_dedup_with_prev_msg/identifier_results_input.jsonl\"\n",
    "enhanced_input_data_path = \"../DSPy_results_batch_previously_labeled_100_dedup_with_prev_msg_w_ref/identifier_results_input.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a641deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(baseline_input_data_path) as f:\n",
    "    records = [json.loads(line) for line in f if line.strip()]\n",
    "baseline_input_data_df = pd.DataFrame(records)\n",
    "with open(enhanced_input_data_path) as f:\n",
    "    records = [json.loads(line) for line in f if line.strip()]\n",
    "enhanced_input_data_df = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daac4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "def make_lookup(df, keep=\"first\", name=\"df\"):\n",
    "    dupes = df[df[\"index\"].duplicated()][\"index\"].unique()\n",
    "    if len(dupes) > 0:\n",
    "        print(f\"[warn] {name} has duplicate index values: {dupes}\")\n",
    "    return (\n",
    "        df.sort_values(\"index\")\n",
    "          .drop_duplicates(subset=\"index\", keep=keep)\n",
    "          .set_index(\"index\")\n",
    "    )\n",
    "\n",
    "baseline_lookup = make_lookup(baseline_input_data_df, keep=\"first\", name=\"baseline\")\n",
    "enhanced_lookup = make_lookup(enhanced_input_data_df, keep=\"first\", name=\"enhanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9b129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- prepare labels (only valid rows) ----------\n",
    "valid_labels = Physician_label.dropna(subset=[\"Source\", \"Domain\", \"Subdomain\", \"Error Code\"]).copy()\n",
    "valid_labels[\"code_key\"] = valid_labels.apply(\n",
    "    lambda r: _slug(f\"{r['Domain']}-{r['Subdomain']}-{r['Error Code']}\"), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6922822",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_lookup = make_lookup(baseline_input_data_df, keep=\"first\", name=\"baseline\")\n",
    "enhanced_lookup = make_lookup(enhanced_input_data_df, keep=\"first\", name=\"enhanced\")\n",
    "\n",
    "def select_input_row(idx: int, labels_df):\n",
    "    srcs = set(labels_df[labels_df[\"Index\"] == idx][\"Source\"].dropna().unique())\n",
    "    preferred = enhanced_lookup if (\"Enhanced\" in srcs or \"Human\" in srcs) else baseline_lookup\n",
    "    if idx not in preferred.index:\n",
    "        return None\n",
    "    return preferred.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9045474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- build training records ----------\n",
    "train_records = []\n",
    "for idx in sorted(first_n_indices):\n",
    "    row = select_input_row(idx, valid_labels)\n",
    "    if row is None:\n",
    "        print(f\"[warn] missing input row for index {idx}, skipping\")\n",
    "        continue\n",
    "\n",
    "    record = {\n",
    "        \"index\": idx,\n",
    "        \"patient_message\": row.patient_message,\n",
    "        \"llm_response\": row.llm_response,\n",
    "        \"patient_info\": row.patient_info,\n",
    "        \"clinical_notes\": row.clinical_notes,\n",
    "        \"previous_messages\": row.previous_messages,\n",
    "        \"retrieved_pairs\": row.retrieved_pairs if pd.notna(getattr(row, \"retrieved_pairs\", \"\")) else \"\",\n",
    "    }\n",
    "    # init all codes to negatives/empty\n",
    "    for ck in all_code_keys:\n",
    "        record[f\"label_{ck}\"] = False\n",
    "        record[f\"rationale_{ck}\"] = \"\"\n",
    "        record[f\"excerpt_{ck}\"] = \"\"\n",
    "\n",
    "    # mark positives for this index\n",
    "    labs = valid_labels[valid_labels[\"Index\"] == idx]\n",
    "    for _, lab in labs.iterrows():\n",
    "        ck = lab[\"code_key\"]\n",
    "        record[f\"label_{ck}\"] = True\n",
    "        record[f\"rationale_{ck}\"] = lab.get(\"Rationale\", \"\") or \"\"\n",
    "        # Add excerpt if you have one; else leave blank (optimizer will default to Not Applicable for negatives)\n",
    "    train_records.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5becacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_records)\n",
    "# assume all_code_keys is the list of your 59 code_keys\n",
    "label_cols = [f\"label_{ck}\" for ck in all_code_keys]\n",
    "\n",
    "# Boolean flag: True if any code is positive, else False\n",
    "train_df[\"any_error_present\"] = train_df[label_cols].any(axis=1)\n",
    "\n",
    "# Optionally, store the list of positive codes for that row\n",
    "train_df[\"positive_codes\"] = train_df[label_cols].apply(\n",
    "    lambda r: [ck for ck, v in zip(all_code_keys, r.values) if v], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4c82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c3cf9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df[train_df[\"any_error_present\"]][\"index\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08c68f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_labels[\"Index\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a0cc9",
   "metadata": {},
   "source": [
    "## the above should be the same, after digging, realized that one of the codes labelled by human is not in the codebook. \n",
    "### manually fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50280c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 140373 any_error_present: True\n",
      "Positive codes: ['clinical_reasoning__comprehension_of_patient_context__incorrect_clinical_information', 'clinical_reasoning__comprehension_of_patient_query__incorrect_clinical_information']\n"
     ]
    }
   ],
   "source": [
    "# --- Hard fix for index 140373 missing the ICC code_key mapping ---\n",
    "override_ck = \"clinical_reasoning__comprehension_of_patient_context__incorrect_clinical_information\"\n",
    "ck_col = f\"label_{override_ck}\"\n",
    "\n",
    "# Ensure the column exists\n",
    "if ck_col not in train_df.columns:\n",
    "    raise ValueError(f\"Expected column {ck_col} not found in train_df\")\n",
    "\n",
    "# Set the label (and rationale/optional excerpt) for this index\n",
    "train_df.loc[train_df[\"index\"] == 140373, ck_col] = True\n",
    "train_df.loc[train_df[\"index\"] == 140373, f\"rationale_{override_ck}\"] = (\n",
    "    \"The instruction missed that the maintenance dose was incorrect.\"\n",
    ")\n",
    "# optional excerpt if you have one:\n",
    "# train_df.loc[train_df[\"index\"] == 140373, f\"excerpt_{override_ck}\"] = \"<verbatim span>\"\n",
    "\n",
    "# Recompute any_error_present and positive_codes\n",
    "label_cols = [c for c in train_df.columns if c.startswith(\"label_\")]\n",
    "train_df[\"any_error_present\"] = train_df[label_cols].any(axis=1)\n",
    "train_df[\"positive_codes\"] = train_df[label_cols].apply(\n",
    "    lambda r: [c.replace(\"label_\", \"\") for c, v in zip(label_cols, r.values) if v], axis=1\n",
    ")\n",
    "\n",
    "print(\"Index 140373 any_error_present:\",\n",
    "      train_df.loc[train_df[\"index\"] == 140373, \"any_error_present\"].item())\n",
    "print(\"Positive codes:\",\n",
    "      train_df.loc[train_df[\"index\"] == 140373, \"positive_codes\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5958384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any_error_present\n",
       "True     57\n",
       "False    43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"any_error_present\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a25b6348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 40 rows to ../data/input_data/labeled_modular_training_20pos_20neg.csv (pos=20, neg=20)\n"
     ]
    }
   ],
   "source": [
    "# Sample positives and negatives (up to 20 each)\n",
    "pos_df = train_df[train_df[\"any_error_present\"]]\n",
    "neg_df = train_df[~train_df[\"any_error_present\"]]\n",
    "\n",
    "# Adjust n if you have fewer than 20 in either group\n",
    "n_pos = min(20, len(pos_df))\n",
    "n_neg = min(20, len(neg_df))\n",
    "\n",
    "pos_sample = pos_df.sample(n=n_pos, random_state=42) if n_pos > 0 else pd.DataFrame(columns=train_df.columns)\n",
    "neg_sample = neg_df.sample(n=n_neg, random_state=42) if n_neg > 0 else pd.DataFrame(columns=train_df.columns)\n",
    "\n",
    "train_subset = pd.concat([pos_sample, neg_sample], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "out_path = \"../data/input_data/labeled_modular_training_20pos_20neg.csv\"\n",
    "train_subset.to_csv(out_path, index=False)\n",
    "print(f\"Saved {len(train_subset)} rows to {out_path} (pos={n_pos}, neg={n_neg})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b4cdb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"../data/input_data/prospective_sample_100_unified_previously_labeled_from_colbert_cleaned.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6efd94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df = pd.read_csv(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e56c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inbasket_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
