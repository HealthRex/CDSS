{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3 OMOP Item Prevalence and RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "##Setting up Google sdk environment\n",
    "import os \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/wip/.config/gcloud/application_default_credentials.json'  \n",
    "os.environ['GCLOUD_PROJECT'] = 'som-nero-phi-jonc101' \n",
    "\n",
    "import sys\n",
    "import json\n",
    "\n",
    "JSON_FILE_PATH = '/Users/wip/Recommender/V3/resource'\n",
    "sys.path.append('/Users/wip/Recommender/V3/python_scripts')\n",
    "#from bigQueryUtil import BigQueryClient \n",
    "from StatsUtil import getStats\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "##Setting up BQ API\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "project_id = 'som-rit-phi-starr-prod'\n",
    "dataset_id = 'starr_omop_cdm5_deid_latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables\n",
    "year_start = '2014'\n",
    "year_end = '2020'\n",
    "prefix = 'V3'\n",
    "\n",
    "save_project_id = 'som-nero-phi-jonc101'\n",
    "save_dataset_id = 'wui_omop_peds'\n",
    "\n",
    "table_id_outpt = prefix + '_Outpt_Cohort_' + year_start + '_' + year_end\n",
    "table_id_cohort =  prefix + '_cohort_'+ year_start + '_' + year_end\n",
    "\n",
    "format_map_dict = {'project_id': project_id,\n",
    "                   'dataset_id': dataset_id, \n",
    "                   'save_project_id': save_project_id,\n",
    "                   'save_dataset_id': save_dataset_id,\n",
    "                   'table_id_outpt': table_id_outpt,\n",
    "                   'table_id_cohort': table_id_cohort,\n",
    "                   'prefix': prefix \n",
    "                    }\n",
    "\n",
    "table_list =  [('measurement','measurement','measurement_concept_id'),\n",
    "                 ('procedure_occurrence','procedure','procedure_concept_id'),\n",
    "                 ('drug_exposure','drug','drug_concept_id'),\n",
    "                 ('condition_occurrence','condition','condition_concept_id'),\n",
    "                 ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_query_table(sql, table_str):\n",
    "    job_config = bigquery.QueryJobConfig(destination=table_str)\n",
    "    client.delete_table(table_str, not_found_ok = True)\n",
    "    query_job = client.query(sql, job_config=job_config)  \n",
    "    query_job.result() \n",
    "    print(\"Query results loaded to the table {}\".format(table_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_row_count(sql):\n",
    "    query_job = client.query(sql)  \n",
    "    results = query_job.result()\n",
    "    results_list = [row for row in results]\n",
    "    return results_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_BQ(table_id):\n",
    "        # reading a table from BiqQuery\n",
    "        sql = \"\"\" \n",
    "            SELECT * FROM \n",
    "                som-nero-phi-jonc101.wui_omop_peds.{table_id}\n",
    "            \"\"\".format_map({'table_id':table_id})\n",
    "        query_job = client.query(sql)\n",
    "        dataframe = query_job.to_dataframe()\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlCohort = \"\"\"SELECT COUNT(DISTINCT(person_id))  \n",
    "                FROM `{save_project_id}.{save_dataset_id}.{table_id_cohort}` \n",
    "                \"\"\".format_map(format_map_dict)\n",
    "    \n",
    "sqlAll = \"\"\"SELECT COUNT(DISTINCT(person_id))  \n",
    "                FROM `{save_project_id}.{save_dataset_id}.{table_id_outpt}` \n",
    "                \"\"\".format_map(format_map_dict)\n",
    "\n",
    "N_cohort = get_query_row_count(sqlCohort)\n",
    "N_All = get_query_row_count(sqlAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query results loaded to the table som-nero-phi-jonc101.wui_omop_peds.V3_count_measurement_Outpt\n",
      "Query results loaded to the table som-nero-phi-jonc101.wui_omop_peds.V3_count_procedure_Outpt\n",
      "Query results loaded to the table som-nero-phi-jonc101.wui_omop_peds.V3_count_drug_Outpt\n",
      "Query results loaded to the table som-nero-phi-jonc101.wui_omop_peds.V3_count_condition_Outpt\n"
     ]
    }
   ],
   "source": [
    "# get counts (number of patients, visits and instances) per each clinical items\n",
    "# in all outpatient pediatric visits 2015-2019\n",
    "\n",
    "table_list =  [('measurement','measurement','measurement_concept_id'),\n",
    "                 ('procedure_occurrence','procedure','procedure_concept_id'),\n",
    "                 ('drug_exposure','drug','drug_concept_id'),\n",
    "                 ('condition_occurrence','condition','condition_concept_id'),\n",
    "                 ]\n",
    "\n",
    "\n",
    "for t in table_list:\n",
    "    (table, tableName, concept_id) = t\n",
    "    \n",
    "    feature_dict = {'table': table,\n",
    "                    'concept_id': concept_id}\n",
    "    \n",
    "    feature_dict.update(format_map_dict)\n",
    "    \n",
    "    sql = \"\"\"\n",
    "            WITH itemAllOutpt AS (        \n",
    "                    SELECT \n",
    "                        x.person_id,\n",
    "                        x.visit_occurrence_id,\n",
    "                        x.{concept_id} as item_concept_id\n",
    "                    FROM \n",
    "                        `{project_id}.{dataset_id}.{table}` x\n",
    "                    INNER JOIN \n",
    "                        `{save_project_id}.{save_dataset_id}.{table_id_outpt}` c \n",
    "                        ON \n",
    "                            (x.person_id = c.person_id) AND\n",
    "                            (x.visit_occurrence_id = c.visit_occurrence_id)\n",
    "                  )\n",
    "\n",
    "            SELECT item_concept_id,\n",
    "                   COUNT(DISTINCT(person_id)) as num_pt, \n",
    "                   COUNT(DISTINCT(visit_occurrence_id)) as num_visit,\n",
    "                   COUNT(*) as instance\n",
    "            FROM itemAllOutpt \n",
    "            GROUP BY item_concept_id \n",
    "            ORDER BY num_pt DESC, num_visit DESC, instance DESC\n",
    "\n",
    "    \"\"\".format_map(feature_dict)\n",
    "\n",
    "    save_table_id = prefix + \"_count_\" + tableName + \"_Outpt\"\n",
    "    table_str = save_project_id + '.' + save_dataset_id + '.' + save_table_id\n",
    "    save_query_table(sql, table_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading...measurement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/google/cloud/bigquery/client.py:444: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading...procedure\n",
      "reading...drug\n",
      "reading...condition\n",
      "saving baseline prevalence map as json\n"
     ]
    }
   ],
   "source": [
    "# getting baseline outpatient prevalence for each item \n",
    "combined_df = pd.DataFrame()\n",
    "features =  ['measurement','procedure','drug','condition']\n",
    "for feature in features:\n",
    "    print('reading...{}'.format(feature))\n",
    "    df = read_BQ(table_id = prefix + '_count_'+ feature +'_Outpt')\n",
    "    combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "combined_df = combined_df[combined_df['item_concept_id']!=0]\n",
    "combined_df[\"baseline_prevalence\"] = combined_df[\"num_pt\"].apply(lambda x : x * 100 / N_All)\n",
    "final_df = combined_df[[\"item_concept_id\",\"baseline_prevalence\"]]\n",
    "final_df.sort_values(by = \"baseline_prevalence\", ascending = False)\n",
    "final_dict = final_df.set_index(\"item_concept_id\").to_dict()\n",
    "baseline_prevalence_map = final_dict[\"baseline_prevalence\"]\n",
    "with open(JSON_FILE_PATH + '/baseline_prevalence_map.json', 'w') as fp:\n",
    "    print('saving baseline prevalence map as json')\n",
    "    json.dump(baseline_prevalence_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cohort item counts - Primary care (PC) and Specialty care (SC)\n",
    "\n",
    "table_list =  [('measurement','measurement_concept_id'),\n",
    "                 ('procedure','procedure_concept_id'),\n",
    "                 ('drug','drug_concept_id'),\n",
    "                 ('condition','condition_concept_id'),\n",
    "                 ]\n",
    "\n",
    "cohorts = [('PC','NOT'),\n",
    "            ('SC','')]\n",
    "\n",
    "for c in cohorts:\n",
    "    (cohort_suffix, cohort_str) = c \n",
    "    feature_dict = {'cohort_str': cohort_str}\n",
    "\n",
    "    for t in table_list:\n",
    "        (table, concept_id) = t\n",
    "        feature_dict.update({'table': table,\n",
    "                     'concept_id': concept_id})\n",
    "    \n",
    "        feature_dict.update(format_map_dict)\n",
    "\n",
    "        sql = \"\"\"\n",
    "        WITH item AS \n",
    "            (SELECT \n",
    "               {concept_id} as item_concept_id,\n",
    "               COUNT(DISTINCT(person_id)) as num_pt, \n",
    "               COUNT(DISTINCT(visit_id)) as num_visit,\n",
    "               COUNT(*) as instance\n",
    "\n",
    "        FROM  `{save_project_id}.{save_dataset_id}.{prefix}_{table}` item\n",
    "\n",
    "        WHERE item.visit_id {cohort_str} IN \n",
    "                    (SELECT Specialty_visit_id \n",
    "                     FROM `{save_project_id}.{save_dataset_id}.{table_id_cohort}`)\n",
    "        GROUP BY \n",
    "            {concept_id})\n",
    "\n",
    "        SELECT \n",
    "            n.*, c.concept_name \n",
    "        FROM \n",
    "            item n \n",
    "        LEFT JOIN \n",
    "            `{project_id}.{dataset_id}.concept` c\n",
    "        ON\n",
    "            n.item_concept_id = c.concept_id\n",
    "        ORDER BY \n",
    "            num_pt DESC, num_visit DESC, instance DESC\n",
    "        \"\"\".format_map(feature_dict)\n",
    "    \n",
    "        save_table_id = prefix + \"_count_\" + table + \"_\" + cohort_suffix + \"_Cohort\"\n",
    "        table_str = save_project_id + '.' + save_dataset_id + '.' + save_table_id\n",
    "        save_query_table(sql, table_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get relative risk of items based on how likely it will appear in the cohort  \n",
    "\n",
    "def getItemRR(category, mode = 'PC', writeFile = False):\n",
    "    \n",
    "    item_Cohort = read_BQ(table_id = prefix + '_count_'+ category +'_' + mode + '_Cohort')\n",
    "    item_NonCohort = read_BQ(table_id = prefix + '_count_'+ category +'_NonCohort')\n",
    "\n",
    "    \n",
    "    N_noncohort = N_All - N_cohort\n",
    "        \n",
    "    # calculate Fisher Negative Log p-value and relative risk in the Cohort \n",
    "    fisherMap = {}\n",
    "    fisherList = []\n",
    "    for index, row in item_Cohort.iterrows():\n",
    "        concept_id = row[\"item_concept_id\"]\n",
    "        pt_cohort = row[\"num_pt\"]\n",
    "        concept_name = row[\"concept_name\"]\n",
    "        if concept_id in item_NonCohort[\"item_concept_id\"].values:\n",
    "            pt_noncohort = item_NonCohort.loc[item_NonCohort[\"item_concept_id\"] == concept_id,\"num_pt\"].iloc[0]\n",
    "        else:\n",
    "            pt_noncohort = 0\n",
    "\n",
    "        nAB = pt_cohort \n",
    "        nA = N_cohort\n",
    "        nB = pt_cohort + pt_noncohort \n",
    "        N = N_cohort + N_noncohort \n",
    "\n",
    "        s = getStats(nAB = nAB, nA = nA, nB = nB, N = N)\n",
    "        s.normalize()\n",
    "        rr = s.calc('rr')\n",
    "        neglogP = s.calc('fisher_neglog')\n",
    "        if concept_id != 0:\n",
    "            fisherMap[concept_id] = (neglogP, rr)\n",
    "            fisherList.append([concept_id, concept_name, neglogP, rr])\n",
    "    \n",
    "    if writeFile:\n",
    "        with open(JSON_FILE_PATH + '/' + category + '_rrMap_Cohort' + mode + '.json', 'w') as fp:\n",
    "             json.dump(fisherMap, fp)\n",
    "        \n",
    "    return pd.DataFrame(fisherList, columns=[\"concept_id\",\"name\",\"neglogP\",\"rr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_list =  ['measurement','procedure','drug','condition']\n",
    "DFlist = []\n",
    "for c in category_list:\n",
    "    DFlist.append(getItemRR(c, writeFile=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
