{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmically Assign Abx To CSNs based on Model Predictions\n",
    "## Include patients who are phenotyped as not infected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pulp import *\n",
    "import os, glob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/conorcorbin/.config/gcloud/application_default_credentials.json' \n",
    "os.environ['GCLOUD_PROJECT'] = 'som-nero-phi-jonc101' \n",
    "%load_ext google.cloud.bigquery\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client=bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Predictions Data For Each Abx Option\n",
    "\n",
    "Predictions of coverage for each antibiotic selection are stored in csv files using the following directory schema.  This function reads in predictions for each classifier so that each row is CSN and has an estimated probability of coverage for each antibiotic selection.  We implement a test function that compute the AUROC of each model after the predictions have been read in and cross checks it with the AUROC that was computed and stored in an `auroc.txt` text file during the model training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test_load_predictions(df):\n",
    "    \"\"\"\n",
    "    Reads in output of df, computes AUROC for each classifier and asserts that it equals the AUROC\n",
    "    listed in the auroc.txt file associate with the classfier's directory\n",
    "    \"\"\"\n",
    "    base_path=\"/Users/conorcorbin/repos/er_infection/results/ast_models_w_not_infected/testing/{abx}\"\n",
    "    abx_options = [\"Vancomycin\",\n",
    "               \"Ampicillin\",\n",
    "               \"Cefazolin\",\n",
    "               \"Ceftriaxone\",\n",
    "               \"Cefepime\",\n",
    "               \"Zosyn\",\n",
    "               \"Ciprofloxacin\",\n",
    "               \"Meropenem\",\n",
    "               \"Vancomycin_Meropenem\",\n",
    "               \"Vancomycin_Zosyn\",\n",
    "               \"Vancomycin_Cefepime\",\n",
    "               \"Vancomycin_Ceftriaxone\"\n",
    "               ]\n",
    "    for abx in abx_options:\n",
    "        path = base_path.format(abx=abx)\n",
    "        f_auroc = os.path.join(path, 'auroc.txt')\n",
    "        with open(f_auroc, 'r') as f:\n",
    "            auroc = round(float(f.read()), 3)\n",
    "        \n",
    "        computed_auroc = round(roc_auc_score(df['%s_label' % abx], df['%s_predictions' % abx]), 3)\n",
    "        \n",
    "        assert auroc == computed_auroc\n",
    "        print(\"%s_auroc: %s\"% (abx, str(auroc)))\n",
    "\n",
    "def load_predictions():\n",
    "    \"\"\"Helper function that loads predictions from AST classifiers for test set data\"\"\"\n",
    "    \n",
    "    base_path=\"/Users/conorcorbin/repos/er_infection/results/ast_models_w_not_infected/testing/{abx}\"\n",
    "    abx_options = [\"Vancomycin\",\n",
    "                   \"Ampicillin\",\n",
    "                   \"Cefazolin\",\n",
    "                   \"Ceftriaxone\",\n",
    "                   \"Cefepime\",\n",
    "                   \"Zosyn\",\n",
    "                   \"Ciprofloxacin\",\n",
    "                   \"Meropenem\",\n",
    "                   \"Vancomycin_Meropenem\",\n",
    "                   \"Vancomycin_Zosyn\",\n",
    "                   \"Vancomycin_Cefepime\",\n",
    "                   \"Vancomycin_Ceftriaxone\"\n",
    "                   ]\n",
    "    df = pd.DataFrame()\n",
    "    for i, abx in enumerate(abx_options):\n",
    "        path = base_path.format(abx=abx)\n",
    "        f_path = glob.glob(os.path.join(path, '*predictions.csv'))[0]\n",
    "        if i == 0:\n",
    "            df = pd.read_csv(f_path)\n",
    "            df = df[['anon_id', 'pat_enc_csn_id_coded', 'label', 'predictions']]\n",
    "            df = df.rename(columns={'label' : '%s_label' % abx,\n",
    "                                    'predictions' : '%s_predictions' % abx})\n",
    "        else:\n",
    "            df_preds = pd.read_csv(f_path)\n",
    "            df_preds = df_preds[['anon_id', 'pat_enc_csn_id_coded', 'label', 'predictions']]\n",
    "            df_preds = df_preds.rename(columns={'label' : '%s_label' % abx,\n",
    "                                                'predictions' : '%s_predictions' % abx})\n",
    "            df = df.merge(df_preds, how='left', on=['anon_id', 'pat_enc_csn_id_coded'])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = load_predictions()\n",
    "test_load_predictions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityEstimator(LogisticRegression):\n",
    "    def __init__(self):\n",
    "        LogisticRegression.__init__(self)\n",
    "            \n",
    "    def predict_proba(self, input_array):   \n",
    "        return input_array*1\n",
    "\n",
    "    def decision_function(self, input_array):\n",
    "        return input_array*1\n",
    "\n",
    "def calibrate_probabilities(predictions, labels):\n",
    "    \"\"\" \n",
    "    Takes in test set probabilites and does a k-fold cross fitting procedure to recalibrate each model\n",
    "    \"\"\"\n",
    "    est = IdentityEstimator()\n",
    "    X = predictions.values.reshape(-1, 1)\n",
    "    y = labels\n",
    "    isotonic_calibrated_predictions = np.array([float(i) for i in range(len(y))])\n",
    "    sigmoid_calibrated_predictions = np.array([float(i) for i in range(len(y))])\n",
    "\n",
    "    # Fit base estimator\n",
    "    est.fit(X, y) # because we've overloaded predict_proba and decision function this doesn't matter\n",
    "\n",
    "    # Calibrated with isotonic calibration\n",
    "    isotonic = CalibratedClassifierCV(est, cv='prefit', method='isotonic')\n",
    "\n",
    "    # Calibrated with sigmoid calibration\n",
    "    sigmoid = CalibratedClassifierCV(est, cv='prefit', method='sigmoid')\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    for train_inds, val_inds in cv.split(X, y):\n",
    "        X_train, y_train = X[train_inds], y[train_inds]\n",
    "        X_val, y_val = X[val_inds], y[val_inds]\n",
    "        isotonic.fit(X_train, y_train)\n",
    "        isotonic_predictions = isotonic.predict_proba(X_val)\n",
    "        isotonic_calibrated_predictions[val_inds] = isotonic_predictions[:, 1]\n",
    "\n",
    "        sigmoid.fit(X_train, y_train)\n",
    "        sigmoid_predictions = sigmoid.predict_proba(X_val)\n",
    "        sigmoid_calibrated_predictions[val_inds] = sigmoid_predictions[:, 1]\n",
    "\n",
    "    \n",
    "    return sigmoid_calibrated_predictions, isotonic_calibrated_predictions\n",
    "\n",
    "abx_options = [\"Vancomycin\",\n",
    "               \"Ampicillin\",\n",
    "               \"Cefazolin\",\n",
    "               \"Ceftriaxone\",\n",
    "               \"Cefepime\",\n",
    "               \"Zosyn\",\n",
    "               \"Ciprofloxacin\",\n",
    "               \"Meropenem\",\n",
    "               \"Vancomycin_Meropenem\",\n",
    "               \"Vancomycin_Zosyn\",\n",
    "               \"Vancomycin_Cefepime\",\n",
    "               \"Vancomycin_Ceftriaxone\"\n",
    "               ]\n",
    "\n",
    "for abx in abx_options:\n",
    "    predictions = df['%s_predictions' % abx]\n",
    "    labels = df['%s_label' % abx]\n",
    "    s_preds, i_preds = calibrate_probabilities(predictions, labels)\n",
    "    df['%s_predictions_sigmoid' % abx] = s_preds\n",
    "    df['%s_predictions_isotonic' % abx] = i_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check AUROCS\n",
    "for abx in abx_options:\n",
    "    auc = roc_auc_score(df['%s_label' % abx], df['%s_predictions' % abx])\n",
    "    auc_s = roc_auc_score(df['%s_label' % abx], df['%s_predictions_sigmoid' % abx])\n",
    "    auc_i = roc_auc_score(df['%s_label' % abx], df['%s_predictions_isotonic' % abx])\n",
    "    console_str = \"{} AUC Uncalibrated:{:.2f} AUC Sigmoid Calibrated:{:.2f} AUC Isotonic Calibrated:{:.2f}\"\n",
    "    print(console_str.format(abx, auc, auc_s, auc_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Calibration Curves\n",
    "def plot_calibration_curves(df, abx, ax):\n",
    "\n",
    "    prob_pos = df['%s_predictions' % abx]\n",
    "    labels = df['%s_label' % abx]\n",
    "    clf_score = brier_score_loss(labels, prob_pos)\n",
    "    print(\"\\tBrier Uncalibrated: %1.5f\" % (clf_score))\n",
    "\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(labels, prob_pos, n_bins=10)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    ax.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "            label=\"%s (%1.5f)\" % ('Uncalibrated', clf_score))\n",
    "        \n",
    "    # Sigmoid \n",
    "    clf_score = brier_score_loss(labels, df['%s_predictions_sigmoid'% abx])\n",
    "    print(\"\\t Sigmoid Brier: %1.5f\" % (clf_score))\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(labels, df['%s_predictions_sigmoid'% abx], n_bins=10)\n",
    "    ax.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "            label=\"%s (%1.5f)\" % ('Sigmoid', clf_score))\n",
    "    \n",
    "    \n",
    "    # Isotonic curve\n",
    "    clf_score = brier_score_loss(labels, df['%s_predictions_isotonic'% abx])\n",
    "    print(\"\\t Isotonic Brier: %1.5f\" % (clf_score))\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(labels, df['%s_predictions_isotonic'% abx], n_bins=10)\n",
    "    ax.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "            label=\"%s (%1.5f)\" % ('Isotonic', clf_score))\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_title(abx)\n",
    "    ax.set_xlabel('Estimated Probability')\n",
    "    ax.set_ylabel(\"Fraction of positives\")\n",
    "\n",
    "fig, ax = plt.subplots(4, 3, figsize=(24, 32))\n",
    "sns.set(font_scale=1.5)\n",
    "row, col = 0, 0\n",
    "for abx in abx_options:\n",
    "    plot_calibration_curves(df, abx, ax[row, col])\n",
    "    \n",
    "    if col == 2:\n",
    "        col = 0\n",
    "        row += 1\n",
    "    else:\n",
    "        col += 1 \n",
    "    \n",
    "plt.show        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get clinician prescribing patterns\n",
    "This SQL query gathers all abx medications ordered within the first 24 hours of admission that were administered to the patient in long format ( one row per administered med_description ) and then joins to our labels table so that we can cross check whether the administered antibiotic was sufficient to cover the patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH adm_abx AS (\n",
    "    SELECT\n",
    "        om.anon_id, om.pat_enc_csn_id_coded, om.order_med_id_coded,\n",
    "        om.med_description, om.order_time\n",
    "    FROM\n",
    "        `mining-clinical-decisions.abx.abx_orders_given_and_stopped` om\n",
    "    WHERE\n",
    "        om.was_given = 1\n",
    "), \n",
    "not_infected as (\n",
    "    SELECT \n",
    "        anon_id, pat_enc_csn_id_coded, index_time,\n",
    "        CASE WHEN abx_stopped_2_days = 1\n",
    "        AND not_discharged_with_orals = 1\n",
    "        AND no_pos_cult_2_weeks_later = 1\n",
    "        AND no_pos_cult_within_day = 1\n",
    "        AND no_inf_dx_codes = 1\n",
    "        THEN 1 ELSE 0 END not_infected\n",
    "    FROM \n",
    "        `mining-clinical-decisions.abx.cohort_not_infected_rules`\n",
    ")\n",
    "SELECT \n",
    "    not_infected.not_infected, om.med_description, om.order_med_id_coded, l.*\n",
    "FROM \n",
    "    adm_abx om\n",
    "RIGHT JOIN \n",
    "    `mining-clinical-decisions.abx.final_cohort_table` l\n",
    "USING\n",
    "    (pat_enc_csn_id_coded)\n",
    "INNER JOIN \n",
    "    not_infected \n",
    "USING \n",
    "    (pat_enc_csn_id_coded)\n",
    "WHERE \n",
    "    l.label_unobserved = 0\n",
    "ORDER BY \n",
    "    anon_id, l.pat_enc_csn_id_coded, om.order_time\n",
    "\"\"\"\n",
    "query_job = client.query(query)\n",
    "df_abx = query_job.result().to_dataframe()\n",
    "df_abx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abx[df_abx['med_description'].isna()]\n",
    "df_abx['med_description'] = df_abx['med_description'].fillna('No Abx Administered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate antibiotic orders \n",
    "Here we aggregate the antibiotic orders so that one row in the desulting dataframe corresponds to a unique CSN. We do this by\n",
    "1. Grouping by the CSN\n",
    "2. Grabbing the first word (antibiotic name) from the med description\n",
    "3. Aggregating the `med_description` column such that it is a single string with all antibiotics admistered to the patient, sorted in alphabetical order and separated by spaces. \n",
    "4. Only keep CSNs where the set of administered antibiotics is equal to one of the antbiotic selections we've trained classifiers for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful dictionaries to map corresponding. strings for the sameantibiotic selections\n",
    "abx_map = {'Ceftriaxone' : \"CEFTRIAXONE\",\n",
    "           'Vancomycin_Zosyn' : \"PIPERACILLIN-TAZOBACTAM VANCOMYCIN\",\n",
    "           'Zosyn' : \"PIPERACILLIN-TAZOBACTAM\",\n",
    "           'Vancomycin_Ceftriaxone' : \"CEFTRIAXONE VANCOMYCIN\",\n",
    "           'Vancomycin_Cefepime' : \"CEFEPIME VANCOMYCIN\",\n",
    "           'Cefepime' : \"CEFEPIME\",\n",
    "           'Vancomycin' :  \"VANCOMYCIN\",\n",
    "           'Meropenem' : \"MEROPENEM\",\n",
    "           'Vancomycin_Meropenem' : \"MEROPENEM VANCOMYCIN\",\n",
    "           'Cefazolin' : \"CEFAZOLIN\",\n",
    "           'Ciprofloxacin' : \"CIPROFLOXACIN\",\n",
    "           'Ampicillin' : 'AMPICILLIN'\n",
    "           #'No Abx' : 'No Abx Administered'\n",
    "          }\n",
    "abx_map_inverse = {abx_map[key] : key for key in abx_map}\n",
    "\n",
    "# Lambda that aggregate Antibiotic orders after we've grouped by CSN\n",
    "concat_abx = lambda x : ' '.join(np.unique(sorted([a for a in x])))\n",
    "\n",
    "# \n",
    "df_drugs = (df_abx\n",
    "    .assign(med_description=lambda x: [a.split(' ')[0] for a in x.med_description]) # Only Take first word (abx)\n",
    "    .assign(med_description=lambda x: [(a.replace('PIPERACILLIN-TAZOBACTAM-DEXTRS','PIPERACILLIN-TAZOBACTAM')\n",
    "                                        .replace('VANCOMYCIN-WATER', 'VANCOMYCIN'))\n",
    "                                       for a in x.med_description])\n",
    "    .assign(year=lambda x: x.index_time.dt.year) # get year of each CSN - used to filter later on\n",
    "    .groupby('pat_enc_csn_id_coded')\n",
    "    .agg({'med_description' : concat_abx,\n",
    "          'not_infected' : 'first',\n",
    "          'year' : 'first',\n",
    "          'Ampicillin' : 'first',\n",
    "          'Ciprofloxacin' : 'first',\n",
    "          'Cefazolin' : 'first',\n",
    "          'Ceftriaxone' : 'first',\n",
    "          'Cefepime' : 'first',\n",
    "          'Zosyn' : 'first',\n",
    "          'Vancomycin' : 'first',\n",
    "          'Meropenem' : 'first',\n",
    "          'Vancomycin_Ceftriaxone' : 'first',\n",
    "          'Vancomycin_Cefepime' : 'first',\n",
    "          'Vancomycin_Zosyn' : 'first',\n",
    "          'Vancomycin_Meropenem' : 'first'})\n",
    "    .reset_index()\n",
    "    # Only look at test set data and CSNs where allowed antibiotic selection was administered\n",
    "    .query(\"year == 2019 and med_description in @abx_map_inverse\", engine='python') \n",
    ")\n",
    "\n",
    "# Roughly 700 of the 1300 original CSNs in the test set\n",
    "print(len(df_drugs))\n",
    "df_drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge this dataframe to predictions dataframe\n",
    "After this step we should have a dataframe that has one row per CSN, each row should have the antibiotic selection actually administered to the patient, along with the predicted probability of said antibiotic selection covering the patient, and the ground truth as to whether it did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_total to df on pat_enc_csn_id_coded\n",
    "base_path=\"/Users/conorcorbin/repos/er_infection/results/ast_models_w_not_infected/testing/{abx}\"\n",
    "df_new = (df\n",
    "    .merge(df_drugs, how='inner', on='pat_enc_csn_id_coded')\n",
    ")\n",
    "\n",
    "# Sanity check - make sure %abx_label columns are equal to %abx columns\n",
    "for abx in abx_options:\n",
    "    for i in range(len(df_new)):\n",
    "        assert df_new[abx].values[i] == df_new['%s_label' % abx].values[i]\n",
    "        \n",
    "# Sanity check 2: compute AUROC of this subset of patients and compare to AUROC on full test set\n",
    "for abx in abx_options:\n",
    "    computed_auroc = roc_auc_score(df_new['%s_label' % abx], df_new['%s_predictions' % abx])\n",
    "    f_auroc = os.path.join(base_path.format(abx=abx), 'auroc.txt')\n",
    "    with open(f_auroc, 'r') as f:\n",
    "        auroc = float(f.read())\n",
    "    print(\"{}: Full test set AUROC:{:.3f} Subset AUROC:{:.3f}\".format(abx, auroc, computed_auroc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Binary Integer Programming Problem Formulation and Solve\n",
    "Here we specificy the problem formulation of the optimization process we wish to solve. The goal is to maximize the probability of covering the set of patients in the test set with the available antibiotic selections subject to the constraints that we assign each antibiotic selection a prespecified number of times, and that we only assign one antibiotic selection to each patient CSN. \n",
    "\n",
    "More technically, Let $N$ be the number of patient CSNs in our test set who were administered one of the 12 abx selections by clinicians, and let $K$ be the number of possible antibiotic selections.  Let $A$ be a matrix in $\\mathbb{R}^{N\\times K}$ such that $a_{ij}$ is 1 if antibiotic selection $j$ is selected for patient CSN $i$ and 0 otherwise. Let $\\Phi$ be a matrix in $\\mathbb{R}^{N \\times K}$ such that $\\phi_{ij}$ is the predicted probability that antibiotic $j$ will cover patient CSN $i$.  Let $C$ be a vector in $\\mathbb{R}^K$ such that $c_j$ specifies the budget for anitbiotic selection $j$ - that is the number of times we are allowed to select antibiotic $j$ across our $N$ patient CSNs. Our problem formulation is as follows. \n",
    "\n",
    "$$  \\underset{A}{\\text{maximize}} \\sum_{i=1}^{N} \\sum_{j=1}^K \\phi_{ij} a_{ij} $$\n",
    "\n",
    "Subject to the following constraints:\n",
    "\n",
    "$$ \\sum_{j=1}^{K} a_{ij} = 1 \\quad i = 1, ..., N $$\n",
    "\n",
    "$$ \\sum_{i=1}^{N} a_{ij} = c_j \\quad j = 1, ...,  K $$\n",
    "\n",
    "In the following code, we implenent and solve this optimization process using the pulp python package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clinician drug counts\n",
    "(df_drugs\n",
    "    .groupby('med_description')\n",
    "    .agg(num_csns=('pat_enc_csn_id_coded', 'nunique'))\n",
    "    .reset_index()\n",
    "    .sort_values('num_csns', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_model = LpProblem(\"Antibiotics\", LpMaximize)\n",
    "\n",
    "# Create binary indicators for whether treatment is used\n",
    "drug_inds = {}\n",
    "for abx in abx_options:\n",
    "    drug_inds[abx] = [LpVariable('%s_%d' % (abx, i), lowBound=0, upBound=1, cat='Binary')\n",
    "                      for i in range(len(df_new))]\n",
    "\n",
    "# Add objective function to model\n",
    "per_csn_sum = []\n",
    "for i in range(len(df_new)):\n",
    "    _sum = 0\n",
    "    for abx in abx_options:\n",
    "        _sum += drug_inds[abx][i] * df_new['%s_predictions_isotonic' % abx].values[i]\n",
    "    per_csn_sum.append(_sum)\n",
    "    \n",
    "abx_model += lpSum(per_csn_sum)\n",
    "\n",
    "# Add one selection constraint\n",
    "for i in range(len(df_new)):\n",
    "    selections = []\n",
    "    for abx in abx_options:\n",
    "        selections.append(drug_inds[abx][i])\n",
    "    abx_model += lpSum(selections) == 1\n",
    "\n",
    "# Add max assignment constraints\n",
    "# abx_assignment_constraints = {\"Vancomycin\" : 13,\n",
    "#                               \"Ampicillin\" : 0,\n",
    "#                               \"Cefazolin\" : 8,\n",
    "#                               \"Ceftriaxone\" : 367,\n",
    "#                               \"Cefepime\" : 14,\n",
    "#                               \"Zosyn\" : 102,\n",
    "#                               \"Ciprofloxacin\" : 8,\n",
    "#                               \"Meropenem\" : 9,\n",
    "#                               \"Vancomycin_Meropenem\" : 9,\n",
    "#                               \"Vancomycin_Zosyn\" :  113,\n",
    "#                               \"Vancomycin_Cefepime\" : 23,\n",
    "#                               \"Vancomycin_Ceftriaxone\" : 31\n",
    "#                              }\n",
    "\n",
    "abx_assignment_constraints = {\"Vancomycin\" : 20,\n",
    "                              \"Ampicillin\" : 54,\n",
    "                              \"Cefazolin\" : 22,\n",
    "                              \"Ceftriaxone\" : 462,\n",
    "                              \"Cefepime\" : 15,\n",
    "                              \"Zosyn\" : 100, # 154\n",
    "                              \"Ciprofloxacin\" : 12,\n",
    "                              \"Meropenem\" : 9,\n",
    "                              \"Vancomycin_Meropenem\" : 10,\n",
    "                              \"Vancomycin_Zosyn\" :  101,\n",
    "                              \"Vancomycin_Cefepime\" : 31,\n",
    "                              \"Vancomycin_Ceftriaxone\" : 38\n",
    "                             }\n",
    "\n",
    "for drug in drug_inds:\n",
    "    abx_model += lpSum([drug_inds[drug][i] for i in range(len(df_new))]) == abx_assignment_constraints[drug]\n",
    "\n",
    "# Solve model\n",
    "abx_model.solve()\n",
    "print(\"Status:\", LpStatus[abx_model.status])\n",
    "\n",
    "# Save selected antibiotic to df_new\n",
    "abx_decisions = []\n",
    "for i in range(len(df_new)):\n",
    "    abx_decision = None\n",
    "    for abx in abx_options:\n",
    "        if drug_inds[abx][i].value() == 1:\n",
    "            abx_decision = abx_map[abx]\n",
    "    assert abx_decision is not None\n",
    "    abx_decisions.append(abx_decision)\n",
    "df_new['IP_med_description'] = abx_decisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Performance to Clinician Performance\n",
    "1. Write a function that takes in antibiotic selection and outputs a 1 if that selection covered the patient.  Simple to do, but annoying because of different ways we've named antibiotic selections.\n",
    "2. Compute fraction of time each patient CSN was covered by the antibiotic selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ugly helper function that just does some string mapping\n",
    "def compute_was_covered(x, decision_column='med_description'):\n",
    "    \"\"\"\n",
    "    Given med description, find appropriate label column and return whether patient was covered during CSN\n",
    "    Returns \"Not in abx options\" if abx regimen isn't in our set of 12 options - useful for filtering later\n",
    "    \"\"\"\n",
    "    if decision_column == 'med_description':\n",
    "        med_description = x.med_description\n",
    "    elif decision_column == 'random_med_description':\n",
    "        med_description = x.random_med_description\n",
    "    elif decision_column == 'IP_med_description':\n",
    "        med_description = x.IP_med_description\n",
    "        \n",
    "    if med_description == \"CEFTRIAXONE\":\n",
    "        return x.Ceftriaxone\n",
    "    elif med_description == \"PIPERACILLIN-TAZOBACTAM VANCOMYCIN\":\n",
    "        return x.Vancomycin_Zosyn\n",
    "    elif med_description == \"PIPERACILLIN-TAZOBACTAM\":\n",
    "        return x.Zosyn\n",
    "    elif med_description == \"CEFTRIAXONE VANCOMYCIN\":\n",
    "        return x.Vancomycin_Ceftriaxone\n",
    "    elif med_description == \"CEFEPIME VANCOMYCIN\":\n",
    "        return x.Vancomycin_Cefepime\n",
    "    elif med_description == \"CEFEPIME\":\n",
    "        return x.Cefepime\n",
    "    elif med_description == \"VANCOMYCIN\":\n",
    "        return x.Vancomycin\n",
    "    elif med_description == \"MEROPENEM\":\n",
    "        return x.Meropenem\n",
    "    elif med_description == \"MEROPENEM VANCOMYCIN\":\n",
    "        return x.Vancomycin_Meropenem\n",
    "    elif med_description == \"CEFAZOLIN\":\n",
    "        return x.Cefazolin\n",
    "    elif med_description == \"CIPROFLOXACIN\":\n",
    "        return x.Ciprofloxacin\n",
    "    elif med_description == \"AMPICILLIN\":\n",
    "        return x.Ampicillin\n",
    "    else:\n",
    "        return \"Not in abx options\"\n",
    "\n",
    "    \n",
    "# Create flag for whether clinicians covered the patient during the csn, whether a random assignemnt covered patient\n",
    "# CSN, and whether optimized assignment covered the patient CSN.\n",
    "\n",
    "df_new = (df_new\n",
    "    .assign(random_med_description=lambda x: np.random.choice(x.med_description, size=len(x.med_description), replace=False))\n",
    ")\n",
    "df_new = (df_new\n",
    "    #.sample(frac=1.0, replace=True) # bootstrap each iteration\n",
    "    .assign(was_covered_dr=df_new.apply(lambda x: compute_was_covered(x), axis=1))\n",
    "    .assign(was_covered_random=df_new.apply(lambda x: compute_was_covered(x, \n",
    "                                                                          decision_column='random_med_description'),\n",
    "                                                                          axis=1))\n",
    "    .assign(was_covered_IP=df_new.apply(lambda x: compute_was_covered(x, \n",
    "                                                                      decision_column='IP_med_description'),\n",
    "                                                                      axis=1))\n",
    ")\n",
    "\n",
    "clin_covered_rate = df_new['was_covered_dr'].sum() / len(df_new)\n",
    "random_covered_rate = df_new['was_covered_random'].sum() / len(df_new)\n",
    "ip_covered_rate = df_new['was_covered_IP'].sum() / len(df_new)\n",
    "console_str = \"Random Coverage Rate:{:.4f} Clinician Coverage Rate:{:.4f} Integer Programming Coverage Rate:{:.4f}\"\n",
    "print(console_str.format(random_covered_rate, clin_covered_rate, ip_covered_rate))\n",
    "\n",
    "df_new_random = (df_new\n",
    "        .groupby('random_med_description')\n",
    "        .agg(num_distinct_csns=('pat_enc_csn_id_coded', 'count'),\n",
    "             num_times_covered_random=('was_covered_random', 'sum'))\n",
    "        .reset_index()\n",
    "        .assign(random_covered=lambda x: ['{}/{}'.format(c, t) for c, t in zip(x.num_times_covered_random,\n",
    "                                                                               x.num_distinct_csns)])\n",
    "        .rename(columns={'random_med_description' : 'med_description'})\n",
    ")[['med_description', 'random_covered']]\n",
    "                 \n",
    "df_new_clinician = (df_new\n",
    "        .groupby('med_description')\n",
    "        .agg(num_distinct_csns=('pat_enc_csn_id_coded', 'count'),\n",
    "             num_times_covered_dr=('was_covered_dr', 'sum'))\n",
    "        .reset_index()\n",
    "        .assign(dr_covered=lambda x: ['{}/{}'.format(c, t) for c, t in zip(x.num_times_covered_dr,\n",
    "                                                                               x.num_distinct_csns)])\n",
    ")[['med_description', 'dr_covered']]\n",
    "                    \n",
    "df_new_ip = (df_new\n",
    "        .groupby('IP_med_description')\n",
    "        .agg(num_distinct_csns=('pat_enc_csn_id_coded', 'count'),\n",
    "             num_times_covered_IP=('was_covered_IP', 'sum'))\n",
    "        .reset_index()\n",
    "        .assign(IP_covered=lambda x: ['{}/{}'.format(c, t) for c, t in zip(x.num_times_covered_IP,\n",
    "                                                                               x.num_distinct_csns)])\n",
    "        .rename(columns={'IP_med_description' : 'med_description'})\n",
    ")[['med_description', 'IP_covered']]\n",
    "\n",
    "df_new_agg = (df_new_random\n",
    "    .merge(df_new_clinician, how='outer', on='med_description')\n",
    "    .merge(df_new_ip, how='outer', on='med_description')\n",
    ")\n",
    "\n",
    "df_new_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note two big limitations here\n",
    "1. Performing a cross fitting procedure on test set to calibrate each classifier on test set \n",
    "2. Assuming we have access to the \"budget\" of antibiotics ahead of time.  Realistically this should be a one at a time problem. Would have to \"cross fit\" the abx selections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
