{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train $P(\\text{Label Observed} = 1 \\mid X=x)$ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.metrics import roc_curve, auc, average_precision_score, roc_auc_score, brier_score_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in feature matrix and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/conorcorbin/repos/er_infection/data/ast_models_c/'\n",
    "\n",
    "X_train = load_npz(os.path.join(data_dir, 'training_examples_round_test.npz'))\n",
    "df_y_train = pd.read_csv(os.path.join(data_dir, 'training_labels_round_test.csv'))\n",
    "y_train = df_y_train['label_unobserved']\n",
    "X_test = load_npz(os.path.join(data_dir, 'test_examples_round_test.npz'))\n",
    "df_y_test = pd.read_csv(os.path.join(data_dir, 'test_labels_round_test.csv'))\n",
    "y_test = df_y_test['label_unobserved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict_proba(X_test)[:, 0] # want probability of observing the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test['label'] = 1-y_test # so that now label is probability of observing the label\n",
    "df_y_test['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/Users/conorcorbin/repos/er_infection/data/results/ast_models_c/'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "df_y_test.to_csv(os.path.join(results_dir, 'yhats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "auc = roc_auc_score(df_y_test['label'], df_y_test['predictions'])\n",
    "sns.set(font_scale=1.5)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "for label in np.unique(df_y_test['label']): \n",
    "    if label == 1:\n",
    "        lab = \"Labels Observed\"\n",
    "    else:\n",
    "        lab = \"Labels Unobserved\"\n",
    "    sns.distplot(df_y_test[df_y_test['label'] == label]['predictions'],\n",
    "                 label=lab,\n",
    "                 ax=ax)\n",
    "ax.set_title(\"Observing labels classifier AUROC: {:.2f}\".format(auc))\n",
    "ax.set_xlabel(\"Estimated Probability of Observing Label\")\n",
    "ax.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityEstimator(LogisticRegression):\n",
    "    def __init__(self):\n",
    "        LogisticRegression.__init__(self)\n",
    "            \n",
    "    def predict_proba(self, input_array):   \n",
    "        return input_array*1\n",
    "\n",
    "    def decision_function(self, input_array):\n",
    "        return input_array*1\n",
    "    \n",
    "def calibrate_probabilities(predictions, labels):\n",
    "    \"\"\" \n",
    "    Takes in test set probabilites and does a k-fold cross fitting procedure to recalibrate each model\n",
    "    \"\"\"\n",
    "    est = IdentityEstimator()\n",
    "    X = predictions.values.reshape(-1, 1)\n",
    "    y = labels\n",
    "    isotonic_calibrated_predictions = np.array([float(i) for i in range(len(y))])\n",
    "    sigmoid_calibrated_predictions = np.array([float(i) for i in range(len(y))])\n",
    "\n",
    "    # Fit base estimator\n",
    "    est.fit(X, y) # because we've overloaded predict_proba and decision function this doesn't matter\n",
    "\n",
    "    # Calibrated with isotonic calibration\n",
    "    isotonic = CalibratedClassifierCV(est, cv='prefit', method='isotonic')\n",
    "\n",
    "    # Calibrated with sigmoid calibration\n",
    "    sigmoid = CalibratedClassifierCV(est, cv='prefit', method='sigmoid')\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    for train_inds, val_inds in cv.split(X, y):\n",
    "        X_train, y_train = X[train_inds], y[train_inds]\n",
    "        X_val, y_val = X[val_inds], y[val_inds]\n",
    "        isotonic.fit(X_train, y_train)\n",
    "        isotonic_predictions = isotonic.predict_proba(X_val)\n",
    "        isotonic_calibrated_predictions[val_inds] = isotonic_predictions[:, 1]\n",
    "\n",
    "        sigmoid.fit(X_train, y_train)\n",
    "        sigmoid_predictions = sigmoid.predict_proba(X_val)\n",
    "        sigmoid_calibrated_predictions[val_inds] = sigmoid_predictions[:, 1]\n",
    "\n",
    "    \n",
    "    return sigmoid_calibrated_predictions, isotonic_calibrated_predictions\n",
    "\n",
    "def plot_calibration_curves():\n",
    "\n",
    "    sns.set(font_scale=1.5)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    prob_pos = df_y_test['predictions']\n",
    "    labels = df_y_test['label']\n",
    "    clf_score = brier_score_loss(labels, prob_pos)\n",
    "    print(\"\\tBrier: %1.3f\" % (clf_score))\n",
    "\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(labels, prob_pos, n_bins=10)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    ax.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "            label=\"%s (%1.3f)\" % ('Uncalibrated', clf_score))\n",
    "    \n",
    "    # Now calibrate\n",
    "    s_predictions, i_predictions = calibrate_probabilities(prob_pos, labels)\n",
    "    \n",
    "    # Sigmoid curve\n",
    "    clf_score = brier_score_loss(labels, s_predictions)\n",
    "    print(\"\\t Sigmoid Brier: %1.3f\" % (clf_score))\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(labels, s_predictions, n_bins=10)\n",
    "    ax.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "            label=\"%s (%1.3f)\" % ('Sigmoid', clf_score))\n",
    "    \n",
    "    \n",
    "    # Isotonic curve\n",
    "    clf_score = brier_score_loss(labels, i_predictions)\n",
    "    print(\"\\t Isotonic Brier: %1.3f\" % (clf_score))\n",
    "    fraction_of_positives, mean_predicted_value = \\\n",
    "        calibration_curve(labels, i_predictions, n_bins=10)\n",
    "    ax.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "            label=\"%s (%1.3f)\" % ('Isotonic', clf_score))\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Estimated Probability')\n",
    "    ax.set_ylabel(\"Fraction of positives\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
