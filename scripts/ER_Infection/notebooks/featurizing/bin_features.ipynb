{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "from google.cloud import bigquery\n",
    "from tqdm import tqdm\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/ccorbin/.config/gcloud/application_default_credentials.json' \n",
    "os.environ['GCLOUD_PROJECT'] = 'som-nero-phi-jonc101' \n",
    "\n",
    "client=bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bq_to_pandas(query, nrows, chunksize=500000):\n",
    "    offsets = [i for i in range(0, nrows, chunksize)]\n",
    "    df = pd.DataFrame()\n",
    "    for offset in tqdm(offsets):\n",
    "        query_str = query + \" LIMIT {chunksize} OFFSET {offset}\"\n",
    "        query_str = query_str.format(chunksize=chunksize, offset=offset)\n",
    "        query_job = client.query(query_str)\n",
    "        df_slice = query_job.result().to_dataframe()\n",
    "        df = pd.concat([df, df_slice])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    *\n",
    "FROM \n",
    "    `mining-clinical-decisions.abx.feature_timeline_long` \n",
    "WHERE \n",
    "    feature_type IN (\"Lab Results\", \"Flowsheet\")\n",
    "AND \n",
    "    TIMESTAMP_ADD(observation_time, INTERVAL 14*24 HOUR) > index_time \n",
    "ORDER BY\n",
    "    obs_num\n",
    "\"\"\"\n",
    "\n",
    "df = read_bq_to_pandas(query, nrows=2337767, chunksize=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(look_up_table):\n",
    "    \"\"\"Converts df look up table to dictionary for faster look up later\"\"\"\n",
    "    bin_val_dict = {}\n",
    "    for feature in look_up_table['features'].unique():\n",
    "        feature_bin_vals = look_up_table[look_up_table['features'] == feature]\n",
    "        for _bin in feature_bin_vals['bins'].unique():\n",
    "            if feature not in bin_val_dict:\n",
    "                bin_val_dict[feature] = {}\n",
    "                bin_val_dict[feature]['min'] = []\n",
    "                bin_val_dict[feature]['max'] = []\n",
    "\n",
    "            min_val_for_bin = feature_bin_vals[feature_bin_vals['bins'] == _bin]['value']['min'].values[0]\n",
    "            max_val_for_bin = feature_bin_vals[feature_bin_vals['bins'] == _bin]['value']['max'].values[0]\n",
    "\n",
    "            bin_val_dict[feature]['min'].append(min_val_for_bin)\n",
    "            bin_val_dict[feature]['max'].append(max_val_for_bin)\n",
    "    return bin_val_dict\n",
    "\n",
    "    \n",
    "def train_featurizer(df_train):\n",
    "    \"\"\"\n",
    "    Compute percent_ranks and generates a look up table of min and max bin values\n",
    "    Input : long form dataframe with features and value where value are the continuous values of labs / vitals\n",
    "    Output: look up table - dict of dict of lists (key1 = feature_name, key2 = max or min, values = lists of values)\n",
    "    \"\"\"\n",
    "    # Compute percentiles and bins\n",
    "    df_train['percentiles'] = df_train.groupby('features')['value'].transform(lambda x: x.rank(pct=True))\n",
    "    df_train['bins'] = df_train['percentiles'].apply(lambda x: int(x * 10))\n",
    "    \n",
    "    # Generate look up table and conver to dictionary stucture\n",
    "    look_up_table_df = df_train.groupby(['features', 'bins']).agg({'value' : ['min', 'max']}).reset_index()\n",
    "    look_up_table = convert_to_dict(look_up_table_df)\n",
    "    \n",
    "    ### Sanity Check. Ensure that min vector for each feature is strictly increasing (no ties!)\n",
    "    # Should be the case because ties are given same percentile rank in default pandas rank function\n",
    "    for feature in look_up_table:\n",
    "        mins = look_up_table[feature]['min']\n",
    "        for i in range(len(mins)-1):\n",
    "            assert mins[i] < mins[i+1]\n",
    "    \n",
    "    return look_up_table\n",
    "\n",
    "\n",
    "def apply_featurizer(df, look_up_table):\n",
    "    \n",
    "    def get_appropriate_bin(feature, value, look_up_table):\n",
    "        \"\"\"Takes in feature, value and look up table and returns appropriate bin\n",
    "\n",
    "        Quick Note: For some features, we do not have 10 bins.  This happens when we have many many ties in the \n",
    "        percent rank - and the percent rank alg returns ties as the average rank within that tie. So for instance\n",
    "        we're trying to break each feature up into deciles where each bin covers range of 10% of the examples. But if more\n",
    "        than 10% of the examples take on 1 value - then bins can be skipped. This shouldn't really be a problem\n",
    "        for downstream tasks - just something to be aware of. This also means 'bins' and 'bins_applied' won't have\n",
    "        perfect overlap in features that end up having less than 10 bins\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mins = look_up_table[feature]['min']\n",
    "        except: # Feature not found in training set\n",
    "            return 0 # return 0th bin - this will get removed as a feature in downstream processing\n",
    "        for i in range(len(mins) - 1):\n",
    "            # If value is smaller than min value of smallest bin (in test time) - then return 0 (smallest bin)\n",
    "            if i == 0 and value < mins[i]:\n",
    "                return i\n",
    "\n",
    "            if value >= mins[i] and value < mins[i+1] :\n",
    "                return i\n",
    "\n",
    "        # Then in last bin\n",
    "        return len(mins)-1\n",
    "    \n",
    "    df['bins_applied'] = df[['features', 'value']].apply(\n",
    "        lambda x: get_appropriate_bin(x['features'], x['value'], look_up_table), axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment by validation split time\n",
    "df_train = df[df['index_time'] < '2018-01-01']\n",
    "\n",
    "# Train featurizer\n",
    "look_up_table = train_featurizer(df_train)\n",
    "\n",
    "# Apply featurizer\n",
    "df_featurized = apply_featurizer(df, look_up_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featurized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check in leui of test code for now\n",
    "df_train = apply_featurizer(df_train, look_up_table)\n",
    "look_up_table_df = df_train.groupby(['features', 'bins']).agg({'value' : ['min', 'max']}).reset_index()\n",
    "\n",
    "features_with_0_9_bins = []\n",
    "for feature in look_up_table_df:\n",
    "    num_bins = len(look_up_table_df[look_up_table_df['features'] == feature]['bins'].values)\n",
    "    ten_in_bins = 10 in look_up_table_df[look_up_table_df['features'] == feature]['bins'].values\n",
    "    if num_bins == 10 and not ten_in_bins:\n",
    "        features_with_0_9_bins.append(feature)\n",
    "\n",
    "for feature in features_with_0_9_bins:\n",
    "    df_test = df_train[df_train['features'] == 'feature']\n",
    "    for b_real, b_computed in zip(df_test['bins'].values, df_test['bins_applied'].values):\n",
    "        assert(b_real == b_computed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# House Cleaning\n",
    "columns = ['obs_num', 'anon_id', 'pat_enc_csn_id_coded', 'index_time', 'observation_time', 'feature_type', 'features', 'value', 'bins_applied']\n",
    "df_new = df_featurized[columns]\n",
    "\n",
    "# New feature names\n",
    "df_new['features'] = ['_'.join([x, str(y)]) for x, y in zip(df_new['features'].values, df_new['bins_applied'].values)] \n",
    "df_new['feature_type'] = [x + '_train' for x in df_new['feature_type'].values]\n",
    "df_new['value'] = [None for x in df_new['value'].values] \n",
    "\n",
    "# df_new.to_csv('lab_results_vitals_binned.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['order_id'] = [x for x in df_new['obs_num'].values]\n",
    "columns = ['obs_num', 'anon_id', 'pat_enc_csn_id_coded', 'index_time', 'order_id', 'feature_type', 'features', 'value', 'observation_time']\n",
    "df_new[columns].to_csv('binned_labs_vitals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[columns].to_csv('binned_labs_vitals.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
