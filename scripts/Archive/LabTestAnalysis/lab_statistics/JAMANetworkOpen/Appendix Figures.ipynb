{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.LabTestAnalysis.machine_learning.LabNormalityPredictionPipeline \\\n",
    "        import NON_PANEL_TESTS_WITH_GT_500_ORDERS\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import stats_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from medinfo.ml.SupervisedClassifier import SupervisedClassifier\n",
    "\n",
    "all_algs = SupervisedClassifier.SUPPORTED_ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_label=\"all_labs\"\n",
    "targeted_PPV=0.95\n",
    "scale_by='enc'\n",
    "use_cached_fig_data=True\n",
    "inverse01=True\n",
    "\n",
    "data_source = 'UCSF'\n",
    "lab_type = 'panel'\n",
    "curr_version = '10000-episodes-lastnormal'\n",
    "\n",
    "all_labs = stats_utils.get_all_labs(data_source, lab_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_folderpath = os.path.join(stats_utils.main_folder, 'lab_statistics/')\n",
    "ml_folderpath = os.path.join(stats_utils.main_folder, 'machine_learning')\n",
    "\n",
    "import LocalEnv\n",
    "statsByDataSet_foldername = 'data-%s-%s-%s' % (data_source, lab_type, curr_version)\n",
    "statsByDataSet_folderpath = os.path.join(stats_folderpath, statsByDataSet_foldername)\n",
    "\n",
    "dataset_foldername = 'data-%s-%s-%s'%(data_source, lab_type, curr_version)\n",
    "labStats_folderpath = os.path.join(LocalEnv.PATH_TO_CDSS, 'scripts/LabTestAnalysis/lab_statistics')\n",
    "statsByLab_folderpath = os.path.join(labStats_folderpath, dataset_foldername)\n",
    "ml_folderpath = statsByLab_folderpath.replace(\"lab_statistics\", \"machine_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stats_utils)\n",
    "def draw__stats_Curves(statsByLab_folderpath, labs, curve_type=\"ROC\", algs=['random-forest'], result_label=None,\n",
    "                       include_baseline=True, inverse01=False):\n",
    "    result_foldername = 'Fig_stats_Curves'\n",
    "    if result_label:\n",
    "        result_foldername += '_' + result_label\n",
    "    result_folderpath = os.path.join(statsByLab_folderpath, result_foldername)\n",
    "    if not os.path.exists(result_folderpath):\n",
    "        os.mkdir(result_folderpath)\n",
    "\n",
    "    result_figname = '%s_%s_%s.png'%(data_source, lab_type, curve_type)\n",
    "    result_figpath = os.path.join(result_folderpath, result_figname)\n",
    "\n",
    "    result_tablename = '%s_%s_%s.csv'%(data_source, lab_type, curve_type)\n",
    "    result_tablepath = os.path.join(result_folderpath, result_tablename)\n",
    "\n",
    "    num_labs = len(labs)\n",
    "    # fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    if lab_type == 'component':\n",
    "        col_num=5\n",
    "    else:\n",
    "        col_num=7\n",
    "\n",
    "    row, col, i_s, j_s = stats_utils.prepare_subfigs(num_labs, col=5) #7\n",
    "\n",
    "    scores_base = []\n",
    "    scores_best = []\n",
    "    p_vals = []\n",
    "\n",
    "    scores_diffs = {}\n",
    "\n",
    "    lab_descriptions = stats_utils.get_lab_descriptions(lab_type=lab_type,\n",
    "                                                        data_source=data_source,\n",
    "                                                        line_break_at=18)\n",
    "    for ind, lab in enumerate(labs):\n",
    "\n",
    "        '''\n",
    "        Getting p-values is slow\n",
    "        '''\n",
    "\n",
    "        xVal_base, yVal_base, score_base, xVal_best, yVal_best, score_best, p_val \\\n",
    "            = stats_utils.get_curve_onelab(lab,\n",
    "                                           all_algs=algs,\n",
    "                                           data_folder=statsByLab_folderpath.replace(\"lab_statistics\", \"machine_learning\"),\n",
    "                                           curve_type=curve_type,\n",
    "                                           get_pval=True)\n",
    "        # print lab, p_val\n",
    "        scores_base.append(score_base)\n",
    "        scores_best.append(score_best)\n",
    "        p_vals.append(p_val)\n",
    "\n",
    "        scores_diffs[lab] = score_best - score_base\n",
    "\n",
    "        i, j = i_s[ind], j_s[ind]\n",
    "        plt.subplot2grid((row, col), (i, j))\n",
    "\n",
    "        dash_num = 20\n",
    "        plt.plot(np.linspace(0, 1, num=dash_num), np.linspace(0, 1, num=dash_num), color='lightblue',\n",
    "                 linestyle='--')\n",
    "        \n",
    "        \n",
    "        lab_descrip = lab_descriptions.get(lab, lab)\n",
    "\n",
    "        if not inverse01:\n",
    "            \n",
    "            plt.plot(xVal_best, yVal_best, label='%0.2f' % (score_best), color='orange')\n",
    "            if include_baseline:\n",
    "                plt.plot(xVal_base, yVal_base, label='%0.2f' % (score_base))\n",
    "        else:\n",
    "            \n",
    "            label_best = '%0.2f' % (score_best)\n",
    "#             if sig_dict[lab]:\n",
    "            label_best = label_best + stats_utils.map_pval_significance(p_val) # significant\n",
    "            plt.plot(1-yVal_best, 1-xVal_best, label=label_best, color='orange')\n",
    "            if include_baseline:\n",
    "                plt.plot(1 - yVal_base, 1 - xVal_base, label='%0.2f' % (score_base))\n",
    "\n",
    "        plt.xlim([0,1])\n",
    "        plt.ylim([0,1])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "        \n",
    "        if data_source == 'UCSF' and ('\\n' not in lab_descrip):\n",
    "            lab_descrip = lab_descrip[:18] + '\\n' + lab_descrip[18:]\n",
    "        plt.xlabel(lab_descrip)\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(result_figpath)\n",
    "\n",
    "    measures = {'ROC': 'AUC (Area Under Curve)', 'PRC': 'APS (Average Precision Score)'}\n",
    "    avg_base, avg_best = np.mean(scores_base), np.mean(scores_best)\n",
    "    print \"Average %s among %i labs: %.3f baseline, %.3f bestalg (an improvement of %.3f).\" \\\n",
    "          % (measures[curve_type], len(scores_base), avg_base, avg_best, avg_best - avg_base)\n",
    "\n",
    "    df_output_table = pd.DataFrame({'lab':labs,\n",
    "                                    curve_type+' benchmark':scores_base,\n",
    "                                    curve_type + ' ML model':scores_best,\n",
    "                                    curve_type + ' p value':p_vals\n",
    "                       })\n",
    "    df_output_table['lab'] = df_output_table['lab'].apply(lambda x: lab_descriptions.get(x,x)) #\n",
    "    df_output_table[curve_type + ' significance'] = df_output_table[curve_type + ' p value'].apply(lambda x: stats_utils.map_pval_significance(x))\n",
    "    df_output_table[['lab',curve_type+' benchmark',curve_type + ' ML model',curve_type + ' p value',curve_type + ' significance']]\\\n",
    "        .to_csv(result_tablepath, index=False, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_set, set_label = all_labs, 'all_labs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC (Area Under Curve) among 13 labs: 0.783 baseline, 0.849 bestalg (an improvement of 0.066).\n"
     ]
    }
   ],
   "source": [
    "draw__stats_Curves(statsByDataSet_folderpath, lab_set, curve_type=\"ROC\", algs=all_algs,\n",
    "                                   result_label=set_label, inverse01=inverse01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
