# configs/base.yaml
field_separator: "\t"
dataset: econsultant

# Use pre-split .inter files instead of automatic splitting
data_path: '.'
benchmark_filename: [train, valid, test]

# Identify key columns  
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
TIME_FIELD: timestamp

# Data loading - load from separate CSV files
load_col:
    inter: [user_id, item_id, timestamp]

# No eval_setting needed - using benchmark files

# Training setup
epochs: 10
train_batch_size: 256
eval_batch_size: 256
learning_rate: 0.001

# Default to no negative sampling for sequential models
train_neg_sample_args: ~

# Evaluation
topk: [5, 10]
metrics: ['Recall', 'Precision', 'NDCG']
valid_metric: 'NDCG@10'

# Model specific parameters for SASRec
max_seq_length: 50
hidden_size: 64
inner_size: 256
n_layers: 2
n_heads: 2
hidden_dropout_prob: 0.5
attn_dropout_prob: 0.5
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
loss_type: 'CE'

# Reproducibility
seed: 2020
reproducibility: true

# Device
device: cpu
