{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0959be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandychen/Desktop/Healthrex_workspace/scripts/Blood_Culture_Stewardship/blood_culture_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sandychen/Desktop/Healthrex_workspace/scripts/Blood_Culture_Stewardship/blood_culture_env/lib/python3.9/site-packages/google/cloud/bigquery/__init__.py:237: FutureWarning: %load_ext google.cloud.bigquery is deprecated. Install bigquery-magics package and use `%load_ext bigquery_magics`, instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "%load_ext google.cloud.bigquery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client=bigquery.Client()\n",
    "project_id = \"som-nero-phi-jonc101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbef6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "table_id_final_base_demo = f\"{project_id}.blood_culture_stewardship_peds_sandy_2024.final_base_bmi_age_race_gender_adi_temp_peds\"\n",
    "final_base_demo = client.query(f\"SELECT * FROM `{table_id_final_base_demo}`\").to_dataframe()\n",
    "# labs\n",
    "table_id_final_base_labs_lda_ua = f\"{project_id}.blood_culture_stewardship_peds_sandy_2024.final_base_labs_without_cpr_or_pct_ua_lda_peds\"\n",
    "final_base_labs_ua_lda= client.query(f\"SELECT * FROM `{table_id_final_base_labs_lda_ua}`\").to_dataframe()\n",
    "# vitals\n",
    "table_id_final_base_vitals = f\"{project_id}.blood_culture_stewardship_peds_sandy_2024.final_base_vitals_peds\"\n",
    "final_base_vitals= client.query(f\"SELECT * FROM `{table_id_final_base_vitals}`\").to_dataframe()\n",
    "\n",
    "table_id_final_labs_cr_only = f\"{project_id}.blood_culture_stewardship_peds_sandy_2024.final_base_labs_cr_only_peds\"\n",
    "final_labs_cr_only = client.query(f\"SELECT * FROM `{table_id_final_labs_cr_only}`\").to_dataframe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6c6589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged features: (27515, 90)\n",
      "Number of rows: 27515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>pat_enc_csn_id_coded</th>\n",
       "      <th>order_proc_id_coded</th>\n",
       "      <th>blood_culture_order_datetime_utc</th>\n",
       "      <th>order_year</th>\n",
       "      <th>age_days</th>\n",
       "      <th>age_years</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>bmi</th>\n",
       "      <th>source</th>\n",
       "      <th>positive_blood_culture</th>\n",
       "      <th>zip_clean</th>\n",
       "      <th>adi_score</th>\n",
       "      <th>adi_imputed_flag</th>\n",
       "      <th>min_wbc</th>\n",
       "      <th>max_wbc</th>\n",
       "      <th>avg_wbc</th>\n",
       "      <th>median_wbc</th>\n",
       "      <th>min_neutrophils</th>\n",
       "      <th>max_neutrophils</th>\n",
       "      <th>avg_neutrophils</th>\n",
       "      <th>median_neutrophils</th>\n",
       "      <th>min_anc</th>\n",
       "      <th>max_anc</th>\n",
       "      <th>avg_anc</th>\n",
       "      <th>median_anc</th>\n",
       "      <th>min_lymphocytes</th>\n",
       "      <th>max_lymphocytes</th>\n",
       "      <th>avg_lymphocytes</th>\n",
       "      <th>median_lymphocytes</th>\n",
       "      <th>min_alc</th>\n",
       "      <th>max_alc</th>\n",
       "      <th>avg_alc</th>\n",
       "      <th>median_alc</th>\n",
       "      <th>min_hgb</th>\n",
       "      <th>max_hgb</th>\n",
       "      <th>avg_hgb</th>\n",
       "      <th>median_hgb</th>\n",
       "      <th>min_plt</th>\n",
       "      <th>max_plt</th>\n",
       "      <th>avg_plt</th>\n",
       "      <th>median_plt</th>\n",
       "      <th>min_glucose</th>\n",
       "      <th>max_glucose</th>\n",
       "      <th>avg_glucose</th>\n",
       "      <th>median_glucose</th>\n",
       "      <th>min_lactate</th>\n",
       "      <th>max_lactate</th>\n",
       "      <th>avg_lactate</th>\n",
       "      <th>median_lactate</th>\n",
       "      <th>Leukocyte_Esterase</th>\n",
       "      <th>WBC_urine</th>\n",
       "      <th>Bacteria_urine</th>\n",
       "      <th>Nitrite_urine</th>\n",
       "      <th>has_any_line</th>\n",
       "      <th>temp_min_c</th>\n",
       "      <th>temp_avg_c</th>\n",
       "      <th>temp_max_c</th>\n",
       "      <th>temp_median_c</th>\n",
       "      <th>temp_mode_c</th>\n",
       "      <th>resp_min</th>\n",
       "      <th>resp_avg</th>\n",
       "      <th>resp_max</th>\n",
       "      <th>resp_median</th>\n",
       "      <th>resp_mode</th>\n",
       "      <th>hr_min</th>\n",
       "      <th>hr_avg</th>\n",
       "      <th>hr_max</th>\n",
       "      <th>hr_median</th>\n",
       "      <th>hr_mode</th>\n",
       "      <th>sysbp_min</th>\n",
       "      <th>sysbp_avg</th>\n",
       "      <th>sysbp_max</th>\n",
       "      <th>sysbp_median</th>\n",
       "      <th>sysbp_mode</th>\n",
       "      <th>diabp_min</th>\n",
       "      <th>diabp_avg</th>\n",
       "      <th>diabp_max</th>\n",
       "      <th>diabp_median</th>\n",
       "      <th>diabp_mode</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>spo2_avg</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>spo2_median</th>\n",
       "      <th>spo2_mode</th>\n",
       "      <th>min_cr</th>\n",
       "      <th>max_cr</th>\n",
       "      <th>avg_cr</th>\n",
       "      <th>median_cr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JC1000964</td>\n",
       "      <td>131181803241</td>\n",
       "      <td>489700509</td>\n",
       "      <td>2016-03-09 05:24:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>4254</td>\n",
       "      <td>11.654795</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>16.11</td>\n",
       "      <td>shc</td>\n",
       "      <td>0</td>\n",
       "      <td>94087</td>\n",
       "      <td>1.291797</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>36.611111</td>\n",
       "      <td>36.972222</td>\n",
       "      <td>37.388889</td>\n",
       "      <td>36.722222</td>\n",
       "      <td>36.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.250000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JC1000964</td>\n",
       "      <td>313661322</td>\n",
       "      <td>717728953</td>\n",
       "      <td>2016-03-09 07:02:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>4254</td>\n",
       "      <td>11.654795</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>16.11</td>\n",
       "      <td>lpch</td>\n",
       "      <td>0</td>\n",
       "      <td>94087</td>\n",
       "      <td>1.291797</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.3</td>\n",
       "      <td>74.3</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.67</td>\n",
       "      <td>16.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>36.611111</td>\n",
       "      <td>36.972222</td>\n",
       "      <td>37.388889</td>\n",
       "      <td>36.722222</td>\n",
       "      <td>36.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>90.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JC1001312</td>\n",
       "      <td>131092528115</td>\n",
       "      <td>467723412</td>\n",
       "      <td>2015-06-19 17:18:00</td>\n",
       "      <td>2015</td>\n",
       "      <td>3983</td>\n",
       "      <td>10.912329</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>27.27</td>\n",
       "      <td>shc</td>\n",
       "      <td>0</td>\n",
       "      <td>94085</td>\n",
       "      <td>1.815900</td>\n",
       "      <td>1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>21.48</td>\n",
       "      <td>21.48</td>\n",
       "      <td>21.48</td>\n",
       "      <td>21.48</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.32</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>444.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>524.5</td>\n",
       "      <td>448.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.32</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>36.416667</td>\n",
       "      <td>36.722222</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>36.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>108.200000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>75.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.333333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JC1001312</td>\n",
       "      <td>311762468</td>\n",
       "      <td>711125650</td>\n",
       "      <td>2015-06-19 18:32:00</td>\n",
       "      <td>2015</td>\n",
       "      <td>3983</td>\n",
       "      <td>10.912329</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>27.27</td>\n",
       "      <td>lpch</td>\n",
       "      <td>0</td>\n",
       "      <td>94085</td>\n",
       "      <td>1.815900</td>\n",
       "      <td>1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>21.48</td>\n",
       "      <td>21.48</td>\n",
       "      <td>21.48</td>\n",
       "      <td>21.48</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.32</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>444.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.32</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>36.416667</td>\n",
       "      <td>36.722222</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>36.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>118.272727</td>\n",
       "      <td>130.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>123.5</td>\n",
       "      <td>134.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>97.166667</td>\n",
       "      <td>99.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JC1001474</td>\n",
       "      <td>131270266094</td>\n",
       "      <td>615238072</td>\n",
       "      <td>2019-05-21 14:13:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>5432</td>\n",
       "      <td>14.882192</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>22.32</td>\n",
       "      <td>shc</td>\n",
       "      <td>0</td>\n",
       "      <td>95667</td>\n",
       "      <td>25.333756</td>\n",
       "      <td>1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>89.6</td>\n",
       "      <td>89.6</td>\n",
       "      <td>89.6</td>\n",
       "      <td>89.6</td>\n",
       "      <td>16.63</td>\n",
       "      <td>16.63</td>\n",
       "      <td>16.63</td>\n",
       "      <td>16.63</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>295.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>273.5</td>\n",
       "      <td>260.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.12</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>38.111111</td>\n",
       "      <td>38.111111</td>\n",
       "      <td>38.111111</td>\n",
       "      <td>38.111111</td>\n",
       "      <td>38.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>132.200000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>96.600000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
       "0  JC1000964          131181803241            489700509   \n",
       "1  JC1000964             313661322            717728953   \n",
       "2  JC1001312          131092528115            467723412   \n",
       "3  JC1001312             311762468            711125650   \n",
       "4  JC1001474          131270266094            615238072   \n",
       "\n",
       "  blood_culture_order_datetime_utc  order_year  age_days  age_years  gender  \\\n",
       "0              2016-03-09 05:24:00        2016      4254  11.654795    Male   \n",
       "1              2016-03-09 07:02:00        2016      4254  11.654795    Male   \n",
       "2              2015-06-19 17:18:00        2015      3983  10.912329    Male   \n",
       "3              2015-06-19 18:32:00        2015      3983  10.912329    Male   \n",
       "4              2019-05-21 14:13:00        2019      5432  14.882192  Female   \n",
       "\n",
       "    race    bmi source  positive_blood_culture zip_clean  adi_score  \\\n",
       "0  White  16.11    shc                       0     94087   1.291797   \n",
       "1  White  16.11   lpch                       0     94087   1.291797   \n",
       "2  Other  27.27    shc                       0     94085   1.815900   \n",
       "3  Other  27.27   lpch                       0     94085   1.815900   \n",
       "4  Other  22.32    shc                       0     95667  25.333756   \n",
       "\n",
       "   adi_imputed_flag  min_wbc  max_wbc  avg_wbc  median_wbc  min_neutrophils  \\\n",
       "0                 1      NaN      NaN      NaN         NaN              NaN   \n",
       "1                 1     13.0     13.0     13.0        13.0             74.3   \n",
       "2                 1     25.9     25.9     25.9        25.9             82.9   \n",
       "3                 1     25.9     25.9     25.9        25.9             82.9   \n",
       "4                 1     18.5     18.5     18.5        18.5             89.6   \n",
       "\n",
       "   max_neutrophils  avg_neutrophils  median_neutrophils  min_anc  max_anc  \\\n",
       "0              NaN              NaN                 NaN      NaN      NaN   \n",
       "1             74.3             74.3                74.3     9.67     9.67   \n",
       "2             82.9             82.9                82.9    21.48    21.48   \n",
       "3             82.9             82.9                82.9    21.48    21.48   \n",
       "4             89.6             89.6                89.6    16.63    16.63   \n",
       "\n",
       "   avg_anc  median_anc  min_lymphocytes  max_lymphocytes  avg_lymphocytes  \\\n",
       "0      NaN         NaN              NaN              NaN              NaN   \n",
       "1     9.67        9.67             16.3             16.3             16.3   \n",
       "2    21.48       21.48             12.8             12.8             12.8   \n",
       "3    21.48       21.48             12.8             12.8             12.8   \n",
       "4    16.63       16.63              6.1              6.1              6.1   \n",
       "\n",
       "   median_lymphocytes  min_alc  max_alc  avg_alc  median_alc  min_hgb  \\\n",
       "0                 NaN      NaN      NaN      NaN         NaN      NaN   \n",
       "1                16.3     2.13     2.13     2.13        2.13     11.3   \n",
       "2                12.8     3.32     3.32     3.32        3.32     16.6   \n",
       "3                12.8     3.32     3.32     3.32        3.32     16.6   \n",
       "4                 6.1     1.13     1.13     1.13        1.13     13.6   \n",
       "\n",
       "   max_hgb  avg_hgb  median_hgb  min_plt  max_plt  avg_plt  median_plt  \\\n",
       "0      NaN      NaN         NaN      NaN      NaN      NaN         NaN   \n",
       "1     11.3     11.3        11.3    267.0    267.0    267.0       267.0   \n",
       "2     16.6     16.6        16.6    444.0    444.0    444.0       444.0   \n",
       "3     16.6     16.6        16.6    444.0    444.0    444.0       444.0   \n",
       "4     13.6     13.6        13.6    295.0    295.0    295.0       295.0   \n",
       "\n",
       "   min_glucose  max_glucose  avg_glucose  median_glucose  min_lactate  \\\n",
       "0          NaN          NaN          NaN             NaN          NaN   \n",
       "1          NaN          NaN          NaN             NaN          NaN   \n",
       "2        448.0        601.0        524.5           448.0         4.32   \n",
       "3        601.0        601.0        601.0           601.0         4.32   \n",
       "4        260.0        287.0        273.5           260.0         6.12   \n",
       "\n",
       "   max_lactate  avg_lactate  median_lactate Leukocyte_Esterase WBC_urine  \\\n",
       "0          NaN          NaN             NaN               None      None   \n",
       "1          NaN          NaN             NaN               None      None   \n",
       "2         4.32         4.32            4.32               None      None   \n",
       "3         4.32         4.32            4.32               None      None   \n",
       "4         6.12         6.12            6.12           NEGATIVE  NEGATIVE   \n",
       "\n",
       "  Bacteria_urine Nitrite_urine  has_any_line  temp_min_c  temp_avg_c  \\\n",
       "0           None          None             0   36.611111   36.972222   \n",
       "1           None          None             0   36.611111   36.972222   \n",
       "2           None          None             0   36.111111   36.416667   \n",
       "3           None          None             0   36.111111   36.416667   \n",
       "4       POSITIVE      NEGATIVE             0   38.111111   38.111111   \n",
       "\n",
       "   temp_max_c  temp_median_c  temp_mode_c  resp_min   resp_avg  resp_max  \\\n",
       "0   37.388889      36.722222         36.6      18.0  18.750000      20.0   \n",
       "1   37.388889      36.722222         36.6      18.0  18.750000      20.0   \n",
       "2   36.722222      36.111111         36.1      20.0  23.333333      26.0   \n",
       "3   36.722222      36.111111         36.1      20.0  23.000000      26.0   \n",
       "4   38.111111      38.111111         38.1      16.0  25.000000      39.0   \n",
       "\n",
       "   resp_median  resp_mode  hr_min      hr_avg  hr_max  hr_median  hr_mode  \\\n",
       "0         18.0       18.0    80.0   85.250000    90.0       84.0     80.0   \n",
       "1         18.0       18.0    80.0   84.666667    90.0       84.0     84.0   \n",
       "2         24.0       20.0   101.0  108.200000   120.0      102.0    102.0   \n",
       "3         23.0       24.0   101.0  118.272727   130.0      122.0    102.0   \n",
       "4         25.0       16.0   125.0  132.200000   138.0      135.0    125.0   \n",
       "\n",
       "   sysbp_min  sysbp_avg  sysbp_max  sysbp_median  sysbp_mode  diabp_min  \\\n",
       "0      105.0      109.0      117.0         105.0       105.0       57.0   \n",
       "1      104.0      108.0      117.0         105.0       105.0       57.0   \n",
       "2      115.0      119.0      124.0         118.0       115.0       67.0   \n",
       "3      115.0      123.5      134.0         120.0       115.0       62.0   \n",
       "4       88.0       88.0       88.0          88.0        88.0       45.0   \n",
       "\n",
       "   diabp_avg  diabp_max  diabp_median  diabp_mode  spo2_min   spo2_avg  \\\n",
       "0  61.250000       71.0          58.0        57.0      97.0  98.250000   \n",
       "1  62.400000       71.0          59.0        57.0      95.0  97.500000   \n",
       "2  70.333333       75.0          69.0        67.0      98.0  98.333333   \n",
       "3  70.666667       76.0          69.0        75.0      96.0  97.166667   \n",
       "4  45.000000       45.0          45.0        45.0      95.0  96.600000   \n",
       "\n",
       "   spo2_max  spo2_median  spo2_mode  min_cr  max_cr  avg_cr  median_cr  \n",
       "0      99.0         98.0       99.0     NaN     NaN     NaN        NaN  \n",
       "1      99.0         97.0       97.0     NaN     NaN     NaN        NaN  \n",
       "2      99.0         98.0       98.0     1.1     1.1     1.1        1.1  \n",
       "3      99.0         96.0       96.0     1.1     1.1     1.1        1.1  \n",
       "4      98.0         96.0       96.0     0.8     0.8     0.8        0.8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative: Using functools.reduce to merge multiple dataframes at once\n",
    "from functools import reduce\n",
    "\n",
    "# Define merge keys\n",
    "key_cols = [\"anon_id\", \"pat_enc_csn_id_coded\", \"order_proc_id_coded\", \"blood_culture_order_datetime_utc\"]\n",
    "\n",
    "# List of dataframes to merge\n",
    "dfs_to_merge = [final_base_demo, final_base_labs_ua_lda, final_base_vitals, final_labs_cr_only]\n",
    "\n",
    "# Merge all dataframes\n",
    "all_features_df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=key_cols, how=\"inner\"),\n",
    "    dfs_to_merge\n",
    ")\n",
    "\n",
    "print(f\"Shape of merged features: {all_features_df.shape}\")\n",
    "print(f\"Number of rows: {len(all_features_df)}\")\n",
    "all_features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f26da664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anon_id: 0.0%\n",
      "pat_enc_csn_id_coded: 0.0%\n",
      "order_proc_id_coded: 0.0%\n",
      "blood_culture_order_datetime_utc: 0.0%\n",
      "order_year: 0.0%\n",
      "age_days: 0.0%\n",
      "age_years: 0.0%\n",
      "gender: 0.0%\n",
      "race: 0.0%\n",
      "bmi: 7.392331455569689%\n",
      "source: 0.0%\n",
      "positive_blood_culture: 0.0%\n",
      "zip_clean: 6.647283300018173%\n",
      "adi_score: 0.0%\n",
      "adi_imputed_flag: 0.0%\n",
      "min_wbc: 8.108304561148465%\n",
      "max_wbc: 8.108304561148465%\n",
      "avg_wbc: 8.108304561148465%\n",
      "median_wbc: 8.108304561148465%\n",
      "min_neutrophils: 51.266581864437576%\n",
      "max_neutrophils: 51.266581864437576%\n",
      "avg_neutrophils: 51.266581864437576%\n",
      "median_neutrophils: 51.266581864437576%\n",
      "min_anc: 24.641104851898966%\n",
      "max_anc: 24.641104851898966%\n",
      "avg_anc: 24.641104851898966%\n",
      "median_anc: 24.641104851898966%\n",
      "min_lymphocytes: 18.026530983100127%\n",
      "max_lymphocytes: 18.026530983100127%\n",
      "avg_lymphocytes: 18.026530983100127%\n",
      "median_lymphocytes: 18.026530983100127%\n",
      "min_alc: 18.826094857350537%\n",
      "max_alc: 18.826094857350537%\n",
      "avg_alc: 18.826094857350537%\n",
      "median_alc: 18.826094857350537%\n",
      "min_hgb: 7.784844630201708%\n",
      "max_hgb: 7.784844630201708%\n",
      "avg_hgb: 7.784844630201708%\n",
      "median_hgb: 7.784844630201708%\n",
      "min_plt: 8.213701617299654%\n",
      "max_plt: 8.213701617299654%\n",
      "avg_plt: 8.213701617299654%\n",
      "median_plt: 8.213701617299654%\n",
      "min_glucose: 20.846810830456114%\n",
      "max_glucose: 20.846810830456114%\n",
      "avg_glucose: 20.846810830456114%\n",
      "median_glucose: 20.846810830456114%\n",
      "min_lactate: 83.26367435944032%\n",
      "max_lactate: 83.26367435944032%\n",
      "avg_lactate: 83.26367435944032%\n",
      "median_lactate: 83.26367435944032%\n",
      "Leukocyte_Esterase: 62.97655824095948%\n",
      "WBC_urine: 63.7143376340178%\n",
      "Bacteria_urine: 63.04561148464474%\n",
      "Nitrite_urine: 62.97655824095948%\n",
      "has_any_line: 0.0%\n",
      "temp_min_c: 2.2569507541341087%\n",
      "temp_avg_c: 2.2569507541341087%\n",
      "temp_max_c: 2.2569507541341087%\n",
      "temp_median_c: 2.2569507541341087%\n",
      "temp_mode_c: 2.2569507541341087%\n",
      "resp_min: 2.456841722696711%\n",
      "resp_avg: 2.456841722696711%\n",
      "resp_max: 2.456841722696711%\n",
      "resp_median: 2.456841722696711%\n",
      "resp_mode: 2.456841722696711%\n",
      "hr_min: 1.9516627294203164%\n",
      "hr_avg: 1.9516627294203164%\n",
      "hr_max: 1.9516627294203164%\n",
      "hr_median: 1.9516627294203164%\n",
      "hr_mode: 1.9516627294203164%\n",
      "sysbp_min: 10.634199527530438%\n",
      "sysbp_avg: 10.634199527530438%\n",
      "sysbp_max: 10.634199527530438%\n",
      "sysbp_median: 10.634199527530438%\n",
      "sysbp_mode: 10.634199527530438%\n",
      "diabp_min: 10.637833908777031%\n",
      "diabp_avg: 10.637833908777031%\n",
      "diabp_max: 10.637833908777031%\n",
      "diabp_median: 10.637833908777031%\n",
      "diabp_mode: 10.637833908777031%\n",
      "spo2_min: 2.27148827912048%\n",
      "spo2_avg: 2.27148827912048%\n",
      "spo2_max: 2.27148827912048%\n",
      "spo2_median: 2.27148827912048%\n",
      "spo2_mode: 2.27148827912048%\n",
      "min_cr: 21.588224604761038%\n",
      "max_cr: 21.588224604761038%\n",
      "avg_cr: 21.588224604761038%\n",
      "median_cr: 21.588224604761038%\n",
      "age: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(all_features_df.isnull().mean()*100):\n",
    "    print(f\"{all_features_df.columns[index]}: {i}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1a395ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df[\"age\"] = np.floor(all_features_df[\"age_years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b39e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        11.654795\n",
       "1        11.654795\n",
       "2        10.912329\n",
       "3        10.912329\n",
       "4        14.882192\n",
       "           ...    \n",
       "27510    11.819178\n",
       "27511    14.657534\n",
       "27512    14.657534\n",
       "27513    17.558904\n",
       "27514    17.558904\n",
       "Name: age_years, Length: 27515, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_df[\"age_years\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be82e9d",
   "metadata": {},
   "source": [
    "## data split\n",
    "\n",
    "### split into train, val, test (with ~70%,~15%,~15%)\n",
    "### use longitudinal split\n",
    "### train: start - 2023 (Exclusive)\n",
    "### val: 2023-2024 (exclusive)\n",
    "### test: 2024-now (inclusive)\n",
    "### the prevalence is about 5% for all data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c64d8adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows: 27515\n",
      "Train data shape: (20263, 91) and is 73.64346719970925% of all data\n",
      "Val data shape: (3183, 91) and is 11.56823550790478% of all data\n",
      "Test data shape: (4069, 91) and is 14.788297292385971% of all data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"total number of rows: {all_features_df.shape[0]}\")\n",
    "train_data = all_features_df[all_features_df['order_year'] < 2023]\n",
    "val_data = all_features_df[(all_features_df['order_year'] >= 2023) & (all_features_df['order_year'] < 2024)]\n",
    "test_data = all_features_df[all_features_df['order_year'] >= 2024]\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape} and is {train_data.shape[0] / all_features_df.shape[0] * 100}% of all data\")\n",
    "print(f\"Val data shape: {val_data.shape} and is {val_data.shape[0] / all_features_df.shape[0] * 100}% of all data\")\n",
    "print(f\"Test data shape: {test_data.shape} and is {test_data.shape[0] / all_features_df.shape[0] * 100}% of all data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c631b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prevalence of blood culture positive in all data: 2.7584953661639107%\n",
      "prevalence of blood culture positive in train data: 3.188076790208755%\n",
      "prevalence of blood culture positive in val data: 1.3509267986176563%\n",
      "prevalence of blood culture positive in test data: 1.7203244040304742%\n"
     ]
    }
   ],
   "source": [
    "# prevalence of blood culture positive\n",
    "print(f\"prevalence of blood culture positive in all data: {all_features_df['positive_blood_culture'].mean() *100}%\")\n",
    "print(f\"prevalence of blood culture positive in train data: {train_data['positive_blood_culture'].mean() *100}%\")\n",
    "print(f\"prevalence of blood culture positive in val data: {val_data['positive_blood_culture'].mean() *100}%\")\n",
    "print(f\"prevalence of blood culture positive in test data: {test_data['positive_blood_culture'].mean() *100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62eeadf",
   "metadata": {},
   "source": [
    "### process demo data\n",
    "##### drop unknown gender and impute BMI by age and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c479f9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  gm = (train_df.groupby(group_cols, dropna=False)[numeric_cols]\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] top remaining missing (should be 0):\n",
      "spo2_avg        0.0\n",
      "hr_max          0.0\n",
      "spo2_min        0.0\n",
      "temp_mode_c     0.0\n",
      "diabp_median    0.0\n",
      "resp_max        0.0\n",
      "spo2_median     0.0\n",
      "diabp_max       0.0\n",
      "resp_median     0.0\n",
      "sysbp_avg       0.0\n",
      "temp_avg_c      0.0\n",
      "hr_median       0.0\n",
      "resp_mode       0.0\n",
      "diabp_min       0.0\n",
      "diabp_avg       0.0\n",
      "spo2_mode       0.0\n",
      "sysbp_median    0.0\n",
      "resp_min        0.0\n",
      "resp_avg        0.0\n",
      "spo2_max        0.0\n",
      "dtype: float64\n",
      "\n",
      "[val] top remaining missing (should be 0):\n",
      "spo2_avg        0.0\n",
      "hr_max          0.0\n",
      "spo2_min        0.0\n",
      "temp_mode_c     0.0\n",
      "diabp_median    0.0\n",
      "resp_max        0.0\n",
      "spo2_median     0.0\n",
      "diabp_max       0.0\n",
      "resp_median     0.0\n",
      "sysbp_avg       0.0\n",
      "temp_avg_c      0.0\n",
      "hr_median       0.0\n",
      "resp_mode       0.0\n",
      "diabp_min       0.0\n",
      "diabp_avg       0.0\n",
      "spo2_mode       0.0\n",
      "sysbp_median    0.0\n",
      "resp_min        0.0\n",
      "resp_avg        0.0\n",
      "spo2_max        0.0\n",
      "dtype: float64\n",
      "\n",
      "[test] top remaining missing (should be 0):\n",
      "spo2_avg        0.0\n",
      "hr_max          0.0\n",
      "spo2_min        0.0\n",
      "temp_mode_c     0.0\n",
      "diabp_median    0.0\n",
      "resp_max        0.0\n",
      "spo2_median     0.0\n",
      "diabp_max       0.0\n",
      "resp_median     0.0\n",
      "sysbp_avg       0.0\n",
      "temp_avg_c      0.0\n",
      "hr_median       0.0\n",
      "resp_mode       0.0\n",
      "diabp_min       0.0\n",
      "diabp_avg       0.0\n",
      "spo2_mode       0.0\n",
      "sysbp_median    0.0\n",
      "resp_min        0.0\n",
      "resp_avg        0.0\n",
      "spo2_max        0.0\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/51115027.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import sklearn\n",
    "\n",
    "# ===============================\n",
    "# 0) Helpers\n",
    "# ===============================\n",
    "def fill_demo_unknown(df):\n",
    "    out = df.copy()\n",
    "    if \"gender\" in out.columns:\n",
    "        out[\"gender\"] = out[\"gender\"].fillna(\"Unknown\")\n",
    "    if \"race\" in out.columns:\n",
    "        out[\"race\"] = out[\"race\"].fillna(\"Unknown\")\n",
    "    return out\n",
    "\n",
    "def make_age_group(df, age_col=\"age\"):\n",
    "    bins   = [18, 40, 65, 200]  # adult-only\n",
    "    labels = [\"young_adult\", \"middle_age\", \"older_adult\"]\n",
    "    out = df.copy()\n",
    "    out[\"age_group\"] = pd.cut(out[age_col], bins=bins, labels=labels, right=False)\n",
    "    return out\n",
    "\n",
    "def fit_group_medians(train_df, group_cols, numeric_cols):\n",
    "    gm = (train_df.groupby(group_cols, dropna=False)[numeric_cols]\n",
    "                  .median()\n",
    "                  .reset_index())\n",
    "    global_medians = train_df[numeric_cols].median()\n",
    "    return gm, global_medians\n",
    "\n",
    "def apply_stratified_impute(df, group_cols, group_medians, global_medians,\n",
    "                            numeric_cols, ua_defaults):\n",
    "    out = df.copy()\n",
    "    out = out.merge(group_medians, on=group_cols, how=\"left\", suffixes=(\"\", \"__grpmed\"))\n",
    "\n",
    "    # numeric columns: per-group median -> global median\n",
    "    for col in numeric_cols:\n",
    "        if col not in out.columns:\n",
    "            continue\n",
    "        out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
    "        grp_col = f\"{col}__grpmed\"\n",
    "        out[col] = out[col].fillna(out.get(grp_col))\n",
    "        if out[col].isna().any():\n",
    "            out[col] = out[col].fillna(global_medians.get(col))\n",
    "        if grp_col in out.columns:\n",
    "            out.drop(columns=[grp_col], inplace=True)\n",
    "\n",
    "    # UA + binary defaults\n",
    "    for col, default_val in ua_defaults.items():\n",
    "        if col in out.columns:\n",
    "            out[f\"{col}_missing_flag\"] = out[col].isna().astype(int)\n",
    "            out[col] = out[col].fillna(default_val)\n",
    "            if col == \"has_any_line\":\n",
    "                try:\n",
    "                    out[col] = out[col].astype(\"Int64\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "    return out\n",
    "\n",
    "def check_missing(df, cols, name):\n",
    "    miss = df[cols].isna().mean().sort_values(ascending=False).head(20)\n",
    "    print(f\"[{name}] top remaining missing (should be 0):\\n{miss}\\n\")\n",
    "\n",
    "# ===============================\n",
    "# 1) Fill demo Unknown + make age_group\n",
    "# ===============================\n",
    "for name in (\"train_data\", \"val_data\", \"test_data\"):\n",
    "    locals()[name] = fill_demo_unknown(locals()[name])\n",
    "    locals()[name] = make_age_group(locals()[name], age_col=\"age\")\n",
    "\n",
    "# ===============================\n",
    "# 2) Feature selection (ALL vitals + ALL lab aggregates)\n",
    "# ===============================\n",
    "label_key = \"positive_blood_culture\"\n",
    "demo_cols = [\"gender\", \"race\", \"age\", \"bmi\", \"adi_score\"]\n",
    "\n",
    "vital_prefixes = (\"temp_\", \"hr_\", \"sysbp_\", \"diabp_\", \"spo2_\", \"resp_\")\n",
    "lab_bases      = (\"wbc\",\"neutrophils\",\"anc\",\"lymphocytes\",\"alc\",\"hgb\",\"plt\",\"glucose\",\"lactate\", \"cr\")\n",
    "lab_agg_prefix = (\"min_\", \"max_\", \"avg_\", \"median_\", \"mode_\")  # mode_* may not exist for all\n",
    "\n",
    "ua_cols_all    = [\"Leukocyte_Esterase\",\"WBC_urine\",\"Bacteria_urine\",\"Nitrite_urine\",\"has_any_line\"]\n",
    "\n",
    "all_cols = set(train_data.columns)\n",
    "\n",
    "# vitals present\n",
    "vital_cols = [c for c in all_cols if c.startswith(vital_prefixes)]\n",
    "\n",
    "# lab aggregates present (min/max/avg/median/mode for chosen lab families)\n",
    "lab_agg_cols = [\n",
    "    c for c in all_cols\n",
    "    if any(c.startswith(pref) for pref in lab_agg_prefix)\n",
    "    and any(c.endswith(f\"_{base}\") for base in lab_bases)\n",
    "]\n",
    "\n",
    "# UA present\n",
    "ua_cols_present = [c for c in ua_cols_all if c in all_cols]\n",
    "\n",
    "# Final feature list used in modeling\n",
    "selected_features = [c for c in (demo_cols + vital_cols + lab_agg_cols + ua_cols_present) if c in all_cols]\n",
    "\n",
    "# Numeric targets for stratified imputation (vitals + all lab aggs + numeric demos)\n",
    "numeric_targets = [\n",
    "    c for c in (list(vital_cols) + list(lab_agg_cols) + [\"age\",\"bmi\",\"adi_score\"])\n",
    "    if c in train_data.columns and pd.api.types.is_numeric_dtype(train_data[c])\n",
    "]\n",
    "\n",
    "# UA defaults for missing (categorical dipsticks as NEGATIVE, line as 0)\n",
    "ua_defaults = {\n",
    "    \"Leukocyte_Esterase\": \"NEGATIVE\",\n",
    "    \"WBC_urine\": \"NEGATIVE\",\n",
    "    \"Bacteria_urine\": \"NEGATIVE\",\n",
    "    \"Nitrite_urine\": \"NEGATIVE\",\n",
    "    \"has_any_line\": 0,   # keep as binary\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# 3) Train-only stratified imputation by (gender  age_group)\n",
    "# ===============================\n",
    "group_cols = [\"gender\", \"age_group\"]\n",
    "group_meds, global_meds = fit_group_medians(train_data, group_cols, numeric_targets)\n",
    "\n",
    "train_imp = apply_stratified_impute(train_data, group_cols, group_meds, global_meds,\n",
    "                                    numeric_targets, ua_defaults)\n",
    "val_imp   = apply_stratified_impute(val_data,   group_cols, group_meds, global_meds,\n",
    "                                    numeric_targets, ua_defaults)\n",
    "test_imp  = apply_stratified_impute(test_data,  group_cols, group_meds, global_meds,\n",
    "                                    numeric_targets, ua_defaults)\n",
    "\n",
    "# Sanity checks (only on columns we actually use)\n",
    "check_cols = [c for c in (numeric_targets + ua_cols_present) if c in train_imp.columns]\n",
    "check_missing(train_imp, check_cols, \"train\")\n",
    "check_missing(val_imp,   check_cols, \"val\")\n",
    "check_missing(test_imp,  check_cols, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f51db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/1539210140.py:6: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  train_imp.to_gbq(\n",
      "100%|| 1/1 [00:00<00:00, 1466.54it/s]\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/1539210140.py:11: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  val_imp.to_gbq(\n",
      "100%|| 1/1 [00:00<00:00, 880.42it/s]\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_98021/1539210140.py:16: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  test_imp.to_gbq(\n",
      "100%|| 1/1 [00:00<00:00, 15592.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded train_imp to som-nero-phi-jonc101.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_train_peds\n",
      "Uploaded val_imp to som-nero-phi-jonc101.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_val_peds\n",
      "Uploaded test_imp to som-nero-phi-jonc101.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_test_peds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "table_id_all_features_imputed_train= f\"{project_id}.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_train_peds\"\n",
    "table_id_all_features_imputed_val= f\"{project_id}.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_val_peds\"\n",
    "table_id_all_features_imputed_test= f\"{project_id}.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_test_peds\"\n",
    "\n",
    "# Upload the DataFrame to BigQuery\n",
    "train_imp.to_gbq(\n",
    "    destination_table=table_id_all_features_imputed_train,\n",
    "    project_id=project_id,\n",
    "    if_exists='replace'  # This will replace the table if it exists\n",
    ")\n",
    "val_imp.to_gbq(\n",
    "    destination_table=table_id_all_features_imputed_val,\n",
    "    project_id=project_id,\n",
    "    if_exists='replace'  # This will replace the table if it exists\n",
    ")\n",
    "test_imp.to_gbq(\n",
    "    destination_table=table_id_all_features_imputed_test,\n",
    "    project_id=project_id,\n",
    "    if_exists='replace'  # This will replace the table if it exists\n",
    ")\n",
    "print(f\"Uploaded train_imp to {table_id_all_features_imputed_train}\")\n",
    "print(f\"Uploaded val_imp to {table_id_all_features_imputed_val}\")\n",
    "print(f\"Uploaded test_imp to {table_id_all_features_imputed_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84162c8d",
   "metadata": {},
   "source": [
    "### imputed train,val test data uploaded to bigquery \n",
    "##### Uploaded train_imp to som-nero-phi-jonc101.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_train_peds\n",
    "##### Uploaded val_imp to som-nero-phi-jonc101.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_val_peds\n",
    "##### Uploaded test_imp to som-nero-phi-jonc101.blood_culture_stewardship_peds_sandy_2024.final_base_features_imputed_test_peds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29511ab2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blood_culture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
