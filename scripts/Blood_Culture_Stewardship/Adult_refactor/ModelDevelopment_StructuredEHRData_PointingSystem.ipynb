{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806c85ae-9c3d-44a8-88dd-d98bba6b814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9474de-a19b-4c52-a9c6-37bf6885af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandychen/Desktop/Healthrex_workspace/scripts/Blood_Culture_Stewardship/blood_culture_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sandychen/Desktop/Healthrex_workspace/scripts/Blood_Culture_Stewardship/blood_culture_env/lib/python3.9/site-packages/google/cloud/bigquery/__init__.py:237: FutureWarning: %load_ext google.cloud.bigquery is deprecated. Install bigquery-magics package and use `%load_ext bigquery_magics`, instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pulp import *\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import seaborn as sns\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "from scipy.stats import mannwhitneyu\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Automatically find and load the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "project_id = os.getenv('GOOGLE_CLOUD_PROJECT')\n",
    "client = bigquery.Client(project=project_id)\n",
    "%load_ext google.cloud.bigquery\n",
    "\n",
    "# load_dotenv('./Credentials.env',override=True)\n",
    "\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] =str(os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n",
    "# os.environ['GCLOUD_PROJECT'] = str(os.getenv(\"GCLOUD_PROJECT\"))\n",
    "\n",
    "# %load_ext google.cloud.bigquery\n",
    "# from google.cloud import bigquery\n",
    "# client=bigquery.Client()\n",
    "# from google.cloud import bigquery_storage_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a121b5-8678-48e4-abff-db2bd6cdd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# from fancyimpute import IterativeImputer as FancyIterativeImputer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb1e29",
   "metadata": {},
   "source": [
    "## Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e411bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery Train_set_df\n",
    "select * from `som-nero-phi-jonc101.blood_culture_stewardship.cohort` where order_year>=2015 and order_year<2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['ed_arrival_datetime'] = pd.to_datetime(Train_set_df['ed_arrival_datetime'])\n",
    "Train_set_df['blood_culture_order_datetime'] = pd.to_datetime(Train_set_df['blood_culture_order_datetime'])\n",
    "Train_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Train_set_df['earliest_iv_antibiotic_datetime'])\n",
    "Train_set_df['hours_between_ed_cult'] = (Train_set_df['blood_culture_order_datetime'] - Train_set_df['ed_arrival_datetime']).dt.total_seconds() / 3600\n",
    "Train_set_df['hours_between_cult_abx'] = (Train_set_df['blood_culture_order_datetime'] - Train_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifiers=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']\n",
    "Labels=['positive_blood_culture','positive_blood_culture_in_week']\n",
    "Labs=['min_heartrate','max_heartrate', 'avg_heartrate', 'median_heartrate',\n",
    "       'min_resprate', 'max_resprate', 'avg_resprate', 'median_resprate',\n",
    "       'min_temp', 'max_temp', 'avg_temp', 'median_temp', 'min_sysbp',\n",
    "       'max_sysbp', 'avg_sysbp', 'median_sysbp', 'min_diasbp',\n",
    "       'max_diasbp', 'avg_diasbp', 'median_diasbp', 'min_wbc', 'max_wbc',\n",
    "       'avg_wbc', 'median_wbc', 'min_neutrophils', 'max_neutrophils',\n",
    "       'avg_neutrophils', 'median_neutrophils', 'min_lymphocytes',\n",
    "       'max_lymphocytes', 'avg_lymphocytes', 'median_lymphocytes',\n",
    "       'min_hgb', 'max_hgb', 'avg_hgb', 'median_hgb', 'min_plt',\n",
    "       'max_plt', 'avg_plt', 'median_plt', 'min_na', 'max_na', 'avg_na',\n",
    "       'median_na', 'min_hco3', 'max_hco3', 'avg_hco3', 'median_hco3',\n",
    "       'min_bun', 'max_bun', 'avg_bun', 'median_bun', 'min_cr', 'max_cr',\n",
    "       'avg_cr', 'median_cr', 'min_lactate', 'max_lactate', 'avg_lactate',\n",
    "       'median_lactate', 'min_procalcitonin', 'max_procalcitonin',\n",
    "       'avg_procalcitonin', 'median_procalcitonin']\n",
    "Demos=[ 'gender','age']\n",
    "ABX=['vanc', 'zosyn', 'vanc_zosyn', 'other_ABX']\n",
    "Time_Varient_features=['hours_between_ed_cult', 'hours_between_cult_abx']\n",
    "Diagnosis= ['bacteremia', 'septic_shock', 'infective_endocarditis',\n",
    "       'septic_thrombophlebitis', 'vascular_graft_infection', 'CRBSI',\n",
    "       'infectious_discitis', 'epidural_abscess', 'septic_arthritis',\n",
    "       'meningitis', 'meningitis_bacteria', 'cholangitis',\n",
    "       'bacterial_cholangitis', 'pyelonephritis',\n",
    "       'acute_bacterial_pyelonephritis', 'severe_pneumonia',\n",
    "       'acute_hematogenous_osteomyelitis', 'asplenia',\n",
    "       'immunocompromised_state', 'severe_cellulitis', 'cystitis',\n",
    "       'prostatitis', 'CAP', 'diabetic_foot_infection', 'colitis',\n",
    "       'aspiration_pneumonia', 'uncomplicated_cholecystitis',\n",
    "       'uncomplicated_diverticulitis', 'Uncomplicated_pancreatitis']\n",
    "\n",
    "Feature_set=Identifiers+Labels+Labs+Demos+ABX+Diagnosis+Time_Varient_features (# select Features based on experiment)\n",
    "Train_set_df=Train_set_df[Feature_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df.drop_duplicates(subset=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['datapoint'] = Train_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['gender'] = Train_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0439f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['Label']= (Train_set_df['positive_blood_culture']|Train_set_df['positive_blood_culture_in_week'])\n",
    "X_train = Train_set_df.drop(columns=['positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','Label'])\n",
    "y_train = Train_set_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f49342",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Fever'] = X_train['max_temp'].apply(lambda x: 1 if x > 100.4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51958856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(X_train)  # Fit on the training data to calculate medians\n",
    "X_train = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the training, test, and validation data\n",
    "X_train2 = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b39dae-9113-4de8-9e97-1251cf064e1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pointing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "532958b4-304b-4372-ae62-882a23ddee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved LR model\n",
    "with open('logistic_regression_modelI.pkl', 'rb') as model_file:\n",
    "    model_l2 = pickle.load(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89e9d6f6-feb5-46a0-8ea6-b84aca5a371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.20057557  0.00179579  0.33366419 -0.207842    0.19397862 -0.09343402\n",
      " -0.08960952 -0.21265723  0.1118055   0.09470426  0.02193637  0.20037391]\n",
      "Intercept: -0.21577695703453317\n"
     ]
    }
   ],
   "source": [
    "# Get the coefficients\n",
    "coefficients = model_l2.coef_[0]  # Coefficients for the features\n",
    "intercept = model_l2.intercept_[0]  # Intercept term\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d11aa428-bcda-4d3c-8b3a-8e9763c9ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: max_heartrate, Coefficient: 0.20057556921051362\n",
      "Feature: max_resprate, Coefficient: 0.0017957877100702754\n",
      "Feature: Fever, Coefficient: 0.33366419300147093\n",
      "Feature: min_sysbp, Coefficient: -0.20784200224952826\n",
      "Feature: max_wbc, Coefficient: 0.19397862134956015\n",
      "Feature: min_na, Coefficient: -0.09343402422707259\n",
      "Feature: min_hco3, Coefficient: -0.08960951907624168\n",
      "Feature: min_plt, Coefficient: -0.21265723295675015\n",
      "Feature: max_cr, Coefficient: 0.11180549512835596\n",
      "Feature: max_lactate, Coefficient: 0.09470426443307634\n",
      "Feature: gender, Coefficient: 0.021936369224784914\n",
      "Feature: age, Coefficient: 0.20037390877239228\n"
     ]
    }
   ],
   "source": [
    "coefficients = model_l2.coef_[0] \n",
    "# Get the feature names from your training data (assuming X_train2 is a DataFrame)\n",
    "feature_names = X_train2.columns\n",
    "\n",
    "# Identify non-zero coefficients and get corresponding feature names\n",
    "non_zero_indices = np.where(coefficients != 0)[0]\n",
    "non_zero_features = feature_names[non_zero_indices]\n",
    "non_zero_coefficients = coefficients[non_zero_indices]\n",
    "\n",
    "# Print the features and their corresponding non-zero coefficients\n",
    "for feature, coef in zip(non_zero_features, non_zero_coefficients):\n",
    "    print(f\"Feature: {feature}, Coefficient: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9314c250-47b3-41c3-836f-82a66c9b17a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Equation:\n",
      "logit(P) = -0.22 + 0.2 * max_heartrate + 0.0 * max_resprate + 0.33 * Fever + -0.21 * min_sysbp + 0.19 * max_wbc + -0.09 * min_na + -0.09 * min_hco3 + -0.21 * min_plt + 0.11 * max_cr + 0.09 * max_lactate + 0.02 * gender + 0.2 * age\n"
     ]
    }
   ],
   "source": [
    "rounded_coefficients = np.round(non_zero_coefficients, 2)\n",
    "rounded_intercept = np.round(intercept, 2)\n",
    "\n",
    "# Create the logistic regression equation as a string\n",
    "equation_terms = [f\"{coef} * {name}\" for coef, name in zip(rounded_coefficients, non_zero_features)]\n",
    "equation = \" + \".join(equation_terms)\n",
    "full_equation = f\"logit(P) = {rounded_intercept} + {equation}\"\n",
    "\n",
    "# Print the logistic regression equation\n",
    "print(\"Logistic Regression Equation:\")\n",
    "print(full_equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ecd6e-523f-43dd-81da-debd9dbd244d",
   "metadata": {},
   "source": [
    "## pointing system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b956e78-6f2a-4f64-bc9a-473d25e46066",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model_l2.coef_[0] \n",
    "# Get the feature names from your training data (assuming X_train2 is a DataFrame)\n",
    "feature_names = X_train2.columns\n",
    "\n",
    "# Identify non-zero coefficients and get corresponding feature names\n",
    "non_zero_indices = np.where(coefficients != 0)[0]\n",
    "non_zero_features = feature_names[non_zero_indices]\n",
    "non_zero_coefficients = coefficients[non_zero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61986e-42bb-487f-a8ff-7e45b87678f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature Condition  Points\n",
      "0   max_heartrate   > 100.0       2\n",
      "1    max_resprate    > 20.0       0\n",
      "2           Fever     > 0.0       3\n",
      "3       min_sysbp   < 113.0       2\n",
      "4         max_wbc     > 9.9       2\n",
      "5          min_na   < 136.0       1\n",
      "6        min_hco3    < 24.0       1\n",
      "7         min_plt   < 222.0       2\n",
      "8          max_cr    > 0.96       1\n",
      "9     max_lactate    > 1.43       1\n",
      "10         gender     > 0.0       0\n",
      "11            age    > 65.0       2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# how do we decide the scaling factor?\n",
    "# use coef and median as the threshold\n",
    "\n",
    "def generate_feature_points_table(non_zero_features, coefficients, medians, scaling_factor=10):\n",
    "    # Create a list to store the rows for the table\n",
    "    table_data = []\n",
    "\n",
    "    for feature, coef in zip(non_zero_features, coefficients):\n",
    "        if 'min' in feature and coef>0:\n",
    "                row = {\n",
    "                'Feature': feature,\n",
    "                'Condition': f'> {round(medians[feature],3)}',\n",
    "                'Points': round(coef*scaling_factor)\n",
    "                    }\n",
    "        elif 'min' in feature and coef<0:\n",
    "                row = {\n",
    "                'Feature': feature,\n",
    "                'Condition': f'< {round(medians[feature],3)}',\n",
    "                'Points': round(-1*coef*scaling_factor)\n",
    "                    }\n",
    "        elif 'max' in  feature and coef>0:\n",
    "                row = {\n",
    "                'Feature': feature,\n",
    "                'Condition': f'> {round(medians[feature],3)}',\n",
    "                'Points': round(coef*scaling_factor)\n",
    "                    }\n",
    "        elif 'max' in  feature and coef<0:\n",
    "                row = {\n",
    "                'Feature': feature,\n",
    "                'Condition': f'< {round(medians[feature],3)}',\n",
    "                'Points': round(-1*coef*scaling_factor)\n",
    "                    }\n",
    "        else:\n",
    "                row = {\n",
    "                'Feature': feature,\n",
    "                'Condition': f'> {round(medians[feature],3)}',\n",
    "                'Points': round(coef*scaling_factor)\n",
    "                    }\n",
    "        # Add the row to the table data\n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Convert the list of rows into a DataFrame\n",
    "    df_points_table = pd.DataFrame(table_data)\n",
    "    return df_points_table\n",
    "\n",
    "# Example usage\n",
    "df_points_table = generate_feature_points_table(non_zero_features, coefficients, medians, scaling_factor=10)\n",
    "\n",
    "# Display the table\n",
    "print(df_points_table)\n",
    "\n",
    "def save_table_as_image(df, filename=\"feature_points_table.png\"):\n",
    "    # Set up the figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(len(df.columns) * 2, len(df) * 0.4))  # Adjust size based on table content\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Create the table plot\n",
    "    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')\n",
    "\n",
    "    # Adjust font size\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    \n",
    "    # Adjust column width\n",
    "    table.scale(1, 1.5)\n",
    "\n",
    "    # Save the table as an image\n",
    "    #plt.show()\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)  # Close the figure after saving to prevent display\n",
    "\n",
    "\n",
    "save_table_as_image(df_points_table[df_points_table.Points>0], \"feature_points_table.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2b44415-2109-4308-ad04-971639a2d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8896551724137931\n",
      "0.33506472426246803\n",
      "0.03787211555398978\n",
      "0.9904042221422574\n"
     ]
    }
   ],
   "source": [
    "# Calculate sensitivity, specificity, PPV, and NPV\n",
    "y_pred_optimal3 = (total_points >=6).astype(int)\n",
    "tn3, fp3, fn3, tp3 = confusion_matrix(y_test, y_pred_optimal3).ravel()\n",
    "sensitivity3 = tp3 / (tp3 + fn3)  # Sensitivity or Recall\n",
    "specificity3 = tn3 / (tn3 + fp3)  # Specificity\n",
    "ppv3 = tp3 / (tp3 + fp3)          # Positive Predictive Value (Precision)\n",
    "npv3 = tn3 / (tn3 + fn3)          # Negative Predictive Value\n",
    "print(sensitivity3)\n",
    "print(specificity3)\n",
    "print(ppv3)\n",
    "print(npv3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blood_culture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
