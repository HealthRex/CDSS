{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c85ae-9c3d-44a8-88dd-d98bba6b814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,PredefinedSplit,GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9474de-a19b-4c52-a9c6-37bf6885af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandychen/Desktop/Healthrex_workspace/scripts/Blood_Culture_Stewardship/blood_culture_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sandychen/Desktop/Healthrex_workspace/scripts/Blood_Culture_Stewardship/blood_culture_env/lib/python3.9/site-packages/google/cloud/bigquery/__init__.py:237: FutureWarning: %load_ext google.cloud.bigquery is deprecated. Install bigquery-magics package and use `%load_ext bigquery_magics`, instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pulp import *\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import seaborn as sns\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "from scipy.stats import mannwhitneyu\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "project_id = os.getenv('GOOGLE_CLOUD_PROJECT')\n",
    "client = bigquery.Client(project=project_id)\n",
    "%load_ext google.cloud.bigquery\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64419d8",
   "metadata": {},
   "source": [
    "# Util funcitons block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75071e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_bigquery(query):\n",
    "    return client.query(query).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf41b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query = \"\"\"\n",
    "select * from `som-nero-phi-jonc101.blood_culture_stewardship.cohort` where order_year>=2015 and order_year<2022\n",
    "\"\"\"\n",
    "val_query = \"\"\"\n",
    "select * from `som-nero-phi-jonc101.blood_culture_stewardship.cohort` where order_year>=2022 and order_year<2023\n",
    "\"\"\"\n",
    "test_query = \"\"\"\n",
    "select * from `som-nero-phi-jonc101.blood_culture_stewardship.cohort` where order_year>=2023 \n",
    "\"\"\"\n",
    "Train_set_df = query_bigquery(train_query)\n",
    "Val_set_df = query_bigquery(val_query)\n",
    "Test_set_df = query_bigquery(test_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d584f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datetime_features(df, datetime_columns, time_diff_pairs):\n",
    "    \"\"\"\n",
    "    Process datetime columns and calculate time differences for a dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe to process\n",
    "    datetime_columns : list\n",
    "        List of column names to convert to datetime\n",
    "    time_diff_pairs : list of tuples\n",
    "        List of tuples containing (col1, col2, new_col_name) for time difference calculations\n",
    "        where new_col_name will contain hours between col1 and col2\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The processed dataframe with datetime conversions and time differences\n",
    "    \"\"\"\n",
    "    # Convert specified columns to datetime\n",
    "    for col in datetime_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    # Calculate time differences in hours\n",
    "    for col1, col2, new_col_name in time_diff_pairs:\n",
    "        if col1 in df.columns and col2 in df.columns:\n",
    "            df[new_col_name] = (df[col1] - df[col2]).dt.total_seconds() / 3600\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc857438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define datetime columns and time difference calculations\n",
    "datetime_columns = ['ed_arrival_datetime', 'blood_culture_order_datetime', 'earliest_iv_antibiotic_datetime']\n",
    "time_diff_pairs = [\n",
    "    ('blood_culture_order_datetime', 'ed_arrival_datetime', 'hours_between_ed_cult'),\n",
    "    ('blood_culture_order_datetime', 'earliest_iv_antibiotic_datetime', 'hours_between_cult_abx')\n",
    "]\n",
    "\n",
    "# Process all dataframes using the function\n",
    "Train_set_df = process_datetime_features(Train_set_df, datetime_columns, time_diff_pairs)\n",
    "Val_set_df = process_datetime_features(Val_set_df, datetime_columns, time_diff_pairs)\n",
    "Test_set_df = process_datetime_features(Test_set_df, datetime_columns, time_diff_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "621c91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_abx (row):\n",
    "    if row['vanc']==1 or row['zosyn']==1 or row['other_ABX']==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbc5ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['any_abx'] = Train_set_df.apply(any_abx, axis=1)\n",
    "Val_set_df['any_abx'] = Val_set_df.apply(any_abx, axis=1)\n",
    "Test_set_df['any_abx'] = Test_set_df.apply(any_abx, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89f36f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"min_alc\" in Train_set_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803df61d-9ed0-4f8d-a34e-1b7c75f097c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifiers=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']\n",
    "# \"blood_culture_order_datetime\", \"ed_arrival_datetime\"]\n",
    "Labels=['positive_blood_culture','positive_blood_culture_in_week']\n",
    "# keep vitals, labs(remove min, )\n",
    "keep_vitals = ['min_heartrate','max_heartrate', 'avg_heartrate', 'median_heartrate',\n",
    "       'min_resprate', 'max_resprate', 'avg_resprate', 'median_resprate',\n",
    "       'min_temp', 'max_temp', 'avg_temp', 'median_temp', 'min_sysbp',\n",
    "       'max_sysbp', 'avg_sysbp', 'median_sysbp', 'min_diasbp',\n",
    "       'max_diasbp', 'avg_diasbp', 'median_diasbp']\n",
    "\n",
    "# Labs=['min_heartrate','max_heartrate', 'avg_heartrate', 'median_heartrate',\n",
    "#        'min_resprate', 'max_resprate', 'avg_resprate', 'median_resprate',\n",
    "#        'min_temp', 'max_temp', 'avg_temp', 'median_temp', 'min_sysbp',\n",
    "#        'max_sysbp', 'avg_sysbp', 'median_sysbp', 'min_diasbp',\n",
    "#        'max_diasbp', 'avg_diasbp', 'median_diasbp', \n",
    "#        'min_wbc', 'max_wbc',\n",
    "# add Absolute neutrophil count (ANC), Absolute lymphocyte count (ALC),C reactive protein (CRP)\n",
    "# \n",
    "labs = [\n",
    "       'avg_wbc', 'median_wbc', 'min_neutrophils', 'max_neutrophils',\n",
    "       'avg_neutrophils', 'median_neutrophils', 'min_lymphocytes',\n",
    "       'max_lymphocytes', 'avg_lymphocytes', 'median_lymphocytes',\n",
    "       'min_hgb', 'max_hgb', 'avg_hgb', 'median_hgb', 'min_plt',\n",
    "       'max_plt', 'avg_plt', 'median_plt', 'min_na', 'max_na', 'avg_na',\n",
    "       'median_na', 'min_hco3', 'max_hco3', 'avg_hco3', 'median_hco3',\n",
    "       'min_bun', 'max_bun', 'avg_bun', 'median_bun', 'min_cr', 'max_cr',\n",
    "       'avg_cr', 'median_cr', 'min_lactate', 'max_lactate', 'avg_lactate',\n",
    "       'median_lactate', 'min_procalcitonin', 'max_procalcitonin',\n",
    "       'avg_procalcitonin', 'median_procalcitonin']\n",
    "Demos=[ 'gender','age']\n",
    "# ABX=['vanc', 'zosyn', 'vanc_zosyn', 'other_ABX']\n",
    "ABX = [\"any_abx\"]\n",
    "Time_Varient_features=['hours_between_ed_cult'] \n",
    "# 'hours_between_cult_abx']\n",
    "Diagnosis= ['bacteremia', 'septic_shock', 'infective_endocarditis',\n",
    "       'septic_thrombophlebitis', 'vascular_graft_infection', 'CRBSI',\n",
    "       'infectious_discitis', 'epidural_abscess', 'septic_arthritis',\n",
    "       'meningitis', 'meningitis_bacteria', 'cholangitis',\n",
    "       'bacterial_cholangitis', 'pyelonephritis',\n",
    "       'acute_bacterial_pyelonephritis', 'severe_pneumonia',\n",
    "       'acute_hematogenous_osteomyelitis', 'asplenia',\n",
    "       'immunocompromised_state', 'severe_cellulitis', 'cystitis',\n",
    "       'prostatitis', 'CAP', 'diabetic_foot_infection', 'colitis',\n",
    "       'aspiration_pneumonia', 'uncomplicated_cholecystitis',\n",
    "       'uncomplicated_diverticulitis', 'Uncomplicated_pancreatitis']\n",
    "# remove diagnosis\n",
    "\n",
    "Feature_set=Identifiers+Labels+Labs+Demos+ABX+Diagnosis+Time_Varient_features #(select Features based on experiment)\n",
    "Train_set_df=Train_set_df[Feature_set]\n",
    "Test_set_df=Test_set_df[Feature_set]\n",
    "Val_set_df=Val_set_df[Feature_set]\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2acc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "25363    0\n",
       "25364    1\n",
       "25365    1\n",
       "25366    1\n",
       "25367    1\n",
       "Name: any_abx, Length: 25368, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Test_set_df[\"any_abx\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e731c9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Feature_set) # exlucde the identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42cb2a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of train set is 90708\n",
      "the size of val set is 19407\n",
      "the size of test set is 25368\n"
     ]
    }
   ],
   "source": [
    "print(f\"the size of train set is {Train_set_df.shape[0]}\")\n",
    "print(f\"the size of val set is {Val_set_df.shape[0]}\")\n",
    "print(f\"the size of test set is {Test_set_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6bfe91c-14f1-4719-8ff5-5a5b10c7daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_95895/4188508575.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Val_set_df.drop_duplicates(subset = Identifiers, inplace= True)\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_95895/4188508575.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Test_set_df.drop_duplicates(subset = Identifiers, inplace= True)\n"
     ]
    }
   ],
   "source": [
    "# Train_set_df.drop_duplicates(subset=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'],inplace=True)\n",
    "# Val_set_df.drop_duplicates(subset=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'],inplace=True)\n",
    "# Test_set_df.drop_duplicates(subset=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'],inplace=True)\n",
    "# # shouldn't we report this number after deduplication?\n",
    "# # why do we need to deduplicate?\n",
    "Train_set_df.drop_duplicates(subset = Identifiers, inplace= True)\n",
    "Val_set_df.drop_duplicates(subset = Identifiers, inplace= True)\n",
    "Test_set_df.drop_duplicates(subset = Identifiers, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2345f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of train set is 90708\n",
      "the size of val set is 19407\n",
      "the size of test set is 25368\n"
     ]
    }
   ],
   "source": [
    "print(f\"the size of train set is {Train_set_df.shape[0]}\")\n",
    "print(f\"the size of val set is {Val_set_df.shape[0]}\")\n",
    "print(f\"the size of test set is {Test_set_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05719c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af53be84-8a74-43d8-8061-72bc6999046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_95895/3045874452.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Test_set_df['datapoint'] = Train_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_95895/3045874452.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Val_set_df['datapoint'] = Val_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n"
     ]
    }
   ],
   "source": [
    "# why do we need the datapoint?\n",
    "Train_set_df['datapoint'] = Train_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n",
    "Test_set_df['datapoint'] = Train_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n",
    "Val_set_df['datapoint'] = Val_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7922e42c-c451-4eef-b589-aebb812a229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_95895/909712918.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Test_set_df['gender'] = Test_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_95895/909712918.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Val_set_df['gender'] = Val_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n"
     ]
    }
   ],
   "source": [
    "Train_set_df['gender'] = Train_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
    "Test_set_df['gender'] = Test_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
    "Val_set_df['gender'] = Val_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fffb6275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135483"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df.shape[0]+Test_set_df.shape[0]+Val_set_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6f614-907a-4a3b-b432-eaf49a73746d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57a121b5-8678-48e4-abff-db2bd6cdd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# from fancyimpute import IterativeImputer as FancyIterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f10efff-8ce1-4c88-9fa7-812781800638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_95895/2775927307.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Test_set_df['Label']= (Test_set_df['positive_blood_culture']|Test_set_df['positive_blood_culture_in_week'])\n",
      "/var/folders/d1/3gdyy98d6h1d9pxx47s40vv40000gp/T/ipykernel_95895/2775927307.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Val_set_df['Label']= (Val_set_df['positive_blood_culture']|Val_set_df['positive_blood_culture_in_week'])\n"
     ]
    }
   ],
   "source": [
    "Train_set_df['Label']= (Train_set_df['positive_blood_culture']|Train_set_df['positive_blood_culture_in_week'])\n",
    "X_train = Train_set_df.drop(columns=['positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','Label'])\n",
    "# 'blood_culture_order_datetime',\n",
    "#  'ed_arrival_datetime' ])\n",
    "y_train = Train_set_df['Label']\n",
    "\n",
    "# Prepare the test data\n",
    "Test_set_df['Label']= (Test_set_df['positive_blood_culture']|Test_set_df['positive_blood_culture_in_week'])\n",
    "X_test = Test_set_df.drop(columns=['positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded', 'Label'])\n",
    "# \"blood_culture_order_datetime\", \"ed_arrival_datetime\"]) # this line was problematic. I fixed by adding \"Lable\"\n",
    "y_test = Test_set_df['Label']\n",
    "\n",
    "\n",
    "Val_set_df['Label']= (Val_set_df['positive_blood_culture']|Val_set_df['positive_blood_culture_in_week'])\n",
    "X_val = Val_set_df.drop(columns=['positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded', 'Label'] )\n",
    "# \"blood_culture_order_datetime\", \"ed_arrival_datetime\"])\n",
    "y_val = Val_set_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fcb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['min_heartrate', 'max_heartrate', 'avg_heartrate', 'median_heartrate',\n",
       "       'min_resprate', 'max_resprate', 'avg_resprate', 'median_resprate',\n",
       "       'min_temp', 'max_temp',\n",
       "       ...\n",
       "       'CAP', 'diabetic_foot_infection', 'colitis', 'aspiration_pneumonia',\n",
       "       'uncomplicated_cholecystitis', 'uncomplicated_diverticulitis',\n",
       "       'Uncomplicated_pancreatitis', 'hours_between_ed_cult',\n",
       "       'hours_between_cult_abx', 'datapoint'],\n",
       "      dtype='object', length=102)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4dc74307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.07103011862239274)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9dc6e",
   "metadata": {},
   "source": [
    "# SKip Fancy_Imputer for now as the manuscript uses median imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f56e74e-3d17-4db1-99ee-5131ab5f8fd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fancy_Imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc29a9-ae88-47cd-9f68-88629bc8490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_imputer = FancyIterativeImputer(max_iter=10, random_state=0)\n",
    "fancy_imputer.fit(X_train)\n",
    "\n",
    "X_train = pd.DataFrame(fancy_imputer.transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Impute the missing values in the test set\n",
    "X_test = pd.DataFrame(fancy_imputer.transform(X_test), columns=X_train_im.columns)\n",
    "\n",
    "# Impute the missing values in the validation set\n",
    "X_val = pd.DataFrame(fancy_imputer.transform(X_val), columns=X_train_im.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d4c50-8f08-405c-8a8d-6e56e5ad4ebf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Median Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ff7db71-60dd-4881-a771-7162d69b5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(X_train)  # Fit on the training data to calculate medians\n",
    "# Step 2: Impute the missing values in all datasets\n",
    "X_train = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
    "X_val = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19bc04",
   "metadata": {},
   "source": [
    "## For study with including Fever as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a7c3cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of train set is (90708, 102)\n",
      "the size of val set is (19407, 102)\n",
      "the size of test set is (25368, 102)\n"
     ]
    }
   ],
   "source": [
    "print(f\"the size of train set is {X_train.shape}\")\n",
    "print(f\"the size of val set is {X_val.shape}\")\n",
    "print(f\"the size of test set is {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8edaf06-9ce6-4b68-a38e-4fca48d9d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain\n",
    "X_train['Fever'] = X_train['max_temp'].apply(lambda x: 1 if x >= 100.4 else 0)\n",
    "X_val['Fever'] = X_val['max_temp'].apply(lambda x: 1 if x >= 100.4 else 0)\n",
    "X_test['Fever'] = X_test['max_temp'].apply(lambda x: 1 if x > 100.4 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea7b06f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of train set is (90708, 103)\n",
      "the size of val set is (19407, 103)\n",
      "the size of test set is (25368, 103)\n"
     ]
    }
   ],
   "source": [
    "print(f\"the size of train set is {X_train.shape}\")\n",
    "print(f\"the size of val set is {X_val.shape}\")\n",
    "print(f\"the size of test set is {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc002e85",
   "metadata": {},
   "source": [
    "## Scale paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36f87a8e-94e9-4422-922f-1521031a0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the training, test, and validation data\n",
    "X_train2 = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_test2 = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)\n",
    "X_val2 = pd.DataFrame(scaler.transform(X_val), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b39dae-9113-4de8-9e97-1251cf064e1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce13d7",
   "metadata": {},
   "source": [
    "## Search over paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0550004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "\n",
    "custom_weights = [\n",
    "    None,                  \n",
    "    \"balanced\",                  \n",
    "    {0: 1, 1: 2},                \n",
    "    {0: 1, 1: 3},                \n",
    "    {0: 1, 1: 5},\n",
    "    {0: 1, 1: ratio} \n",
    "]\n",
    "param_grid = [\n",
    "    {\n",
    "        \"penalty\": [\"l1\"],\n",
    "        \"solver\": [\"liblinear\", \"saga\"],\n",
    "        \"C\": [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "        \"class_weight\": custom_weights,\n",
    "        \"max_iter\": [1000]\n",
    "    },\n",
    "    {\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"solver\": [\"liblinear\", \"saga\", \"lbfgs\", \"sag\"],\n",
    "        \"C\": [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "        \"class_weight\": custom_weights,\n",
    "        \"max_iter\": [1000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd83716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and val so GridSearchCV \n",
    "X_search = np.vstack([X_train2, X_val2])\n",
    "y_search = np.concatenate([y_train, y_val])\n",
    "\n",
    "test_fold = np.array([-1] * len(y_train) + [0] * len(y_val))\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba63e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LogisticRegression()\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=ps,               \n",
    "    refit=True,         \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c276fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fitted grid for future use\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Create filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "grid_filename = f\"fitted_grid_{timestamp}.pkl\"\n",
    "\n",
    "# Save the complete fitted grid\n",
    "with open(grid_filename, 'wb') as f:\n",
    "    pickle.dump(grid, f)\n",
    "\n",
    "print(f\"Grid saved as: {grid_filename}\")\n",
    "print(f\"Best score: {grid.best_score_:.4f}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "print(f\"Total combinations tested: {len(grid.cv_results_['params'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d843dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 90708\n",
      "Validation size: 19407\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "grid_filename = \"fitted_grid_20250903_145027.pkl\"\n",
    "with open(grid_filename, \"rb\") as f:\n",
    "    loaded_grid = pickle.load(f)\n",
    "\n",
    "# The PredefinedSplit object you passed in is still here\n",
    "ps = loaded_grid.cv\n",
    "\n",
    "# Its test_fold attribute tells you which sample went to which fold\n",
    "test_fold = np.array(ps.test_fold)\n",
    "\n",
    "n_train = np.sum(test_fold == -1)\n",
    "n_val   = np.sum(test_fold == 0)\n",
    "\n",
    "print(\"Training size:\", n_train)\n",
    "print(\"Validation size:\", n_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16088905",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_train2.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae337b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid loaded successfully!\n",
      "Best score: 0.7919\n",
      "Best parameters: {'C': 0.001, 'class_weight': {0: 1, 1: np.float64(13.078534844016762)}, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# TO LOAD THE GRID NEXT TIME (instead of rerunning grid search):\n",
    "# Uncomment and modify filename when you want to load\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# Load the saved grid (replace with your actual filename)\n",
    "with open(\"fitted_grid_20250903_145027.pkl\", 'rb') as f:\n",
    "    grid = pickle.load(f)\n",
    "\n",
    "print(f\"Grid loaded successfully!\")\n",
    "print(f\"Best score: {grid.best_score_:.4f}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "\n",
    "# Now you can use grid.best_estimator_ directly\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70fc39e",
   "metadata": {},
   "source": [
    "## LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "784fb95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandychen/Desktop/Healthrex_workspace/scripts/Blood_Culture_Stewardship/blood_culture_env/lib/python3.9/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "y_pred_prob_test = best_model.predict_proba(X_test2)[:, 1]\n",
    "auc_test = roc_auc_score(y_test, y_pred_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea26db8-d04a-406a-b47a-e8f84ae4f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = grid.best_params_.copy()\n",
    "# model_l2 = LogisticRegression(**best_params)\n",
    "# model_l2.fit(X_train2, y_train)\n",
    "\n",
    "# # Predict probabilities for the test set\n",
    "# y_pred_prob_l2 = model_l2.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "# # Calculate the AUC\n",
    "# auc_l2 = roc_auc_score(y_test, y_pred_prob_l2)\n",
    "# print(f\"AUC for the test set with L1 regularization: {auc_l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32e30c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the test set with L1 regularization: 0.7967\n"
     ]
    }
   ],
   "source": [
    "#new \n",
    "best_params = grid.best_params_.copy()\n",
    "model_l2 = LogisticRegression(**best_params)\n",
    "model_l2.fit(X_train2, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_prob_l2 = model_l2.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "# Calculate the AUC\n",
    "auc_l2 = roc_auc_score(y_test, y_pred_prob_l2)\n",
    "print(f\"AUC for the test set with L1 regularization: {auc_l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d5003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"refactor_logistic_regression_model.pkl\", 'wb') as f:\n",
    "#     pickle.dump(model_l2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ae18d-694c-4538-9e23-516473624cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import statsmodels.api as sm\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# # L2 Regularization (Ridge)\n",
    "# model_l2 = LogisticRegression(max_iter=2000,class_weight='balanced')#, C=0.01, penalty='l1')#solver='lbfgs'\n",
    "# model_l2.fit(X_train2, y_train)\n",
    "\n",
    "# # Predict probabilities for the test set\n",
    "# y_pred_prob_l2 = model_l2.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "# # Calculate the AUC\n",
    "# auc_l2 = roc_auc_score(y_test, y_pred_prob_l2)\n",
    "# print(f\"AUC for the test set with L2 regularization: {auc_l2:.4f}\")\n",
    "\n",
    "\n",
    "# # Calculate the AUC\n",
    "# yt_pred_prob_l2 = model_l2.predict_proba(X_val2)[:, 1]\n",
    "# auc_l2 = roc_auc_score(y_val, yt_pred_prob_l2)\n",
    "# print(f\"AUC for the validation set with L2 regularization: {auc_l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "068152b8-e1c8-4b36-8e55-cc5fe5417795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.2893\n",
      "Sensitivity: 0.9503\n",
      "Specificity: 0.3344\n",
      "PPV (Precision): 0.0752\n",
      "NPV: 0.9916\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_l2)\n",
    "\n",
    "# Find the threshold where sensitivity (TPR) >= 0.9\n",
    "threshold_index = np.argmax(tpr >= 0.95)\n",
    "optimal_threshold = thresholds[threshold_index]\n",
    "\n",
    "# Use the optimal threshold to make binary predictions\n",
    "y_pred_optimal = (y_pred_prob_l2 >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_optimal).ravel()\n",
    "\n",
    "# Calculate sensitivity, specificity, PPV, and NPV\n",
    "sensitivity = tp / (tp + fn)  # Sensitivity or Recall\n",
    "specificity = tn / (tn + fp)  # Specificity\n",
    "ppv = tp / (tp + fp)          # Positive Predictive Value (Precision)\n",
    "npv = tn / (tn + fn)          # Negative Predictive Value\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv:.4f}\")\n",
    "print(f\"NPV: {npv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39313e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed60fab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_prob_l2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_curve, confusion_matrix\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate the ROC curve\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m roc_curve(y_test, \u001b[43my_pred_prob_l2\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Find the threshold where sensitivity (TPR) >= 0.9\u001b[39;00m\n\u001b[1;32m      9\u001b[0m threshold_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(tpr \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.95\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_prob_l2' is not defined"
     ]
    }
   ],
   "source": [
    "# new\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_l2)\n",
    "\n",
    "# Find the threshold where sensitivity (TPR) >= 0.9\n",
    "threshold_index = np.argmax(tpr >= 0.95)\n",
    "optimal_threshold = thresholds[threshold_index]\n",
    "\n",
    "# Use the optimal threshold to make binary predictions\n",
    "y_pred_optimal = (y_pred_prob_l2 >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_optimal).ravel()\n",
    "\n",
    "# Calculate sensitivity, specificity, PPV, and NPV\n",
    "sensitivity = tp / (tp + fn)  # Sensitivity or Recall\n",
    "specificity = tn / (tn + fp)  # Specificity\n",
    "ppv = tp / (tp + fp)          # Positive Predictive Value (Precision)\n",
    "npv = tn / (tn + fn)          # Negative Predictive Value\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv:.4f}\")\n",
    "print(f\"NPV: {npv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e71458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_df[\"y_pred_prob_Cultryx\"] = y_pred_prob_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_l2)\n",
    "\n",
    "# Find the threshold where sensitivity (TPR) >= 0.9\n",
    "threshold_index = np.argmax(tpr >= 0.95)\n",
    "optimal_threshold = thresholds[threshold_index]\n",
    "\n",
    "# Use the optimal threshold to make binary predictions\n",
    "y_pred_optimal = (y_pred_prob_l2 >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_optimal).ravel()\n",
    "\n",
    "# Calculate sensitivity, specificity, PPV, and NPV\n",
    "sensitivity = tp / (tp + fn)  # Sensitivity or Recall\n",
    "specificity = tn / (tn + fp)  # Specificity\n",
    "ppv = tp / (tp + fp)          # Positive Predictive Value (Precision)\n",
    "npv = tn / (tn + fn)          # Negative Predictive Value\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv:.4f}\")\n",
    "print(f\"NPV: {npv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5826ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_df[\"y_pred_Cultryx\"] = y_pred_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save_df = Test_set_df[['anon_id','pat_enc_csn_id_coded','order_proc_id_coded',\"Label\", 'y_pred_Cultryx', 'y_pred_prob_Cultryx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e91b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save_df.to_csv(\"Cultryx_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532958b4-304b-4372-ae62-882a23ddee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "# Assuming model_l2 is your trained Logistic Regression model\n",
    "with open('logistic_regression_modelI.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model_l2, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89e9d6f6-feb5-46a0-8ea6-b84aca5a371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.00000000e+00  6.76946719e-02  0.00000000e+00  9.11883449e-02\n",
      "  0.00000000e+00  0.00000000e+00  1.69859821e-03  0.00000000e+00\n",
      "  0.00000000e+00  3.51428537e-01  0.00000000e+00  0.00000000e+00\n",
      " -6.37092346e-02  0.00000000e+00  0.00000000e+00 -5.46881773e-02\n",
      "  0.00000000e+00  0.00000000e+00 -4.70226023e-03 -8.16152066e-02\n",
      "  8.30847983e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  8.68150846e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -9.39016527e-02\n",
      "  0.00000000e+00 -1.84197797e-01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -4.47934994e-02  0.00000000e+00 -2.42986139e-02\n",
      "  0.00000000e+00 -9.05524189e-02  0.00000000e+00  0.00000000e+00\n",
      "  1.59540921e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  5.65706096e-02  0.00000000e+00  4.34165031e-02  0.00000000e+00\n",
      "  0.00000000e+00  8.37853380e-02  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.33215314e-01  9.71237693e-02  1.59347225e-01\n",
      "  2.66364918e-02  2.07900259e-01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  6.89245042e-02  5.50363742e-02\n",
      "  8.04496173e-02 -2.78787557e-02  9.47820270e-03  0.00000000e+00\n",
      "  0.00000000e+00 -5.04550186e-05  0.00000000e+00 -1.37811875e-02\n",
      " -4.27327676e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  5.50676039e-02  0.00000000e+00  0.00000000e+00 -1.06422154e-01\n",
      " -1.51811055e-01  8.01138507e-03  1.88881340e-02]\n",
      "Intercept: -0.3263983675589842\n"
     ]
    }
   ],
   "source": [
    "# Get the coefficients\n",
    "coefficients = model_l2.coef_[0]  # Coefficients for the features\n",
    "intercept = model_l2.intercept_[0]  # Intercept term\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d11aa428-bcda-4d3c-8b3a-8e9763c9ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: max_heartrate, Coefficient: 0.06769467188954216\n",
      "Feature: median_heartrate, Coefficient: 0.09118834489720277\n",
      "Feature: avg_resprate, Coefficient: 0.0016985982087139775\n",
      "Feature: max_temp, Coefficient: 0.35142853663551205\n",
      "Feature: min_sysbp, Coefficient: -0.06370923459879302\n",
      "Feature: median_sysbp, Coefficient: -0.05468817727612786\n",
      "Feature: avg_diasbp, Coefficient: -0.0047022602290733295\n",
      "Feature: median_diasbp, Coefficient: -0.0816152065758585\n",
      "Feature: min_wbc, Coefficient: 0.08308479834071922\n",
      "Feature: avg_neutrophils, Coefficient: 0.08681508462753895\n",
      "Feature: median_hgb, Coefficient: -0.09390165268955498\n",
      "Feature: max_plt, Coefficient: -0.18419779694771327\n",
      "Feature: max_na, Coefficient: -0.044793499403164155\n",
      "Feature: median_na, Coefficient: -0.0242986138858686\n",
      "Feature: max_hco3, Coefficient: -0.09055241886663995\n",
      "Feature: min_bun, Coefficient: 0.15954092094047956\n",
      "Feature: min_lactate, Coefficient: 0.0565706095633029\n",
      "Feature: avg_lactate, Coefficient: 0.04341650310866221\n",
      "Feature: max_procalcitonin, Coefficient: 0.08378533798876102\n",
      "Feature: age, Coefficient: 0.13321531384413005\n",
      "Feature: vanc, Coefficient: 0.09712376933502928\n",
      "Feature: zosyn, Coefficient: 0.15934722546786204\n",
      "Feature: vanc_zosyn, Coefficient: 0.026636491814842334\n",
      "Feature: other_ABX, Coefficient: 0.20790025867342377\n",
      "Feature: bacterial_cholangitis, Coefficient: 0.0689245041617706\n",
      "Feature: pyelonephritis, Coefficient: 0.055036374163623655\n",
      "Feature: acute_bacterial_pyelonephritis, Coefficient: 0.08044961733686937\n",
      "Feature: severe_pneumonia, Coefficient: -0.027878755685902246\n",
      "Feature: acute_hematogenous_osteomyelitis, Coefficient: 0.00947820270187098\n",
      "Feature: severe_cellulitis, Coefficient: -5.04550185539495e-05\n",
      "Feature: prostatitis, Coefficient: -0.013781187457400415\n",
      "Feature: CAP, Coefficient: -0.0427327675727725\n",
      "Feature: uncomplicated_cholecystitis, Coefficient: 0.0550676039486256\n",
      "Feature: hours_between_ed_cult, Coefficient: -0.10642215380844823\n",
      "Feature: hours_between_cult_abx, Coefficient: -0.1518110552082797\n",
      "Feature: datapoint, Coefficient: 0.008011385066677647\n",
      "Feature: Fever, Coefficient: 0.0188881339558748\n"
     ]
    }
   ],
   "source": [
    "coefficients = model_l2.coef_[0] \n",
    "# Get the feature names from your training data (assuming X_train2 is a DataFrame)\n",
    "feature_names = X_train2.columns\n",
    "\n",
    "# Identify non-zero coefficients and get corresponding feature names\n",
    "non_zero_indices = np.where(coefficients != 0)[0]\n",
    "non_zero_features = feature_names[non_zero_indices]\n",
    "non_zero_coefficients = coefficients[non_zero_indices]\n",
    "\n",
    "# Print the features and their corresponding non-zero coefficients\n",
    "for feature, coef in zip(non_zero_features, non_zero_coefficients):\n",
    "    print(f\"Feature: {feature}, Coefficient: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd00a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blood_culture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
