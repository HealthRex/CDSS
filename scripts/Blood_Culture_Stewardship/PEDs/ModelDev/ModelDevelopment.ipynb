{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2435b595-3c52-4465-9bfb-77bf0a4a96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9b54b74-335c-4fda-b6e6-7521116ec662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pulp import *\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import seaborn as sns\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "from scipy.stats import mannwhitneyu\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa6fe951-8e8b-4dd6-8b74-ec268b56bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The google.cloud.bigquery extension is already loaded. To reload it, use:\n",
      "  %reload_ext google.cloud.bigquery\n"
     ]
    }
   ],
   "source": [
    "load_dotenv() \n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/fa/.config/gcloud/application_default_credentials.json'\n",
    "os.environ['GCLOUD_PROJECT'] = 'som-nero-phi-jonc101'\n",
    "%load_ext google.cloud.bigquery\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client=bigquery.Client()\n",
    "from google.cloud import bigquery_storage_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9653b9bc-d2b3-4d97-8e03-d69a98081cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f1e50db51e40f8a073ee6b6056c52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2411a4e9aa1d47168d22757d94fa71fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery Train_set_df\n",
    "select * from  `som-nero-phi-jonc101.PEDsblood_culture_stewardship.cohort` where Extract(year from blood_culture_order_datetime)<2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc12cd38-2380-4248-b134-e9c3ca0248e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df[(Train_set_df.positive_blood_culture==1)|(Train_set_df.positive_blood_culture_in_week==1)][['anon_id','pat_enc_csn_id_coded','order_proc_id_coded']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f95954e0-24e0-4a74-af0e-3141a7bb8588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded',\n",
       "       'blood_culture_order_datetime', 'birth_date_jittered', 'bmi',\n",
       "       'positive_blood_culture', 'positive_blood_culture_in_week',\n",
       "       'earliest_iv_antibiotic_datetime', 'min_heartrate',\n",
       "       'max_heartrate', 'avg_heartrate', 'median_heartrate',\n",
       "       'min_resprate', 'max_resprate', 'avg_resprate', 'median_resprate',\n",
       "       'min_temp', 'max_temp', 'avg_temp', 'median_temp', 'min_sysbp',\n",
       "       'max_sysbp', 'avg_sysbp', 'median_sysbp', 'min_diasbp',\n",
       "       'max_diasbp', 'avg_diasbp', 'median_diasbp', 'min_wbc', 'max_wbc',\n",
       "       'avg_wbc', 'median_wbc', 'min_neutrophils', 'max_neutrophils',\n",
       "       'avg_neutrophils', 'median_neutrophils', 'min_lymphocytes',\n",
       "       'max_lymphocytes', 'avg_lymphocytes', 'median_lymphocytes',\n",
       "       'min_hgb', 'max_hgb', 'avg_hgb', 'median_hgb', 'min_plt',\n",
       "       'max_plt', 'avg_plt', 'median_plt', 'min_na', 'max_na', 'avg_na',\n",
       "       'median_na', 'min_hco3', 'max_hco3', 'avg_hco3', 'median_hco3',\n",
       "       'min_bun', 'max_bun', 'avg_bun', 'median_bun', 'min_cr', 'max_cr',\n",
       "       'avg_cr', 'median_cr', 'min_lactate', 'max_lactate', 'avg_lactate',\n",
       "       'median_lactate', 'min_procalcitonin', 'max_procalcitonin',\n",
       "       'avg_procalcitonin', 'median_procalcitonin', 'gender', 'race',\n",
       "       'bacteremia', 'septic_shock', 'infective_endocarditis',\n",
       "       'septic_thrombophlebitis', 'vascular_graft_infection', 'CRBSI',\n",
       "       'infectious_discitis', 'epidural_abscess', 'septic_arthritis',\n",
       "       'meningitis', 'meningitis_bacteria', 'cholangitis',\n",
       "       'bacterial_cholangitis', 'pyelonephritis',\n",
       "       'acute_bacterial_pyelonephritis', 'severe_pneumonia',\n",
       "       'acute_hematogenous_osteomyelitis', 'asplenia',\n",
       "       'immunocompromised_state', 'severe_cellulitis', 'cystitis',\n",
       "       'prostatitis', 'CAP', 'diabetic_foot_infection', 'colitis',\n",
       "       'aspiration_pneumonia', 'uncomplicated_cholecystitis',\n",
       "       'uncomplicated_diverticulitis', 'Uncomplicated_pancreatitis',\n",
       "       'vanc', 'zosyn', 'vanc_zosyn', 'other_ABX', 'Leukocyte_Esterase',\n",
       "       'WBC_urine', 'Bacteria_urine', 'Nitrite_urine', 'Line_Presense',\n",
       "       'Transplant', 'min_anc', 'max_anc', 'avg_anc', 'median_anc',\n",
       "       'min_alc', 'max_alc', 'avg_alc', 'median_alc', 'min_spo2',\n",
       "       'max_spo2', 'avg_spo2', 'median_spo2'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b96cb4a-cd55-4634-96cc-d9e0959e3174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df[(Train_set_df.positive_blood_culture==1)|(Train_set_df.positive_blood_culture_in_week==1)][['anon_id','pat_enc_csn_id_coded','order_proc_id_coded']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a46f3411-74aa-402e-a202-e55530f439db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19721, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df[(Train_set_df.positive_blood_culture==0)|(Train_set_df.positive_blood_culture_in_week==0)][['anon_id','pat_enc_csn_id_coded','order_proc_id_coded']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30db6e75-4107-4fd1-a950-97e01106ce75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857f1d4f2adc4c94a930beb61621cf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8791df82ea6f4aa0a16e2b62d9409bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery Val_set_df\n",
    "select * from `som-nero-phi-jonc101.PEDsblood_culture_stewardship.cohort` \n",
    "where  Extract(year from blood_culture_order_datetime)>=2022 and \n",
    "Extract(year from blood_culture_order_datetime)<2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a00fc1c5-8c12-411e-b5d4-1536df03eff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b455502a52fb4d5b9f4de7833cf250be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f960a799240a4d97b1e304e154f6d61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery Test_set_df\n",
    "select * from `som-nero-phi-jonc101.PEDsblood_culture_stewardship.cohort`\n",
    "where Extract(year from blood_culture_order_datetime)>=2023 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc042b9a-a3ad-4a54-91c5-9e7d0639e84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "earliest_iv_antibiotic_datetime     91.617580\n",
       "min_lactate                         82.182450\n",
       "max_lactate                         82.182450\n",
       "avg_lactate                         82.182450\n",
       "median_lactate                      82.182450\n",
       "infective_endocarditis              95.937170\n",
       "septic_thrombophlebitis            100.000000\n",
       "vascular_graft_infection            94.390575\n",
       "CRBSI                               84.256155\n",
       "infectious_discitis                100.000000\n",
       "epidural_abscess                    89.309772\n",
       "septic_arthritis                    99.954690\n",
       "meningitis                          99.758345\n",
       "meningitis_bacteria                 99.873131\n",
       "cholangitis                         94.076424\n",
       "Line_Presense                       97.806978\n",
       "min_anc                             99.915421\n",
       "max_anc                             99.915421\n",
       "avg_anc                             99.915421\n",
       "median_anc                          99.915421\n",
       "min_alc                             99.915421\n",
       "max_alc                             99.915421\n",
       "avg_alc                             99.915421\n",
       "median_alc                          99.915421\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = Test_set_df.isnull().mean() * 100\n",
    "missing_percentage[missing_percentage>80]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d728dd-829c-499b-ae35-344be6fbb45a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SIRS Criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c2627cb-42aa-4e77-baa0-480633b95200",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['Label'] = (Train_set_df['positive_blood_culture'] | Train_set_df['positive_blood_culture_in_week'])\n",
    "Test_set_df['Label'] = (Test_set_df['positive_blood_culture'] | Test_set_df['positive_blood_culture_in_week'])\n",
    "Val_set_df['Label'] = (Val_set_df['positive_blood_culture'] | Val_set_df['positive_blood_culture_in_week'])\n",
    "\n",
    "\n",
    "Train_set_df['birth_date_jittered'] = pd.to_datetime(Train_set_df['birth_date_jittered'])\n",
    "Train_set_df['blood_culture_order_datetime'] = pd.to_datetime(Train_set_df['blood_culture_order_datetime'])\n",
    "Train_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Train_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "Val_set_df['birth_date_jittered'] = pd.to_datetime(Val_set_df['birth_date_jittered'])\n",
    "Val_set_df['blood_culture_order_datetime'] = pd.to_datetime(Val_set_df['blood_culture_order_datetime'])\n",
    "Val_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Val_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "\n",
    "Test_set_df['birth_date_jittered'] = pd.to_datetime(Test_set_df['birth_date_jittered'])\n",
    "Test_set_df['blood_culture_order_datetime'] = pd.to_datetime(Test_set_df['blood_culture_order_datetime'])\n",
    "Test_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Test_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "\n",
    "# Calculate the difference in hours:\n",
    "Train_set_df['age'] = (Train_set_df['blood_culture_order_datetime'] - Train_set_df['birth_date_jittered']).dt.days \n",
    "Test_set_df['age'] = (Test_set_df['blood_culture_order_datetime'] - Test_set_df['birth_date_jittered']).dt.days #/ 3600\n",
    "Val_set_df['age'] = (Val_set_df['blood_culture_order_datetime'] - Val_set_df['birth_date_jittered']).dt.days #/ 3600\n",
    "\n",
    "Train_set_df['hours_between_cult_abx'] = (Train_set_df['blood_culture_order_datetime'] - Train_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n",
    "Test_set_df['hours_between_cult_abx'] = (Test_set_df['blood_culture_order_datetime'] - Test_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n",
    "Val_set_df['hours_between_cult_abx'] = (Val_set_df['blood_culture_order_datetime'] - Val_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6659b565-d0b6-4bbd-ad40-d562233de5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']\n",
    "Test_set_df['sirs_temp'] = (Test_set_df['max_temp'] > 38) | (Test_set_df['min_temp'] < 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "552cf311-f5b7-4eae-aadd-6c458c8a7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIRS HR\n",
    "Test_set_df['sirs_hr'] = 0\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_heartrate'] > 180) | (Test_set_df['min_heartrate'] < 100)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] >= 30) & (Test_set_df['age'] <= 365)\n",
    "    ),\n",
    "    'sirs_hr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_heartrate'] > 140)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > 365) & (Test_set_df['age'] <= (365*2) )\n",
    "    ),\n",
    "    'sirs_hr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_heartrate'] > 120)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (2*365)) & (Test_set_df['age'] <= (365*5) )\n",
    "    ),\n",
    "    'sirs_hr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_heartrate'] > 118)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (5*365)) & (Test_set_df['age'] <= (365*9) )\n",
    "    ),\n",
    "    'sirs_hr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_heartrate'] > 100)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (9*365)) & (Test_set_df['age'] <= (365*15) )\n",
    "    ),\n",
    "    'sirs_hr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_heartrate'] > 90)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (15*365))\n",
    "    ),\n",
    "    'sirs_hr'\n",
    "] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28c7545b-514b-492c-bb0f-df854f03675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIRS RR\n",
    "Test_set_df['sirs_rr'] = 0\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_resprate'] > 53)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] >= 30) & (Test_set_df['age'] <= 365)\n",
    "    ),\n",
    "    'sirs_rr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_resprate'] > 37)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > 365) & (Test_set_df['age'] <= (365*2) )\n",
    "    ),\n",
    "    'sirs_rr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_resprate'] > 28)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (2*365)) & (Test_set_df['age'] <= (365*5) )\n",
    "    ),\n",
    "    'sirs_rr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_resprate'] > 25)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (5*365)) & (Test_set_df['age'] <= (365*9) )\n",
    "    ),\n",
    "    'sirs_rr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_resprate'] > 20)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (9*365)) & (Test_set_df['age'] <= (365*15) )\n",
    "    ),\n",
    "    'sirs_rr'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_resprate'] > 20)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (15*365))\n",
    "    ),\n",
    "    'sirs_rr'\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0152180e-8d93-4d3a-8492-23e8bfbd6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_df['sirs_wbc'] = 0\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_wbc'] > 17.5) & (Test_set_df['min_wbc'] < 5.5)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] >= 30) & (Test_set_df['age'] <= 365)\n",
    "    ),\n",
    "    'sirs_wbc'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_wbc'] > 17) & (Test_set_df['min_wbc'] < 6)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > 365) & (Test_set_df['age'] <= (365*2) )\n",
    "    ),\n",
    "    'sirs_wbc'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_wbc'] > 15.5)  & (Test_set_df['min_wbc'] < 5.5)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (2*365)) & (Test_set_df['age'] <= (365*5) )\n",
    "    ),\n",
    "    'sirs_wbc'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_wbc'] > 13.5) & (Test_set_df['min_wbc'] < 4.5)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (5*365)) & (Test_set_df['age'] <= (365*9) )\n",
    "    ),\n",
    "    'sirs_wbc'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_wbc'] > 13.5)& (Test_set_df['min_wbc'] < 4.5)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (9*365)) & (Test_set_df['age'] <= (365*12) )\n",
    "    ),\n",
    "    'sirs_wbc'\n",
    "] = 1\n",
    "\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_wbc'] > 13) & (Test_set_df['min_wbc'] < 4.5)\n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (12*365)) & (Test_set_df['age'] <= (365*15) )\n",
    "    ),\n",
    "    'sirs_wbc'\n",
    "] = 1\n",
    "\n",
    "Test_set_df.loc[\n",
    "    (\n",
    "        (Test_set_df['max_wbc'] > 12) & (Test_set_df['min_wbc'] < 4) \n",
    "    ) & (\n",
    "        (Test_set_df['age'] > (15*365))\n",
    "    ),\n",
    "    'sirs_wbc'\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "707aa5d7-c06b-489d-ad97-804ac481fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up SIRS criteria to get a score from 0–4\n",
    "Test_set_df['sirs_score'] = Test_set_df[['sirs_temp', 'sirs_hr', 'sirs_rr', 'sirs_wbc']].sum(axis=1)\n",
    "\n",
    "# Optional: create a binary flag for meeting at least 2 criteria and either temp or wbc positive\n",
    "Test_set_df['sirs_2plus_temp_or_wbc'] = (\n",
    "    (Test_set_df['sirs_temp'] | Test_set_df['sirs_wbc']) &\n",
    "    (Test_set_df['sirs_score'] >= 2))\n",
    "\n",
    "Test_set_df['sirs_2plus'] = (\n",
    "    (Test_set_df['sirs_score'] >= 3))\n",
    "# we should have temp or  wbc to habe hr and rr be counted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba33d353-1560-4b37-937a-890a35a8c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for SIRS score: 0.581\n",
      "Threshold for ~80% sensitivity: 1.000\n",
      "Sensitivity: 0.625\n",
      "Specificity: 0.536\n",
      "PPV: 0.015\n",
      "NPV: 0.992\n"
     ]
    }
   ],
   "source": [
    "# Step 1: AUC\n",
    "auc = roc_auc_score(Test_set_df['Label'], Test_set_df['sirs_2plus'])\n",
    "print(f\"AUC for SIRS score: {auc:.3f}\")\n",
    "\n",
    "# Step 2: ROC\n",
    "fpr, tpr, thresholds = roc_curve(Test_set_df['Label'], Test_set_df['sirs_2plus'])\n",
    "\n",
    "# Step 3: Find threshold for ~80% sensitivity\n",
    "target_sens = 0.80\n",
    "idx = (np.abs(tpr - target_sens)).argmin()\n",
    "best_threshold = thresholds[idx]\n",
    "print(f\"Threshold for ~80% sensitivity: {best_threshold:.3f}\")\n",
    "\n",
    "# Step 4: Binarize\n",
    "y_pred = (Test_set_df['sirs_2plus'] >= best_threshold).astype(int)\n",
    "\n",
    "# Step 5: Confusion matrix (✅ now fixed)\n",
    "tn, fp, fn, tp = confusion_matrix(Test_set_df['Label'], y_pred).ravel()\n",
    "\n",
    "# Step 6: Metrics\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "print(f\"Sensitivity: {sensitivity:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"PPV: {ppv:.3f}\")\n",
    "print(f\"NPV: {npv:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08e8bb81-b0cf-419d-92f0-f5ae7afd403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.529 (95% CI: 0.519–0.541)\n"
     ]
    }
   ],
   "source": [
    "#95% CI\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def bootstrap_auc_ci(y_true, y_score, n_bootstraps=100, ci=0.95, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    bootstrapped_scores = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        # sample with replacement\n",
    "        indices = rng.choice(np.arange(len(y_true)), size=len(y_true), replace=True)\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue  # skip if no positive or negative cases\n",
    "        score = roc_auc_score(y_true[indices], y_score[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "\n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "\n",
    "    # Compute lower and upper bound of CI\n",
    "    lower_bound = np.percentile(sorted_scores, (1 - ci) / 2 * 100)\n",
    "    upper_bound = np.percentile(sorted_scores, (1 + ci) / 2 * 100)\n",
    "\n",
    "    return roc_auc_score(y_true, y_score), (lower_bound, upper_bound)\n",
    "\n",
    "y_true = Test_set_df['Label'].values\n",
    "y_score = Test_set_df['sirs_2plus_temp_or_wbc'].values\n",
    "\n",
    "auc, (ci_lower, ci_upper) = bootstrap_auc_ci(y_true, y_score)\n",
    "print(f\"AUC: {auc:.3f} (95% CI: {ci_lower:.3f}–{ci_upper:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce1acf6d-b731-4441-ae18-ecd0afd7d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for ~90% Sensitivity: 3.00\n",
      "Sensitivity: 0.921\n",
      "Specificity: 0.092\n",
      "PPV: 0.012\n",
      "NPV: 0.990\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_score, recall_score\n",
    "\n",
    "y_true = Test_set_df['Label']\n",
    "y_scores = Test_set_df['sirs_score']  # Or predicted probabilities from a model\n",
    "\n",
    "\n",
    "# Get fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "\n",
    "# Find threshold for 90% sensitivity\n",
    "target_sensitivity = 0.75\n",
    "idx = (np.abs(tpr - target_sensitivity)).argmin()\n",
    "best_threshold = thresholds[idx]\n",
    "\n",
    "# Apply threshold to get binary predictions\n",
    "y_pred = (y_scores >= best_threshold).astype(int)\n",
    "\n",
    "# Confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "specificity = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp)\n",
    "npv = tn / (tn + fn)\n",
    "\n",
    "print(f\"Threshold for ~90% Sensitivity: {best_threshold:.2f}\")\n",
    "print(f\"Sensitivity: {tpr[idx]:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"PPV: {ppv:.3f}\")\n",
    "print(f\"NPV: {npv:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f950460-96bf-4d90-b446-a8558d095c56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46007755-4f88-41a0-90a2-323bace2811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['birth_date_jittered'] = pd.to_datetime(Train_set_df['birth_date_jittered'])\n",
    "Train_set_df['blood_culture_order_datetime'] = pd.to_datetime(Train_set_df['blood_culture_order_datetime'])\n",
    "Train_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Train_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "Val_set_df['birth_date_jittered'] = pd.to_datetime(Val_set_df['birth_date_jittered'])\n",
    "Val_set_df['blood_culture_order_datetime'] = pd.to_datetime(Val_set_df['blood_culture_order_datetime'])\n",
    "Val_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Val_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "\n",
    "Test_set_df['birth_date_jittered'] = pd.to_datetime(Test_set_df['birth_date_jittered'])\n",
    "Test_set_df['blood_culture_order_datetime'] = pd.to_datetime(Test_set_df['blood_culture_order_datetime'])\n",
    "Test_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Test_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "\n",
    "# Calculate the difference in hours:\n",
    "Train_set_df['age'] = (Train_set_df['blood_culture_order_datetime'] - Train_set_df['birth_date_jittered']).dt.days \n",
    "Test_set_df['age'] = (Test_set_df['blood_culture_order_datetime'] - Test_set_df['birth_date_jittered']).dt.days #/ 3600\n",
    "Val_set_df['age'] = (Val_set_df['blood_culture_order_datetime'] - Val_set_df['birth_date_jittered']).dt.days #/ 3600\n",
    "\n",
    "Train_set_df['hours_between_cult_abx'] = (Train_set_df['blood_culture_order_datetime'] - Train_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n",
    "Test_set_df['hours_between_cult_abx'] = (Test_set_df['blood_culture_order_datetime'] - Test_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n",
    "Val_set_df['hours_between_cult_abx'] = (Val_set_df['blood_culture_order_datetime'] - Val_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30797dbb-c452-43a8-b880-817d5f246b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded',\n",
       "       'blood_culture_order_datetime', 'birth_date_jittered', 'bmi',\n",
       "       'positive_blood_culture', 'positive_blood_culture_in_week',\n",
       "       'earliest_iv_antibiotic_datetime', 'min_heartrate',\n",
       "       'max_heartrate', 'avg_heartrate', 'median_heartrate',\n",
       "       'min_resprate', 'max_resprate', 'avg_resprate', 'median_resprate',\n",
       "       'min_temp', 'max_temp', 'avg_temp', 'median_temp', 'min_sysbp',\n",
       "       'max_sysbp', 'avg_sysbp', 'median_sysbp', 'min_diasbp',\n",
       "       'max_diasbp', 'avg_diasbp', 'median_diasbp', 'min_wbc', 'max_wbc',\n",
       "       'avg_wbc', 'median_wbc', 'min_neutrophils', 'max_neutrophils',\n",
       "       'avg_neutrophils', 'median_neutrophils', 'min_lymphocytes',\n",
       "       'max_lymphocytes', 'avg_lymphocytes', 'median_lymphocytes',\n",
       "       'min_hgb', 'max_hgb', 'avg_hgb', 'median_hgb', 'min_plt',\n",
       "       'max_plt', 'avg_plt', 'median_plt', 'min_na', 'max_na', 'avg_na',\n",
       "       'median_na', 'min_hco3', 'max_hco3', 'avg_hco3', 'median_hco3',\n",
       "       'min_bun', 'max_bun', 'avg_bun', 'median_bun', 'min_cr', 'max_cr',\n",
       "       'avg_cr', 'median_cr', 'min_lactate', 'max_lactate', 'avg_lactate',\n",
       "       'median_lactate', 'min_procalcitonin', 'max_procalcitonin',\n",
       "       'avg_procalcitonin', 'median_procalcitonin', 'gender', 'race',\n",
       "       'bacteremia', 'septic_shock', 'infective_endocarditis',\n",
       "       'septic_thrombophlebitis', 'vascular_graft_infection', 'CRBSI',\n",
       "       'infectious_discitis', 'epidural_abscess', 'septic_arthritis',\n",
       "       'meningitis', 'meningitis_bacteria', 'cholangitis',\n",
       "       'bacterial_cholangitis', 'pyelonephritis',\n",
       "       'acute_bacterial_pyelonephritis', 'severe_pneumonia',\n",
       "       'acute_hematogenous_osteomyelitis', 'asplenia',\n",
       "       'immunocompromised_state', 'severe_cellulitis', 'cystitis',\n",
       "       'prostatitis', 'CAP', 'diabetic_foot_infection', 'colitis',\n",
       "       'aspiration_pneumonia', 'uncomplicated_cholecystitis',\n",
       "       'uncomplicated_diverticulitis', 'Uncomplicated_pancreatitis',\n",
       "       'vanc', 'zosyn', 'vanc_zosyn', 'other_ABX', 'Leukocyte_Esterase',\n",
       "       'WBC_urine', 'Bacteria_urine', 'Nitrite_urine', 'Line_Presense',\n",
       "       'Transplant', 'min_anc', 'max_anc', 'avg_anc', 'median_anc',\n",
       "       'min_alc', 'max_alc', 'avg_alc', 'median_alc', 'min_spo2',\n",
       "       'max_spo2', 'avg_spo2', 'median_spo2', 'age',\n",
       "       'hours_between_cult_abx'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf900fd-3b9d-4405-bf9e-b4821b58d085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02099527-869b-4728-a220-f5d583164aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifiers=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']\n",
    "Labels=['positive_blood_culture','positive_blood_culture_in_week']\n",
    "Labs=['min_heartrate','max_heartrate', 'avg_heartrate', 'median_heartrate',\n",
    "       'min_resprate', 'max_resprate', 'avg_resprate', 'median_resprate',\n",
    "       'min_temp', 'max_temp', 'avg_temp', 'median_temp', 'min_sysbp',\n",
    "       'max_sysbp', 'avg_sysbp', 'median_sysbp', 'min_diasbp',\n",
    "       'max_diasbp', 'avg_diasbp', 'median_diasbp', 'min_wbc', 'max_wbc',\n",
    "       'avg_wbc', 'median_wbc', 'min_neutrophils', 'max_neutrophils',\n",
    "       'avg_neutrophils', 'median_neutrophils', 'min_lymphocytes',\n",
    "       'max_lymphocytes', 'avg_lymphocytes', 'median_lymphocytes',\n",
    "       'min_hgb', 'max_hgb', 'avg_hgb', 'median_hgb', 'min_plt',\n",
    "       'max_plt', 'avg_plt', 'median_plt', 'min_na', 'max_na', 'avg_na',\n",
    "       'median_na', 'min_hco3', 'max_hco3', 'avg_hco3', 'median_hco3',\n",
    "       'min_bun', 'max_bun', 'avg_bun', 'median_bun', 'min_cr', 'max_cr',\n",
    "       'avg_cr', 'median_cr', 'min_lactate', 'max_lactate', 'avg_lactate',\n",
    "       'median_lactate', 'min_procalcitonin', 'max_procalcitonin',\n",
    "       'avg_procalcitonin', 'median_procalcitonin','Leukocyte_Esterase',\n",
    "       'WBC_urine', 'Bacteria_urine','Nitrite_urine', \n",
    "      'min_anc', 'max_anc', 'avg_anc', 'median_anc',\n",
    "       'min_alc', 'max_alc', 'avg_alc', 'median_alc', 'min_spo2',\n",
    "       'max_spo2', 'avg_spo2', 'median_spo2']\n",
    "Demos=[ 'gender','age','bmi']\n",
    "ABX=['vanc', 'zosyn', 'vanc_zosyn', 'other_ABX']\n",
    "Time_Varient_features=['hours_between_cult_abx']\n",
    "Diagnosis= ['Line_Presense','Transplant'] #bacteremia', 'septic_shock', 'infective_endocarditis',\n",
    "      # 'septic_thrombophlebitis', 'vascular_graft_infection', 'CRBSI',\n",
    "      # 'infectious_discitis', 'epidural_abscess', 'septic_arthritis',\n",
    "      # 'meningitis', 'meningitis_bacteria', 'cholangitis',\n",
    "      # 'bacterial_cholangitis', 'pyelonephritis',\n",
    "      # 'acute_bacterial_pyelonephritis', 'severe_pneumonia',\n",
    "      # 'acute_hematogenous_osteomyelitis', 'asplenia',\n",
    "      # 'immunocompromised_state', 'severe_cellulitis', 'cystitis',\n",
    "      # 'prostatitis', 'CAP', 'diabetic_foot_infection', 'colitis',\n",
    "      # 'aspiration_pneumonia', 'uncomplicated_cholecystitis',\n",
    "      # 'uncomplicated_diverticulitis', 'Uncomplicated_pancreatitis',\n",
    "Feature_set=Identifiers+Labels+Labs+Demos+Diagnosis#+Time_Varient_features+ABX\n",
    "Train_set_df=Train_set_df[Feature_set]\n",
    "Test_set_df=Test_set_df[Feature_set]\n",
    "Val_set_df=Val_set_df[Feature_set]\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee0147ae-4e18-4840-a308-3f0302dbf2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df.drop_duplicates(subset=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'],inplace=True)\n",
    "Val_set_df.drop_duplicates(subset=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'],inplace=True)\n",
    "Test_set_df.drop_duplicates(subset=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c92dd54-4574-4732-b45c-fde4945d5191",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['datapoint'] = Train_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n",
    "Test_set_df['datapoint'] = Train_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n",
    "Val_set_df['datapoint'] = Val_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "843066a9-c44a-42e8-9f34-7e43af67fab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'NEGATIVE', 'POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df.Bacteria_urine.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d350492-971f-4574-846d-f1dcf833a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['gender'] = Train_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
    "Test_set_df['gender'] = Test_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
    "Val_set_df['gender'] = Val_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
    "\n",
    "\n",
    "Train_set_df['Leukocyte_Esterase'] = Train_set_df['Leukocyte_Esterase'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Test_set_df['Leukocyte_Esterase'] = Test_set_df['Leukocyte_Esterase'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Val_set_df['Leukocyte_Esterase'] = Val_set_df['Leukocyte_Esterase'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "\n",
    "\n",
    "Train_set_df['WBC_urine'] = Train_set_df['WBC_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Test_set_df['WBC_urine'] = Test_set_df['WBC_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Val_set_df['WBC_urine'] = Val_set_df['WBC_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "\n",
    "\n",
    "Train_set_df['Bacteria_urine'] = Train_set_df['Bacteria_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Test_set_df['Bacteria_urine'] = Test_set_df['Bacteria_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Val_set_df['Bacteria_urine'] = Val_set_df['Bacteria_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "\n",
    "\n",
    "Train_set_df['Nitrite_urine'] = Train_set_df['Nitrite_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Test_set_df['Nitrite_urine'] = Test_set_df['Nitrite_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Val_set_df['Nitrite_urine'] = Val_set_df['Nitrite_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "\n",
    "\n",
    "Train_set_df['ET_Tube'] = Train_set_df['Line_Presense'].apply(lambda x: 1 if x == 'ET_Tube' else 0)\n",
    "Test_set_df['ET_Tube'] = Test_set_df['Line_Presense'].apply(lambda x: 1 if x == 'ET_Tube' else 0 )\n",
    "Val_set_df['ET_Tube'] = Val_set_df['Line_Presense'].apply(lambda x: 1 if x == 'ET_Tube' else 0)\n",
    "\n",
    "\n",
    "\n",
    "Train_set_df['otherline'] = Train_set_df['Line_Presense'].apply(lambda x: 1 if x == 'otherline' else 0)\n",
    "Test_set_df['otherline'] = Test_set_df['Line_Presense'].apply(lambda x: 1 if x == 'otherline' else 0 )\n",
    "Val_set_df['otherline'] = Val_set_df['Line_Presense'].apply(lambda x: 1 if x == 'otherline' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cac54fc5-06b9-4b62-ab49-342da1b3c599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26829"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df.shape[0]+Test_set_df.shape[0]+Val_set_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c496ef-6128-4337-9421-258b4f361d39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0e9f6532-36d3-4f60-bc0e-2d7c790f605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from fancyimpute import IterativeImputer as FancyIterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1a0375e1-3540-4b7a-aed5-c31a6f229c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'bmi', 'avg_neutrophils', 'age', 'max_na', 'max_heartrate', 'median_procalcitonin', \n",
    "    'min_temp', 'avg_lymphocytes', 'min_diasbp', 'avg_spo2', 'min_resprate', 'max_hco3', \n",
    "    'min_wbc', 'min_hgb', 'median_bun', 'max_cr', 'ET_Tube', 'WBC_urine', 'Bacteria_urine', 'Leukocyte_Esterase',\n",
    "    'positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded',\n",
    "    'datapoint','Line_Presense']\n",
    "Train_set_df=Train_set_df[selected_features]\n",
    "Test_set_df=Test_set_df[selected_features]\n",
    "Val_set_df=Val_set_df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e7a9a5c1-842b-482d-a3f6-cb5b068e4fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3b/31jnsf8150z57g6vqxxwj3vw0000gp/T/ipykernel_97924/4149568682.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Train_set_df['Label'] = (Train_set_df['positive_blood_culture'] | Train_set_df['positive_blood_culture_in_week'])\n"
     ]
    }
   ],
   "source": [
    "Train_set_df['Label'] = (Train_set_df['positive_blood_culture'] | Train_set_df['positive_blood_culture_in_week'])\n",
    "Test_set_df['Label'] = (Test_set_df['positive_blood_culture'] | Test_set_df['positive_blood_culture_in_week'])\n",
    "Val_set_df['Label'] = (Val_set_df['positive_blood_culture'] | Val_set_df['positive_blood_culture_in_week'])\n",
    "\n",
    "X_train = Train_set_df.drop(columns=['Label','positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint','Line_Presense'])#\n",
    "y_train = Train_set_df['Label']\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = Test_set_df.drop(columns=['Label','positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint','Line_Presense'])#\n",
    "y_test = Test_set_df['Label']\n",
    "\n",
    "\n",
    "X_val = Val_set_df.drop(columns=['Label','positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint','Line_Presense'])#\n",
    "y_val = Val_set_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ff3b038e-e8e8-40ee-a1d9-db4f90dd10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.dropna(axis=1, how='all')\n",
    "X_val = X_val[X_train.columns]\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3c3e0c3b-aa5f-42a0-a57d-4a5832db4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(X_train)  \n",
    "X_train = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
    "X_val = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1f6bc04b-b53e-4c7c-a0a4-6914d9ff3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the training, test, and validation data\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e8483884-e135-45d5-896b-96c98ef9f75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[0, 1]\n",
       "Length: 2, dtype: Int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5a6b34be-7707-4296-a850-535f964387bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Compute class weights \n",
    "\n",
    "# Count number of samples per class\n",
    "\"\"\"\n",
    "counts = pd.Series(y_train).value_counts().to_dict()\n",
    "\n",
    "# Total samples\n",
    "total = len(y_train)\n",
    "\n",
    "# Manually compute weight for each class (e.g., scale positive more heavily)\n",
    "class_weights = {\n",
    "    0: 1.0,  # keep negative as baseline\n",
    "    1: total / (2 * counts[1])  # scale positive inversely proportional to its count\n",
    "}\n",
    "\"\"\"\n",
    "# for higher sensitivity avoid scaling posetive cases\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array([0, 1]),\n",
    "    y=y_train \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c3ebfc61-9466-4f7e-8161-b7bde0a41537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for the test set with L2 regularization: 0.7329\n",
      "AUC for the train set with L2 regularization: 0.7572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Map into dict\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "\n",
    "model_l2 = LogisticRegression(max_iter=10000,class_weight=class_weight_dict, C=0.01, penalty='l2',solver='lbfgs')\n",
    "model_l2.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_prob_l2 = model_l2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the AUC\n",
    "auc_l2 = roc_auc_score(y_test, y_pred_prob_l2)\n",
    "print(f\"AUC for the test set with L2 regularization: {auc_l2:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate the AUC\n",
    "yt_pred_prob_l2 = model_l2.predict_proba(X_val)[:, 1]\n",
    "auc_l2 = roc_auc_score(y_val, yt_pred_prob_l2)\n",
    "print(f\"AUC for the val set with L2 regularization: {auc_l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7dd14d50-6bc2-4fa0-a328-e925d1b0060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4066\n",
      "Sensitivity: 0.9074\n",
      "Specificity: 0.3618\n",
      "PPV (Precision): 0.0439\n",
      "NPV: 0.9918\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_l2)\n",
    "\n",
    "# Find the threshold where sensitivity (TPR) >= 0.9\n",
    "threshold_index = np.argmax(tpr >= 0.9)\n",
    "optimal_threshold = thresholds[threshold_index]\n",
    "\n",
    "# Use the optimal threshold to make binary predictions\n",
    "y_pred_optimal = (y_pred_prob_l2 >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_optimal).ravel()\n",
    "\n",
    "# Calculate sensitivity, specificity, PPV, and NPV\n",
    "sensitivity = tp / (tp + fn)  # Sensitivity or Recall\n",
    "specificity = tn / (tn + fp)  # Specificity\n",
    "ppv = tp / (tp + fp)          # Positive Predictive Value (Precision)\n",
    "npv = tn / (tn + fn)          # Negative Predictive Value\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"PPV (Precision): {ppv:.4f}\")\n",
    "print(f\"NPV: {npv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e70d0ff7-cf0d-49c0-a73f-f7c273fc3443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for AUC: (0.6844405769013293, 0.7786331324344548)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "y_pred_prob =  model_l2.predict_proba(X_test) [:,1]\n",
    "\n",
    "\n",
    "# Step 2: Bootstrap resampling\n",
    "n_iterations = 1000  # Number of bootstrap samples\n",
    "auc_scores = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Resample the data with replacement (X_test and y_test)\n",
    "    X_resampled, y_resampled = resample(X_test, y_test, replace=True)\n",
    "       \n",
    "    # Get the predicted probabilities for the resampled data\n",
    "    y_pred_prob_resampled =  model_l2.predict_proba(X_resampled)[:,1]\n",
    "    \n",
    "    # Calculate the AUC score for the resampled data\n",
    "    auc = roc_auc_score(y_resampled, y_pred_prob_resampled)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Step 3: Calculate the 95% confidence interval for AUC\n",
    "ci_lower = np.percentile(auc_scores, 2.5)\n",
    "ci_upper = np.percentile(auc_scores, 97.5)\n",
    "\n",
    "print(f\"95% confidence interval for AUC: ({ci_lower}, {ci_upper})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f67c6-e8e7-4d10-9237-b942acc8c9be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pointing system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e0c20063-c13f-4d4a-9332-e7ea3a2dbece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: median_procalcitonin, Coefficient: 0.6050\n",
      "Feature: bmi, Coefficient: -0.4810\n",
      "Feature: age, Coefficient: 0.2644\n",
      "Feature: min_hgb, Coefficient: -0.2125\n",
      "Feature: max_heartrate, Coefficient: 0.1852\n",
      "Feature: avg_neutrophils, Coefficient: 0.1634\n",
      "Feature: median_bun, Coefficient: 0.1507\n",
      "Feature: max_na, Coefficient: -0.1102\n",
      "Feature: avg_lymphocytes, Coefficient: -0.0980\n",
      "Feature: WBC_urine, Coefficient: 0.0909\n",
      "Feature: min_resprate, Coefficient: 0.0816\n",
      "Feature: min_temp, Coefficient: 0.0710\n",
      "Feature: Bacteria_urine, Coefficient: 0.0598\n",
      "Feature: ET_Tube, Coefficient: 0.0587\n",
      "Feature: Leukocyte_Esterase, Coefficient: 0.0494\n",
      "Feature: max_hco3, Coefficient: 0.0239\n",
      "Feature: avg_spo2, Coefficient: 0.0041\n",
      "Feature: min_wbc, Coefficient: -0.0009\n",
      "Feature: min_diasbp, Coefficient: -0.0009\n",
      "Feature: max_cr, Coefficient: 0.0008\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get coefficients and feature names\n",
    "coefficients = model_l2.coef_[0]\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# 1. Find nonzero coefficients\n",
    "non_zero_indices = np.where(coefficients != 0)[0]\n",
    "non_zero_features = feature_names[non_zero_indices]\n",
    "non_zero_coefficients = coefficients[non_zero_indices]\n",
    "\n",
    "# 2. Sort by absolute value of coefficients\n",
    "sorted_indices = np.argsort(-np.abs(non_zero_coefficients))  # negative sign for descending sort\n",
    "sorted_features = non_zero_features[sorted_indices]\n",
    "sorted_coefficients = non_zero_coefficients[sorted_indices]\n",
    "\n",
    "# 3. Print sorted features and coefficients\n",
    "for feature, coef in zip(sorted_features, sorted_coefficients):\n",
    "    print(f\"Feature: {feature}, Coefficient: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4835a963-81ed-44d0-a79d-5cb10e0fc156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Equation:\n",
      "logit(P) = -0.16 + -0.48 * bmi + 0.16 * avg_neutrophils + 0.26 * age + -0.11 * max_na + 0.19 * max_heartrate + 0.61 * median_procalcitonin + 0.07 * min_temp + -0.1 * avg_lymphocytes + 0.08 * min_resprate + 0.02 * max_hco3 + -0.21 * min_hgb + 0.15 * median_bun + 0.06 * ET_Tube + 0.09 * WBC_urine + 0.06 * Bacteria_urine + 0.05 * Leukocyte_Esterase\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get original coefficients and intercept\n",
    "coefficients = model_l2.coef_[0]\n",
    "intercept = model_l2.intercept_[0]\n",
    "feature_names = X_train.columns  # or replace with your feature list\n",
    "\n",
    "# Round the coefficients\n",
    "rounded_coefficients = np.round(coefficients, 2)\n",
    "\n",
    "# Filter: keep only coefficients that are non-zero **after rounding**\n",
    "non_zero_mask = rounded_coefficients != 0\n",
    "non_zero_coefficients = rounded_coefficients[non_zero_mask]\n",
    "non_zero_features = feature_names[non_zero_mask]\n",
    "\n",
    "# Round intercept\n",
    "rounded_intercept = np.round(intercept, 2)\n",
    "\n",
    "# Build the logistic regression equation\n",
    "equation_terms = [f\"{coef} * {name}\" for coef, name in zip(non_zero_coefficients, non_zero_features)]\n",
    "equation = \" + \".join(equation_terms)\n",
    "full_equation = f\"logit(P) = {rounded_intercept} + {equation}\"\n",
    "\n",
    "# Print the equation\n",
    "print(\"Logistic Regression Equation:\")\n",
    "print(full_equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8e86eb47-4670-435f-8b38-4bb0d37c9097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Equation:\n",
      "logit(P) = -0.16 + -0.48 * bmi + 0.16 * avg_neutrophils + 0.26 * age + -0.11 * max_na + 0.19 * max_heartrate + 0.61 * median_procalcitonin + 0.07 * min_temp + -0.1 * avg_lymphocytes + 0.08 * min_resprate + 0.02 * max_hco3 + -0.21 * min_hgb + 0.15 * median_bun + 0.06 * ET_Tube + 0.09 * WBC_urine + 0.06 * Bacteria_urine + 0.05 * Leukocyte_Esterase\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get original coefficients and intercept\n",
    "coefficients = model_l2.coef_[0]\n",
    "intercept = model_l2.intercept_[0]\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Round the coefficients\n",
    "rounded_coefficients = np.round(coefficients, 2)\n",
    "\n",
    "# Filter: keep only coefficients that are non-zero **after rounding**\n",
    "non_zero_mask = rounded_coefficients != 0\n",
    "non_zero_coefficients = rounded_coefficients[non_zero_mask]\n",
    "non_zero_features = feature_names[non_zero_mask]\n",
    "\n",
    "# Now select only the top 6 features\n",
    "selected_features = [\n",
    "    'bmi', \n",
    "    'avg_neutrophils', \n",
    "    'age', \n",
    "    'max_na', \n",
    "    'max_heartrate', \n",
    "    'median_procalcitonin', \n",
    "    'min_temp', \n",
    "    'avg_lymphocytes', \n",
    "    'min_diasbp', \n",
    "    'avg_spo2', \n",
    "    'min_resprate', \n",
    "    'max_hco3', \n",
    "    'min_wbc', \n",
    "    'min_hgb', \n",
    "    'median_bun', \n",
    "    'max_cr', \n",
    "    'ET_Tube', \n",
    "    'WBC_urine', \n",
    "    'Bacteria_urine', \n",
    "    'Leukocyte_Esterase'\n",
    "]\n",
    "\n",
    "# Mask for selected features\n",
    "selected_mask = np.isin(non_zero_features, selected_features)\n",
    "\n",
    "selected_coefficients = non_zero_coefficients[selected_mask]\n",
    "selected_feature_names = non_zero_features[selected_mask]\n",
    "\n",
    "# Round intercept\n",
    "rounded_intercept = np.round(intercept, 2)\n",
    "\n",
    "# Build the logistic regression equation\n",
    "equation_terms = [f\"{coef} * {name}\" for coef, name in zip(selected_coefficients, selected_feature_names)]\n",
    "equation = \" + \".join(equation_terms)\n",
    "full_equation = f\"logit(P) = {rounded_intercept} + {equation}\"\n",
    "\n",
    "print(\"Logistic Regression Equation:\")\n",
    "print(full_equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "60f25bdf-62ca-427b-af2b-a06456737964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Feature  Coefficient  \\\n",
      "bmi                                    bmi      -0.4664   \n",
      "avg_neutrophils            avg_neutrophils       0.3382   \n",
      "age                                    age       0.2440   \n",
      "max_na                              max_na      -0.2402   \n",
      "max_heartrate                max_heartrate       0.2359   \n",
      "median_procalcitonin  median_procalcitonin       0.2209   \n",
      "min_temp                          min_temp       0.2194   \n",
      "avg_lymphocytes            avg_lymphocytes      -0.2002   \n",
      "min_diasbp                      min_diasbp       0.1982   \n",
      "avg_spo2                          avg_spo2      -0.1810   \n",
      "max_hco3                          max_hco3      -0.1357   \n",
      "min_resprate                  min_resprate       0.1427   \n",
      "min_hgb                            min_hgb      -0.0963   \n",
      "min_wbc                            min_wbc       0.0863   \n",
      "WBC_urine                        WBC_urine       0.0896   \n",
      "median_bun                      median_bun       0.0579   \n",
      "Leukocyte_Esterase      Leukocyte_Esterase       0.0579   \n",
      "ET_Tube                            ET_Tube       0.0544   \n",
      "Bacteria_urine              Bacteria_urine       0.0542   \n",
      "max_cr                              max_cr      -0.0391   \n",
      "\n",
      "                      Baseline (real units)  Points per Unit  \n",
      "bmi                                   18.43             0.47  \n",
      "avg_neutrophils                       21.50             0.34  \n",
      "age                                 1676.00             0.24  \n",
      "max_na                               136.00             0.24  \n",
      "max_heartrate                        140.00             0.24  \n",
      "median_procalcitonin                   0.24             0.22  \n",
      "min_temp                              99.10             0.22  \n",
      "avg_lymphocytes                       32.00             0.20  \n",
      "min_diasbp                            65.00             0.20  \n",
      "avg_spo2                              98.67             0.18  \n",
      "max_hco3                              23.00             0.14  \n",
      "min_resprate                          22.00             0.14  \n",
      "min_hgb                            11500.00             0.10  \n",
      "min_wbc                                9.10             0.09  \n",
      "WBC_urine                              0.00             0.09  \n",
      "median_bun                            11.00             0.06  \n",
      "Leukocyte_Esterase                     0.00             0.06  \n",
      "ET_Tube                                0.00             0.05  \n",
      "Bacteria_urine                         0.00             0.05  \n",
      "max_cr                                 0.40             0.04  \n"
     ]
    }
   ],
   "source": [
    "selected_features = [\n",
    "    'bmi', 'avg_neutrophils', 'age', 'max_na', 'max_heartrate', 'median_procalcitonin', \n",
    "    'min_temp', 'avg_lymphocytes', 'min_diasbp', 'avg_spo2', 'min_resprate', 'max_hco3', \n",
    "    'min_wbc', 'min_hgb', 'median_bun', 'max_cr', 'ET_Tube', 'WBC_urine', 'Bacteria_urine', 'Leukocyte_Esterase'\n",
    "]\n",
    "\n",
    "coefficients = np.array([\n",
    "    -0.4664, 0.3382, 0.2440, -0.2402, 0.2359, 0.2209, 0.2194, -0.2002,\n",
    "    0.1982, -0.1810, 0.1427, -0.1357, 0.0863, -0.0963, 0.0579, -0.0391,\n",
    "    0.0544, 0.0896, 0.0542, 0.0579\n",
    "])\n",
    "\n",
    "# 1. Get scaler mean and std for each feature\n",
    "feature_means = pd.Series(scaler.mean_, index=scaler.feature_names_in_)\n",
    "feature_stds = pd.Series(np.sqrt(scaler.var_), index=scaler.feature_names_in_)\n",
    "\n",
    "# 2. Median (standardized space) from X_train\n",
    "baseline_standardized = X_train[selected_features].median()\n",
    "\n",
    "# 3. Reverse standardization\n",
    "baseline_real = baseline_standardized * feature_stds[selected_features] + feature_means[selected_features]\n",
    "\n",
    "#4.\n",
    "points_per_feature = np.abs(coefficients)\n",
    "\n",
    "\n",
    "#5 Build the new pointing table\n",
    "points_table = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Coefficient': coefficients,\n",
    "    'Baseline (real units)': baseline_real.round(2),\n",
    "    'Points per Unit': np.abs(coefficients).round(2)\n",
    "})\n",
    "\n",
    "# Step 2: Display it sorted\n",
    "points_table = points_table.sort_values(by='Points per Unit', ascending=False)\n",
    "\n",
    "print(points_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9f1079f9-082b-4401-bad5-55910e010826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 28\n"
     ]
    }
   ],
   "source": [
    "selected_features = [\n",
    "    'bmi', 'avg_neutrophils', 'age', 'max_na', 'max_heartrate', 'median_procalcitonin', \n",
    "    'min_temp', 'avg_lymphocytes', 'min_diasbp', 'avg_spo2', 'min_resprate', 'max_hco3', \n",
    "    'min_wbc', 'min_hgb', 'median_bun', 'max_cr', 'ET_Tube', 'WBC_urine', 'Bacteria_urine', 'Leukocyte_Esterase'\n",
    "]\n",
    "\n",
    "\n",
    "def calculate_patient_points(patient):\n",
    "    score = 0\n",
    "    \n",
    "    if patient['bmi'] < 18.4:\n",
    "        score += 5\n",
    "    if patient['avg_neutrophils'] > 21.5:\n",
    "        score += 3\n",
    "    if patient['age'] > 5:\n",
    "        score += 2\n",
    "    if patient['max_na'] < 136.0:\n",
    "        score += 2\n",
    "    if patient['max_heartrate'] > 140.0:\n",
    "        score += 2\n",
    "    if patient['median_procalcitonin'] > 0.22:\n",
    "        score += 2\n",
    "    if patient['min_temp'] > 99.1:\n",
    "        score += 2\n",
    "    if patient['avg_lymphocytes'] < 32.0:\n",
    "        score += 2\n",
    "    if patient['min_diasbp'] > 65.0:\n",
    "        score += 2\n",
    "    if patient['avg_spo2'] < 98.7:\n",
    "        score += 2\n",
    "    if patient['max_hco3'] < 23.0:\n",
    "        score += 1\n",
    "    if patient['min_resprate'] > 22.0:\n",
    "        score += 1\n",
    "    if patient['min_hgb'] < 11500:\n",
    "        score += 1\n",
    "    if patient['min_wbc'] > 9.1:\n",
    "        score += 1\n",
    "    if patient['WBC_urine'] == 1:\n",
    "        score += 1\n",
    "    if patient['median_bun'] > 11:\n",
    "        score += 1\n",
    "    if patient['Leukocyte_Esterase'] == 1:\n",
    "        score += 1\n",
    "    if patient['ET_Tube'] == 1:\n",
    "        score += 1\n",
    "    if patient['Bacteria_urine'] == 1:\n",
    "        score += 1\n",
    "    \n",
    "    return score\n",
    "\n",
    "X_test_real = X_test[selected_features] * feature_stds[selected_features] + feature_means[selected_features]\n",
    "scores = X_test_real[selected_features].apply(calculate_patient_points, axis=1)\n",
    "min_score = scores.min()\n",
    "max_score = scores.max()\n",
    "print(min_score,max_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "263abe6a-f560-4ce0-8697-8e7854a16078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Threshold': 0.0,\n",
       "  'Sensitivity': 1.0,\n",
       "  'Specificity': 0.0,\n",
       "  'PPV': 0.031286210892236384,\n",
       "  'NPV': 0,\n",
       "  'Accuracy': 0.031286210892236384},\n",
       " {'Threshold': 1.0,\n",
       "  'Sensitivity': 1.0,\n",
       "  'Specificity': 0.00687799043062201,\n",
       "  'PPV': 0.031496062992125984,\n",
       "  'NPV': 1.0,\n",
       "  'Accuracy': 0.03794901506373117},\n",
       " {'Threshold': 2.0,\n",
       "  'Sensitivity': 0.9814814814814815,\n",
       "  'Specificity': 0.020035885167464115,\n",
       "  'PPV': 0.03133313626958321,\n",
       "  'NPV': 0.9710144927536232,\n",
       "  'Accuracy': 0.05011587485515643},\n",
       " {'Threshold': 3.0,\n",
       "  'Sensitivity': 0.9814814814814815,\n",
       "  'Specificity': 0.04724880382775119,\n",
       "  'PPV': 0.03219927095990279,\n",
       "  'NPV': 0.9875,\n",
       "  'Accuracy': 0.07647740440324449},\n",
       " {'Threshold': 4.0,\n",
       "  'Sensitivity': 0.9814814814814815,\n",
       "  'Specificity': 0.07954545454545454,\n",
       "  'PPV': 0.03329145728643216,\n",
       "  'NPV': 0.9925373134328358,\n",
       "  'Accuracy': 0.10776361529548088},\n",
       " {'Threshold': 5.0,\n",
       "  'Sensitivity': 0.9351851851851852,\n",
       "  'Specificity': 0.11931818181818182,\n",
       "  'PPV': 0.03315824031516743,\n",
       "  'NPV': 0.9827586206896551,\n",
       "  'Accuracy': 0.14484356894553882},\n",
       " {'Threshold': 6.0,\n",
       "  'Sensitivity': 0.9259259259259259,\n",
       "  'Specificity': 0.17464114832535885,\n",
       "  'PPV': 0.03496503496503497,\n",
       "  'NPV': 0.9864864864864865,\n",
       "  'Accuracy': 0.1981460023174971},\n",
       " {'Threshold': 7.0,\n",
       "  'Sensitivity': 0.9074074074074074,\n",
       "  'Specificity': 0.22757177033492823,\n",
       "  'PPV': 0.03655352480417755,\n",
       "  'NPV': 0.9870298313878081,\n",
       "  'Accuracy': 0.2488412514484357},\n",
       " {'Threshold': 8.0,\n",
       "  'Sensitivity': 0.9074074074074074,\n",
       "  'Specificity': 0.28438995215311,\n",
       "  'PPV': 0.039341629867523084,\n",
       "  'NPV': 0.9895941727367326,\n",
       "  'Accuracy': 0.3038818076477404},\n",
       " {'Threshold': 9.0,\n",
       "  'Sensitivity': 0.8703703703703703,\n",
       "  'Specificity': 0.3576555023923445,\n",
       "  'PPV': 0.04192685102586976,\n",
       "  'NPV': 0.9884297520661157,\n",
       "  'Accuracy': 0.37369640787949016},\n",
       " {'Threshold': 10.0,\n",
       "  'Sensitivity': 0.7685185185185185,\n",
       "  'Specificity': 0.4395933014354067,\n",
       "  'PPV': 0.04241185487991824,\n",
       "  'NPV': 0.9832775919732442,\n",
       "  'Accuracy': 0.44988412514484355},\n",
       " {'Threshold': 11.0,\n",
       "  'Sensitivity': 0.7129629629629629,\n",
       "  'Specificity': 0.5236244019138756,\n",
       "  'PPV': 0.04610778443113772,\n",
       "  'NPV': 0.9826038159371493,\n",
       "  'Accuracy': 0.52954808806489},\n",
       " {'Threshold': 12.0,\n",
       "  'Sensitivity': 0.5925925925925926,\n",
       "  'Specificity': 0.6007775119617225,\n",
       "  'PPV': 0.045746962115797,\n",
       "  'NPV': 0.9785679493424257,\n",
       "  'Accuracy': 0.6005214368482039},\n",
       " {'Threshold': 13.0,\n",
       "  'Sensitivity': 0.48148148148148145,\n",
       "  'Specificity': 0.6800239234449761,\n",
       "  'PPV': 0.04634581105169341,\n",
       "  'NPV': 0.9759656652360515,\n",
       "  'Accuracy': 0.6738122827346466},\n",
       " {'Threshold': 14.0,\n",
       "  'Sensitivity': 0.37962962962962965,\n",
       "  'Specificity': 0.7559808612440191,\n",
       "  'PPV': 0.047841306884480746,\n",
       "  'NPV': 0.9741811175337187,\n",
       "  'Accuracy': 0.7442062572421785},\n",
       " {'Threshold': 15.0,\n",
       "  'Sensitivity': 0.3333333333333333,\n",
       "  'Specificity': 0.8089114832535885,\n",
       "  'PPV': 0.05333333333333334,\n",
       "  'NPV': 0.9740727403673028,\n",
       "  'Accuracy': 0.7940324449594438},\n",
       " {'Threshold': 16.0,\n",
       "  'Sensitivity': 0.25,\n",
       "  'Specificity': 0.8639354066985646,\n",
       "  'PPV': 0.056016597510373446,\n",
       "  'NPV': 0.9727272727272728,\n",
       "  'Accuracy': 0.8447276940903824},\n",
       " {'Threshold': 17.0,\n",
       "  'Sensitivity': 0.14814814814814814,\n",
       "  'Specificity': 0.9159688995215312,\n",
       "  'PPV': 0.05387205387205387,\n",
       "  'NPV': 0.9708399366085578,\n",
       "  'Accuracy': 0.891946697566628},\n",
       " {'Threshold': 18.0,\n",
       "  'Sensitivity': 0.1111111111111111,\n",
       "  'Specificity': 0.94377990430622,\n",
       "  'PPV': 0.06,\n",
       "  'NPV': 0.9704797047970479,\n",
       "  'Accuracy': 0.9177288528389339},\n",
       " {'Threshold': 19.0,\n",
       "  'Sensitivity': 0.09259259259259259,\n",
       "  'Specificity': 0.9680023923444976,\n",
       "  'PPV': 0.08547008547008547,\n",
       "  'NPV': 0.9706146926536732,\n",
       "  'Accuracy': 0.9406141367323291},\n",
       " {'Threshold': 20.0,\n",
       "  'Sensitivity': 0.06481481481481481,\n",
       "  'Specificity': 0.9760765550239234,\n",
       "  'PPV': 0.08045977011494253,\n",
       "  'NPV': 0.9699851411589896,\n",
       "  'Accuracy': 0.947566628041715},\n",
       " {'Threshold': 21.0,\n",
       "  'Sensitivity': 0.05555555555555555,\n",
       "  'Specificity': 0.9853468899521531,\n",
       "  'PPV': 0.10909090909090909,\n",
       "  'NPV': 0.9699735060347365,\n",
       "  'Accuracy': 0.9562572421784473},\n",
       " {'Threshold': 22.0,\n",
       "  'Sensitivity': 0.027777777777777776,\n",
       "  'Specificity': 0.9898325358851675,\n",
       "  'PPV': 0.08108108108108109,\n",
       "  'NPV': 0.9692532942898975,\n",
       "  'Accuracy': 0.9597334878331402},\n",
       " {'Threshold': 23.0,\n",
       "  'Sensitivity': 0.018518518518518517,\n",
       "  'Specificity': 0.9952153110047847,\n",
       "  'PPV': 0.1111111111111111,\n",
       "  'NPV': 0.9691322073383809,\n",
       "  'Accuracy': 0.9646581691772885},\n",
       " {'Threshold': 24.0,\n",
       "  'Sensitivity': 0.009259259259259259,\n",
       "  'Specificity': 0.9991028708133971,\n",
       "  'PPV': 0.25,\n",
       "  'NPV': 0.9689675174013921,\n",
       "  'Accuracy': 0.9681344148319815}]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_scores = scores - min_score  # All scores now ≥ 0\n",
    "thresholds = np.arange(0, np.ceil(shifted_scores.max()) + 1)\n",
    "results = []\n",
    "\n",
    "auc = roc_auc_score(y_test, scores)\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (shifted_scores >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    results.append({\n",
    "        'Threshold': t,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'PPV': ppv,\n",
    "        'NPV': npv,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d5bc3f1d-d850-49de-aea8-5e9433112ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval for AUC: (0.497, 0.763)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Assume you already have `scores` from your custom point function and `y_test`\n",
    "n_iterations = 1000\n",
    "auc_scores = []\n",
    "\n",
    "# Combine scores and labels for easier resampling\n",
    "score_label_df = pd.DataFrame({\n",
    "    'score': scores,\n",
    "    'label': y_test\n",
    "})\n",
    "\n",
    "score_label_df = score_label_df.dropna()\n",
    "\n",
    "# Step 2: Bootstrap\n",
    "for _ in range(n_iterations):\n",
    "    sample = score_label_df.sample(frac=1, replace=True)\n",
    "    auc = roc_auc_score(sample['label'], sample['score'])\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Step 3: 95% CI\n",
    "ci_lower = np.percentile(auc_scores, 2.5)\n",
    "ci_upper = np.percentile(auc_scores, 97.5)\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: ({ci_lower:.3f}, {ci_upper:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622d2dd-2021-45db-be4b-6e24c502f753",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0936716-a976-4719-9462-ba252aeac3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['Label'] = (Train_set_df['positive_blood_culture'] | Train_set_df['positive_blood_culture_in_week'])\n",
    "Test_set_df['Label'] = (Test_set_df['positive_blood_culture'] | Test_set_df['positive_blood_culture_in_week'])\n",
    "Val_set_df['Label'] = (Val_set_df['positive_blood_culture'] | Val_set_df['positive_blood_culture_in_week'])\n",
    "\n",
    "X_train = Train_set_df.drop(columns=['Label','positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint','Line_Presense'])\n",
    "y_train = Train_set_df['Label']\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = Test_set_df.drop(columns=['Label','positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint','Line_Presense'])\n",
    "y_test = Test_set_df['Label']\n",
    "\n",
    "\n",
    "X_val = Val_set_df.drop(columns=['Label','positive_blood_culture', 'positive_blood_culture_in_week','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint','Line_Presense'])\n",
    "y_val = Val_set_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "961ebce9-56c4-40f4-aa4f-d7835cd3bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3c80ac4-7b54-451a-8b2c-29504195d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ratio of negative to positive samples\n",
    "scale_pos_weight =(len(y_train[y_train == 0]) / len(y_train[y_train == 1]))\n",
    "\n",
    "params = {\n",
    "    'max_depth':2,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'scale_pos_weight': scale_pos_weight  # Add this line\n",
    "}\n",
    "num_rounds = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5fd681fb-a330-4e33-b16b-617f12e1a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-auc:0.71451\n",
      "[1]\tval-auc:0.71437\n",
      "[2]\tval-auc:0.71647\n",
      "[3]\tval-auc:0.71355\n",
      "[4]\tval-auc:0.74924\n",
      "[5]\tval-auc:0.75233\n",
      "[6]\tval-auc:0.76392\n",
      "[7]\tval-auc:0.77518\n",
      "[8]\tval-auc:0.77896\n",
      "[9]\tval-auc:0.78125\n",
      "[10]\tval-auc:0.78357\n",
      "[11]\tval-auc:0.79237\n",
      "[12]\tval-auc:0.79745\n",
      "[13]\tval-auc:0.80262\n",
      "[14]\tval-auc:0.80293\n",
      "[15]\tval-auc:0.80144\n",
      "[16]\tval-auc:0.80132\n",
      "[17]\tval-auc:0.80238\n",
      "[18]\tval-auc:0.80399\n",
      "[19]\tval-auc:0.78944\n",
      "[20]\tval-auc:0.79625\n",
      "[21]\tval-auc:0.79763\n",
      "[22]\tval-auc:0.80304\n",
      "[23]\tval-auc:0.80281\n",
      "[24]\tval-auc:0.79709\n",
      "[25]\tval-auc:0.80159\n",
      "[26]\tval-auc:0.80184\n",
      "[27]\tval-auc:0.80940\n",
      "[28]\tval-auc:0.80156\n",
      "[29]\tval-auc:0.80353\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds, evals=[(dval, 'val')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e5c59e14-9cff-4882-b4f1-692c52914432",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(dtest)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # converting probabilities to binary output\n",
    "y_pred_val = bst.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "281ff776-e1f8-4ebc-895f-275352719373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "print(f'AUC Score: {auc_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "99f3404d-d63b-43b1-ab27-667e55255959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for AUC: (0.6552451434160992, 0.7533567366972678)\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = bst.predict(dtest, output_margin=False)  # returns probabilities for each class\n",
    "\n",
    "# Step 2: Bootstrap resampling\n",
    "n_iterations = 1000  # Number of bootstrap samples\n",
    "auc_scores = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Resample the data with replacement (X_test and y_test)\n",
    "    X_resampled, y_resampled = resample(X_test, y_test, replace=True)\n",
    "    \n",
    "    # Convert the resampled features back to a DMatrix\n",
    "    dtest_resampled = xgb.DMatrix(X_resampled)  # Resample data needs to be in DMatrix format\n",
    "    \n",
    "    # Get the predicted probabilities for the resampled data\n",
    "    y_pred_prob_resampled = bst.predict(dtest_resampled, output_margin=False)\n",
    "    \n",
    "    # Calculate the AUC score for the resampled data\n",
    "    auc = roc_auc_score(y_resampled, y_pred_prob_resampled)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Step 3: Calculate the 95% confidence interval for AUC\n",
    "ci_lower = np.percentile(auc_scores, 2.5)\n",
    "ci_upper = np.percentile(auc_scores, 97.5)\n",
    "\n",
    "print(f\"95% confidence interval for AUC: ({ci_lower}, {ci_upper})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "987f22d1-7312-4977-855b-09c5b4881c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4a1094c2-a9cb-4386-99d5-15dfc46fc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)  # Calculate area under the curve\n",
    "\n",
    "fpr_val, tpr_val,_ = roc_curve(y_val, y_pred_val)\n",
    "roc_auc_tr = auc(fpr_val, tpr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cb333941-6a6d-4fdb-9d4a-fc103e942813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity 0.9166666666666666\n",
      "specifity 0.32894736842105265\n",
      "Threshod 0.29400873\n",
      "Recall (Sensitivity): 0.90\n",
      "specificity: 0.35\n",
      "Precision (PPV): 0.04\n",
      "Negative Predictive Value (NPV): 0.99\n"
     ]
    }
   ],
   "source": [
    "index=np.where(tpr>=0.9)[0][0]\n",
    "print('sensitivity',tpr[index])\n",
    "print('specifity',1-fpr[index])\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_binary).ravel()\n",
    "recall_val = recall_score(y_test, y_pred_binary)\n",
    "print('Threshod',thresholds[index])\n",
    "ppv_val = precision_score(y_test, y_pred_binary)\n",
    "npv_val = tn / (tn + fn)\n",
    "specificity_val = tn / (tn + fp)\n",
    "print(f\"Recall (Sensitivity): {recall_val:.2f}\")\n",
    "print(f\"specificity: {specificity_val:.2f}\")\n",
    "print(f\"Precision (PPV): {ppv_val:.2f}\")\n",
    "print(f\"Negative Predictive Value (NPV): {npv_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e9804-e04f-4926-8f13-26447b15c16e",
   "metadata": {},
   "source": [
    "# Adding Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fd91d6a9-f0ae-42e8-8696-894cf805e0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc57556c8e4f4987a6521914d19f2f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0665f6bcef7948c5871e4cae34f09dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery Train_set \n",
    "select anon_id,\n",
    "pat_enc_csn_id_coded,\n",
    "order_proc_id_coded,\n",
    "notedatetime,\n",
    "deid_note_text \n",
    "from som-nero-phi-jonc101.PEDsblood_culture_stewardship.Notes\n",
    "where Extract(year from notedatetime)<2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d026d95f-62f3-4829-a9d6-cf4a66573a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeca8b0d67c544f7922978c2bf8b6735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d264d05ce14f7c91591ca1e4d5ca5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery Val_set \n",
    "select anon_id,\n",
    "pat_enc_csn_id_coded,\n",
    "order_proc_id_coded,\n",
    "notedatetime,\n",
    "deid_note_text \n",
    "from som-nero-phi-jonc101.PEDsblood_culture_stewardship.Notes\n",
    "where  Extract(year from notedatetime)>=2022 and \n",
    "Extract(year from notedatetime)<2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9c731f95-764f-43d1-acf1-df0a0d29d17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e93a5bcfe14ceca28236fc7faf1749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd991dec92c41ec87688c0883aa4199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery Test_set \n",
    "select anon_id,\n",
    "pat_enc_csn_id_coded,\n",
    "order_proc_id_coded,\n",
    "notedatetime,\n",
    "deid_note_text \n",
    "from som-nero-phi-jonc101.PEDsblood_culture_stewardship.Notes\n",
    "where  \n",
    "Extract(year from notedatetime)>=2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f1f60e13-cfe9-47ce-9aba-2ff2b68d8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set.to_csv('Train_set.csv',index=False)\n",
    "Val_set.to_csv('Val_set.csv',index=False)\n",
    "Test_set.to_csv('Test_set.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4b7e4-98d2-436a-b676-21a29037063c",
   "metadata": {},
   "source": [
    "# perfom Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abffa5fa-9bf9-4977-bb8c-8e736c05b428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the embeding \n",
    "train_set_embeding=pd.read_csv('Train_set_with_embeddings.csv')\n",
    "train_set_embeding2=pd.read_csv('Train_set_with_embeddings_part2.csv')\n",
    "train_set_embeding=pd.concat([train_set_embeding,train_set_embeding2],axis=0)\n",
    "train_set_embeding.drop_duplicates(subset=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','notedatetime','deid_note_text'],inplace=True)\n",
    "train_set_embeding.shape\n",
    "\n",
    "\n",
    "test_set_embeding=pd.read_csv('Test_set_with_embeddings.csv')\n",
    "test_set_embeding.drop_duplicates(subset=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','notedatetime','deid_note_text'],inplace=True)\n",
    "test_set_embeding.shape\n",
    "\n",
    "\n",
    "val_set_embeding=pd.read_csv('Val_set_with_embeddings.csv')\n",
    "val_set_embeding.drop_duplicates(subset=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','notedatetime','deid_note_text'],inplace=True)\n",
    "val_set_embeding.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc4b36d-b6e6-42f3-a559-d7329fcf0883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40638, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_embeding[['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','notedatetime','deid_note_text']].drop_duplicates().shape # unique orders 20056, unique notes = 39909,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2db7d878-25bb-4526-9cb1-713709a1168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_Notes=pd.read_csv('Train_set.csv')\n",
    "Train_set_Notes=pd.merge(Train_set_Notes,train_set_embeding,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','notedatetime','deid_note_text'])\n",
    "Train_set_Notes=train_set_embeding\n",
    "\n",
    "Test_set_Notes=pd.read_csv('Test_set.csv')\n",
    "Test_set_Notes=pd.merge(Test_set_Notes,test_set_embeding,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','notedatetime','deid_note_text'])\n",
    "Test_set_Notes=test_set_embeding\n",
    "\n",
    "Val_set_Notes=pd.read_csv('Val_set.csv')\n",
    "Val_set_Notes=pd.merge(Val_set_Notes,val_set_embeding,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','notedatetime','deid_note_text'])\n",
    "Val_set_Notes=val_set_embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93734f6e-abc0-48fd-a162-ad546e927876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3b/31jnsf8150z57g6vqxxwj3vw0000gp/T/ipykernel_34790/3777328094.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Train_set_df_temp.drop_duplicates(inplace=True)\n",
      "/var/folders/3b/31jnsf8150z57g6vqxxwj3vw0000gp/T/ipykernel_34790/3777328094.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Test_set_df_temp.drop_duplicates(inplace=True)\n",
      "/var/folders/3b/31jnsf8150z57g6vqxxwj3vw0000gp/T/ipykernel_34790/3777328094.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Val_set_df_temp.drop_duplicates(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6090, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_df_temp=Train_set_df[['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','blood_culture_order_datetime']]\n",
    "Train_set_df_temp.drop_duplicates(inplace=True)\n",
    "Train_set_Notes=pd.merge(Train_set_Notes,Train_set_df_temp,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'])\n",
    "\n",
    "\n",
    "Test_set_df_temp=Test_set_df[['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','blood_culture_order_datetime']]\n",
    "Test_set_df_temp.drop_duplicates(inplace=True)\n",
    "Test_set_Notes=pd.merge(Test_set_Notes,Test_set_df_temp,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'])\n",
    "Test_set_Notes.shape\n",
    "\n",
    "\n",
    "Val_set_df_temp=Val_set_df[['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','blood_culture_order_datetime']]\n",
    "Val_set_df_temp.drop_duplicates(inplace=True)\n",
    "Val_set_Notes=pd.merge(Val_set_Notes,Val_set_df_temp,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'])\n",
    "Val_set_Notes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e4f187a-97ee-4176-88b6-f43d59260ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_Notes['notedatetime'] = pd.to_datetime(Train_set_Notes['notedatetime'])\n",
    "Train_set_Notes['blood_culture_order_datetime'] = pd.to_datetime(Train_set_Notes['blood_culture_order_datetime'])\n",
    "Train_set_Notes['Notetime_cultrueTime'] = (Train_set_Notes['blood_culture_order_datetime'] - Train_set_Notes['notedatetime']).dt.total_seconds()/3600\n",
    "Train_set_Notes=Train_set_Notes[['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','Notetime_cultrueTime','sentence_qmbedding']]\n",
    "\n",
    "\n",
    "Test_set_Notes['notedatetime'] = pd.to_datetime(Test_set_Notes['notedatetime'])\n",
    "Test_set_Notes['blood_culture_order_datetime'] = pd.to_datetime(Test_set_Notes['blood_culture_order_datetime'])\n",
    "Test_set_Notes['Notetime_cultrueTime'] = (Test_set_Notes['blood_culture_order_datetime'] - Test_set_Notes['notedatetime']).dt.total_seconds()/3600\n",
    "Test_set_Notes=Test_set_Notes[['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','Notetime_cultrueTime','sentence_qmbedding']]\n",
    "\n",
    "\n",
    "\n",
    "Val_set_Notes['notedatetime'] = pd.to_datetime(Val_set_Notes['notedatetime'])\n",
    "Val_set_Notes['blood_culture_order_datetime'] = pd.to_datetime(Val_set_Notes['blood_culture_order_datetime'])\n",
    "Val_set_Notes['Notetime_cultrueTime'] = (Val_set_Notes['blood_culture_order_datetime'] - Val_set_Notes['notedatetime']).dt.total_seconds()/3600\n",
    "Val_set_Notes=Val_set_Notes[['anon_id','pat_enc_csn_id_coded','order_proc_id_coded','Notetime_cultrueTime','sentence_qmbedding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f706a8f5-b343-4eeb-8a53-1c5d2c0294d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3016, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_idx = Train_set_Notes.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'])['Notetime_cultrueTime'].idxmin()\n",
    "Train_set_Notes = Train_set_Notes.loc[min_idx].reset_index(drop=True)\n",
    "Train_set_Notes.shape\n",
    "\n",
    "\n",
    "min_idx = Test_set_Notes.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'])['Notetime_cultrueTime'].idxmin()\n",
    "Test_set_Notes = Test_set_Notes.loc[min_idx].reset_index(drop=True)\n",
    "Test_set_Notes.shape\n",
    "\n",
    "\n",
    "min_idx = Val_set_Notes.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded'])['Notetime_cultrueTime'].idxmin()\n",
    "Val_set_Notes = Val_set_Notes.loc[min_idx].reset_index(drop=True)\n",
    "Val_set_Notes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a252fab-1bd3-4e77-822e-5e9f6b323673",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['Label'] = (Train_set_df['positive_blood_culture'] | Train_set_df['positive_blood_culture_in_week'])\n",
    "Test_set_df['Label'] = (Test_set_df['positive_blood_culture'] | Test_set_df['positive_blood_culture_in_week'])\n",
    "Val_set_df['Label'] = (Val_set_df['positive_blood_culture'] | Val_set_df['positive_blood_culture_in_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3108692c-7fae-403c-b41f-0660884370b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df=pd.merge(Train_set_Notes,Train_set_df,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'])\n",
    "Train_set_df.drop_duplicates(subset=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'],inplace=True)\n",
    "Train_set_df['datapoint'] = Train_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n",
    "\n",
    "\n",
    "Test_set_df=pd.merge(Test_set_Notes,Test_set_df,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'])\n",
    "Test_set_df.drop_duplicates(subset=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'],inplace=True)\n",
    "Test_set_df['datapoint'] = Train_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n",
    "\n",
    "Val_set_df=pd.merge(Val_set_Notes,Val_set_df,how='inner',on=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'])\n",
    "Val_set_df.drop_duplicates(subset=['anon_id','pat_enc_csn_id_coded','order_proc_id_coded'],inplace=True)\n",
    "Val_set_df['datapoint'] = Val_set_df.groupby(['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded']).ngroup() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1718c67-1fae-4fa7-a4b8-4db072d342d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['birth_date_jittered'] = pd.to_datetime(Train_set_df['birth_date_jittered'])\n",
    "Train_set_df['blood_culture_order_datetime'] = pd.to_datetime(Train_set_df['blood_culture_order_datetime'])\n",
    "Train_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Train_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "Val_set_df['birth_date_jittered'] = pd.to_datetime(Val_set_df['birth_date_jittered'])\n",
    "Val_set_df['blood_culture_order_datetime'] = pd.to_datetime(Val_set_df['blood_culture_order_datetime'])\n",
    "Val_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Val_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "\n",
    "Test_set_df['birth_date_jittered'] = pd.to_datetime(Test_set_df['birth_date_jittered'])\n",
    "Test_set_df['blood_culture_order_datetime'] = pd.to_datetime(Test_set_df['blood_culture_order_datetime'])\n",
    "Test_set_df['earliest_iv_antibiotic_datetime'] = pd.to_datetime(Test_set_df['earliest_iv_antibiotic_datetime'])\n",
    "\n",
    "\n",
    "# Calculate the difference in hours:\n",
    "Train_set_df['age'] = (Train_set_df['blood_culture_order_datetime'] - Train_set_df['birth_date_jittered']).dt.days \n",
    "Test_set_df['age'] = (Test_set_df['blood_culture_order_datetime'] - Test_set_df['birth_date_jittered']).dt.days #/ 3600\n",
    "Val_set_df['age'] = (Val_set_df['blood_culture_order_datetime'] - Val_set_df['birth_date_jittered']).dt.days #/ 3600\n",
    "\n",
    "Train_set_df['hours_between_cult_abx'] = (Train_set_df['blood_culture_order_datetime'] - Train_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n",
    "Test_set_df['hours_between_cult_abx'] = (Test_set_df['blood_culture_order_datetime'] - Test_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n",
    "Val_set_df['hours_between_cult_abx'] = (Val_set_df['blood_culture_order_datetime'] - Val_set_df['earliest_iv_antibiotic_datetime']).dt.total_seconds() / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74067427-a17f-4397-848e-a3e6317a28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df['gender'] = Train_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
    "Test_set_df['gender'] = Test_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
    "Val_set_df['gender'] = Val_set_df['gender'].apply(lambda x: 1 if x == 'Male' else (0 if x == 'Female' else None))\n",
    "\n",
    "\n",
    "Train_set_df['Leukocyte_Esterase'] = Train_set_df['Leukocyte_Esterase'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Test_set_df['Leukocyte_Esterase'] = Test_set_df['Leukocyte_Esterase'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Val_set_df['Leukocyte_Esterase'] = Val_set_df['Leukocyte_Esterase'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "\n",
    "\n",
    "Train_set_df['WBC_urine'] = Train_set_df['WBC_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Test_set_df['WBC_urine'] = Test_set_df['WBC_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Val_set_df['WBC_urine'] = Val_set_df['WBC_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "\n",
    "\n",
    "Train_set_df['Bacteria_urine'] = Train_set_df['Bacteria_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Test_set_df['Bacteria_urine'] = Test_set_df['Bacteria_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Val_set_df['Bacteria_urine'] = Val_set_df['Bacteria_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "\n",
    "\n",
    "Train_set_df['Nitrite_urine'] = Train_set_df['Nitrite_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Test_set_df['Nitrite_urine'] = Test_set_df['Nitrite_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "Val_set_df['Nitrite_urine'] = Val_set_df['Nitrite_urine'].apply(lambda x: 1 if x == 'POSITIVE' else (0 if x == 'NEGATIVE' else None))\n",
    "\n",
    "\n",
    "Train_set_df['ET_Tube'] = Train_set_df['Line_Presense'].apply(lambda x: 1 if x == 'ET_Tube' else 0)\n",
    "Test_set_df['ET_Tube'] = Test_set_df['Line_Presense'].apply(lambda x: 1 if x == 'ET_Tube' else 0 )\n",
    "Val_set_df['ET_Tube'] = Val_set_df['Line_Presense'].apply(lambda x: 1 if x == 'ET_Tube' else 0)\n",
    "\n",
    "\n",
    "\n",
    "Train_set_df['otherline'] = Train_set_df['Line_Presense'].apply(lambda x: 1 if x == 'otherline' else 0)\n",
    "Test_set_df['otherline'] = Test_set_df['Line_Presense'].apply(lambda x: 1 if x == 'otherline' else 0 )\n",
    "Val_set_df['otherline'] = Val_set_df['Line_Presense'].apply(lambda x: 1 if x == 'otherline' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "957b53bf-a829-4c2c-9ade-43acb8eca49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set\n",
    "Identifiers=['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint']\n",
    "Labels=['Label']\n",
    "Labs=['min_heartrate','max_heartrate', 'avg_heartrate', 'median_heartrate',\n",
    "       'min_resprate', 'max_resprate', 'avg_resprate', 'median_resprate',\n",
    "       'min_temp', 'max_temp', 'avg_temp', 'median_temp', 'min_sysbp',\n",
    "       'max_sysbp', 'avg_sysbp', 'median_sysbp', 'min_diasbp',\n",
    "       'max_diasbp', 'avg_diasbp', 'median_diasbp', 'min_wbc', 'max_wbc',\n",
    "       'avg_wbc', 'median_wbc', 'min_neutrophils', 'max_neutrophils',\n",
    "       'avg_neutrophils', 'median_neutrophils', 'min_lymphocytes',\n",
    "       'max_lymphocytes', 'avg_lymphocytes', 'median_lymphocytes',\n",
    "       'min_hgb', 'max_hgb', 'avg_hgb', 'median_hgb', 'min_plt',\n",
    "       'max_plt', 'avg_plt', 'median_plt', 'min_na', 'max_na', 'avg_na',\n",
    "       'median_na', 'min_hco3', 'max_hco3', 'avg_hco3', 'median_hco3',\n",
    "       'min_bun', 'max_bun', 'avg_bun', 'median_bun', 'min_cr', 'max_cr',\n",
    "       'avg_cr', 'median_cr', 'min_lactate', 'max_lactate', 'avg_lactate',\n",
    "       'median_lactate', 'min_procalcitonin', 'max_procalcitonin',\n",
    "       'avg_procalcitonin', 'median_procalcitonin','Leukocyte_Esterase',\n",
    "       'WBC_urine', 'Bacteria_urine','Nitrite_urine', \n",
    "      'min_anc', 'max_anc', 'avg_anc', 'median_anc',\n",
    "       'min_alc', 'max_alc', 'avg_alc', 'median_alc', 'min_spo2',\n",
    "       'max_spo2', 'avg_spo2', 'median_spo2']\n",
    "Demos=[ 'gender','age','bmi']\n",
    "ABX=['vanc', 'zosyn', 'vanc_zosyn', 'other_ABX']\n",
    "Time_Varient_features=['hours_between_cult_abx']\n",
    "Embeddings=['sentence_qmbedding']\n",
    "Diagnosis= ['ET_Tube','otherline','Transplant']\n",
    "# Include or Exclude Diagnosis \n",
    "        #bacteremia', 'septic_shock', 'infective_endocarditis',\n",
    "      # 'septic_thrombophlebitis', 'vascular_graft_infection', 'CRBSI',\n",
    "      # 'infectious_discitis', 'epidural_abscess', 'septic_arthritis',\n",
    "      # 'meningitis', 'meningitis_bacteria', 'cholangitis',\n",
    "      # 'bacterial_cholangitis', 'pyelonephritis',\n",
    "      # 'acute_bacterial_pyelonephritis', 'severe_pneumonia',\n",
    "      # 'acute_hematogenous_osteomyelitis', 'asplenia',\n",
    "      # 'immunocompromised_state', 'severe_cellulitis', 'cystitis',\n",
    "      # 'prostatitis', 'CAP', 'diabetic_foot_infection', 'colitis',\n",
    "      # 'aspiration_pneumonia', 'uncomplicated_cholecystitis',\n",
    "      # 'uncomplicated_diverticulitis', 'Uncomplicated_pancreatitis',\n",
    "Feature_set=Identifiers+Labels+Labs+Demos+Diagnosis+Time_Varient_features+ABX+Embeddings\n",
    "Train_set_df=Train_set_df[Feature_set]\n",
    "Test_set_df=Test_set_df[Feature_set]\n",
    "Val_set_df=Val_set_df[Feature_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e8df5b-e207-4d95-8e4f-0e792fb73cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "Train_set_df['sentence_qmbedding'] = Train_set_df['sentence_qmbedding'].apply(ast.literal_eval)\n",
    "Test_set_df['sentence_qmbedding'] = Test_set_df['sentence_qmbedding'].apply(ast.literal_eval)\n",
    "Val_set_df['sentence_qmbedding'] = Val_set_df['sentence_qmbedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49bbb348-3070-49f6-a21c-f94f2dd584f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_df = Train_set_df.reset_index(drop=True)\n",
    "Test_set_df = Test_set_df.reset_index(drop=True)\n",
    "Val_set_df = Val_set_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ccd6d65-d86e-4ea6-aa5b-5b71508c3c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_Trdf = pd.DataFrame(Train_set_df['sentence_qmbedding'].tolist(),\n",
    "                               columns=[f'embedding_{i}' for i in range(len(Train_set_df['sentence_qmbedding'].iloc[0]))])\n",
    "\n",
    "embedding_Tedf = pd.DataFrame(Test_set_df['sentence_qmbedding'].tolist(),\n",
    "                               columns=[f'embedding_{i}' for i in range(len(Test_set_df['sentence_qmbedding'].iloc[0]))])\n",
    "\n",
    "embedding_Valdf = pd.DataFrame(Val_set_df['sentence_qmbedding'].tolist(),\n",
    "                               columns=[f'embedding_{i}' for i in range(len(Val_set_df['sentence_qmbedding'].iloc[0]))])\n",
    "\n",
    "\n",
    "Train_set_df = pd.concat([Train_set_df.drop(columns=['sentence_qmbedding']), embedding_Trdf], axis=1)\n",
    "Test_set_df = pd.concat([Test_set_df.drop(columns=['sentence_qmbedding']), embedding_Tedf], axis=1)\n",
    "Val_set_df = pd.concat([Val_set_df.drop(columns=['sentence_qmbedding']), embedding_Valdf], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f029f8f6-3fb5-4e4c-b00e-2c2ade6844fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train_set_df.drop(columns=['Label','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint'])\n",
    "y_train = Train_set_df['Label']\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = Test_set_df.drop(columns=['Label','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint'])\n",
    "y_test = Test_set_df['Label']\n",
    "\n",
    "\n",
    "X_val = Val_set_df.drop(columns=['Label','anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded','datapoint'])\n",
    "y_val = Val_set_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2cd1310-97b6-45da-a6cf-9f5fbd28c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6732311e-5ddb-4e42-9ae8-b3b0ee91921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = (len(y_train[y_train == 0]) / len(y_train[y_train == 1]))\n",
    "params = {\n",
    "    'max_depth':3,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'scale_pos_weight': scale_pos_weight  \n",
    "}\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b445718e-480f-4570-a04b-f84f630103d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-auc:0.66648\n",
      "[1]\tval-auc:0.66066\n",
      "[2]\tval-auc:0.70550\n",
      "[3]\tval-auc:0.71788\n",
      "[4]\tval-auc:0.72182\n",
      "[5]\tval-auc:0.72893\n",
      "[6]\tval-auc:0.73941\n",
      "[7]\tval-auc:0.73530\n",
      "[8]\tval-auc:0.74830\n",
      "[9]\tval-auc:0.73297\n",
      "[10]\tval-auc:0.73688\n",
      "[11]\tval-auc:0.75061\n",
      "[12]\tval-auc:0.74823\n",
      "[13]\tval-auc:0.75358\n",
      "[14]\tval-auc:0.76162\n",
      "[15]\tval-auc:0.77077\n",
      "[16]\tval-auc:0.77054\n",
      "[17]\tval-auc:0.76993\n",
      "[18]\tval-auc:0.77180\n",
      "[19]\tval-auc:0.76214\n",
      "[20]\tval-auc:0.76329\n",
      "[21]\tval-auc:0.76278\n",
      "[22]\tval-auc:0.76668\n",
      "[23]\tval-auc:0.76699\n",
      "[24]\tval-auc:0.76582\n",
      "[25]\tval-auc:0.77170\n",
      "[26]\tval-auc:0.77207\n",
      "[27]\tval-auc:0.77287\n",
      "[28]\tval-auc:0.77716\n",
      "[29]\tval-auc:0.77548\n",
      "[30]\tval-auc:0.77921\n",
      "[31]\tval-auc:0.78058\n",
      "[32]\tval-auc:0.78607\n",
      "[33]\tval-auc:0.78325\n",
      "[34]\tval-auc:0.77519\n",
      "[35]\tval-auc:0.77216\n",
      "[36]\tval-auc:0.77288\n",
      "[37]\tval-auc:0.77215\n",
      "[38]\tval-auc:0.77539\n",
      "[39]\tval-auc:0.77180\n",
      "[40]\tval-auc:0.77543\n",
      "[41]\tval-auc:0.77568\n",
      "[42]\tval-auc:0.77856\n",
      "[43]\tval-auc:0.77270\n",
      "[44]\tval-auc:0.77304\n",
      "[45]\tval-auc:0.76982\n",
      "[46]\tval-auc:0.76572\n",
      "[47]\tval-auc:0.76356\n",
      "[48]\tval-auc:0.76521\n",
      "[49]\tval-auc:0.76471\n",
      "[50]\tval-auc:0.76687\n",
      "[51]\tval-auc:0.76206\n",
      "[52]\tval-auc:0.75916\n",
      "[53]\tval-auc:0.76340\n",
      "[54]\tval-auc:0.76435\n",
      "[55]\tval-auc:0.76760\n",
      "[56]\tval-auc:0.76515\n",
      "[57]\tval-auc:0.76606\n",
      "[58]\tval-auc:0.76472\n",
      "[59]\tval-auc:0.76651\n",
      "[60]\tval-auc:0.76664\n",
      "[61]\tval-auc:0.76809\n",
      "[62]\tval-auc:0.77015\n",
      "[63]\tval-auc:0.77110\n",
      "[64]\tval-auc:0.76971\n",
      "[65]\tval-auc:0.77535\n",
      "[66]\tval-auc:0.77717\n",
      "[67]\tval-auc:0.77884\n",
      "[68]\tval-auc:0.78017\n",
      "[69]\tval-auc:0.77848\n",
      "[70]\tval-auc:0.77642\n",
      "[71]\tval-auc:0.77725\n",
      "[72]\tval-auc:0.77869\n",
      "[73]\tval-auc:0.78228\n",
      "[74]\tval-auc:0.78431\n",
      "[75]\tval-auc:0.78477\n",
      "[76]\tval-auc:0.78315\n",
      "[77]\tval-auc:0.78344\n",
      "[78]\tval-auc:0.78289\n",
      "[79]\tval-auc:0.78396\n",
      "[80]\tval-auc:0.78296\n",
      "[81]\tval-auc:0.77968\n",
      "[82]\tval-auc:0.77672\n",
      "[83]\tval-auc:0.77599\n",
      "[84]\tval-auc:0.77350\n",
      "[85]\tval-auc:0.77443\n",
      "[86]\tval-auc:0.77356\n",
      "[87]\tval-auc:0.77067\n",
      "[88]\tval-auc:0.77069\n",
      "[89]\tval-auc:0.77406\n",
      "[90]\tval-auc:0.77273\n",
      "[91]\tval-auc:0.77256\n",
      "[92]\tval-auc:0.77114\n",
      "[93]\tval-auc:0.77346\n",
      "[94]\tval-auc:0.77721\n",
      "[95]\tval-auc:0.78100\n",
      "[96]\tval-auc:0.78357\n",
      "[97]\tval-auc:0.78036\n",
      "[98]\tval-auc:0.77920\n",
      "[99]\tval-auc:0.77829\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds, evals=[(dval, 'val')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a62fe728-2f3b-4284-a192-52bb3cc0157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(dtest)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  \n",
    "y_pred_val = bst.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "91ff236f-1be0-4d75-99a1-1b0c9c1abb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.80\n",
      " Val AUC Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "print(f'AUC Score: {auc_score:.2f}')\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "val_auc_score = roc_auc_score(y_val, y_pred_val)\n",
    "print(f' Val AUC Score: {val_auc_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80bc9f-7a4c-4d5b-9101-5f83777441fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = bst.predict(dtest, output_margin=False)  # returns probabilities for each class\n",
    "\n",
    "# Step 2: Bootstrap resampling\n",
    "n_iterations = 1000  # Number of bootstrap samples\n",
    "auc_scores = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Resample the data with replacement (X_test and y_test)\n",
    "    X_resampled, y_resampled = resample(X_test, y_test, replace=True)\n",
    "    \n",
    "    # Convert the resampled features back to a DMatrix\n",
    "    dtest_resampled = xgb.DMatrix(X_resampled)  # Resample data needs to be in DMatrix format\n",
    "    \n",
    "    # Get the predicted probabilities for the resampled data\n",
    "    y_pred_prob_resampled = bst.predict(dtest_resampled, output_margin=False)\n",
    "    \n",
    "    # Calculate the AUC score for the resampled data\n",
    "    auc = roc_auc_score(y_resampled, y_pred_prob_resampled)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Step 3: Calculate the 95% confidence interval for AUC\n",
    "ci_lower = np.percentile(auc_scores, 2.5)\n",
    "ci_upper = np.percentile(auc_scores, 97.5)\n",
    "\n",
    "print(f\"95% confidence interval for AUC: ({ci_lower}, {ci_upper})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ffdfc246-df75-441c-a7b2-8f691de96710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b2e9f83e-03fa-409e-a66b-cb09ceb4f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)  # Calculate area under the curve\n",
    "\n",
    "fpr_val, tpr_val,_ = roc_curve(y_val, y_pred_val)\n",
    "roc_auc_tr = auc(fpr_val, tpr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "32112af7-ea75-499e-899c-5281ceb139ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity 0.9166666666666666\n",
      "specifity 0.42985611510791366\n",
      "0.04947526236881558\n",
      "0.9937629937629938\n"
     ]
    }
   ],
   "source": [
    "index=np.where(tpr>=0.90)[0][0]\n",
    "print('sensitivity',tpr[index])\n",
    "print('specifity',1-fpr[index])\n",
    "SEN=tpr[index]\n",
    "SPEC=1-fpr[index]\n",
    "P=y_test[y_test==1].shape[0]/y_test.shape[0]\n",
    "PPV = (SEN * P) / (SEN * P + (1 - SPEC) * (1 - P))\n",
    "NPV = (SPEC * (1 - P)) / ((1 - SEN) * P + SPEC * (1 - P))\n",
    "print(PPV)\n",
    "print(NPV)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
