{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_path = \"/Users/jonc101/Box Sync/jichiang_folders/clinical_recommender_pipeline/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design and Implementation of Clinical Recommender: \n",
    "\n",
    "Aims: \n",
    "\n",
    "- Create a Framework to Evaluate the Impact of a Recommender System on Physician Behavior\n",
    "- Create a Data Pipeline that Preprocess Raw Clinical Behavioral Data into Actionable Clinical Insights\n",
    "- Unit Testing\n",
    "- Terminal Run Commands \n",
    "- Git Pull and Git Run: \n",
    "- Configuration: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCI PostDoc Feedback: \n",
    "- Survey questioning is useless. \n",
    "     you couldn’t simply obtain from observing them interact with the system\n",
    "- Keep them short\n",
    "- Anecdotal Inverse relationship between # questions asked afterward and quality/truthfulness of response. They’ll humor you for a bit, but after that just click click click\n",
    "- Most useful is having people think outloud during the protocol. \n",
    "- They independently said this is the most useful thing. Or have each person observing for one specific different task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics: \n",
    "- Number of mouse clicks\n",
    "- Resolution down to individual buttons and items\n",
    "- Elapsed time\n",
    "- From start of simulation to end\n",
    "- Number of signed orders\n",
    "- Number of (unique) recommendations\n",
    "- Signed orders from recommender\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods: \n",
    "\n",
    "Our goal was to design a grading pipeline that incorporates an in-house clinical recommender system (CRS) designed by Jonathan Chen. We had to design a data pipeline that actively stores data into a postgres database when physicians select clinical orders from CRS.\n",
    "\n",
    "The clinical orders correspond to different simulation states. A simulation state represents a patient's current diagnostic and procedural mock-up as designed by an expert physician. We developed 2 cases in-house and reached out to three different Stanford physicians to design three different cases.\n",
    "\n",
    "For each clinical order that is capture within a simulation state there is a corresponding score. A specific case has anywhere between 3 to 6 states that are triggered due to specific clinical decisions. We are abstracting a clinical grading platform that has never been done before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responses were recording using Google Forms, which tabulates the results into a Google Sheet, which is made accessible to R and Python. The forms were joined on physician id from the CRS and manually reviewed for validation. The purpose of the google forms, captures HCI survey information about clinical recommender utility for clinical workflow. The survey also captures physician background information, such as years since receiving medical degree and board certifications.\n",
    "\n",
    "The majority of the initial participants were Stanford University Medical residents. After the initial trials ended, we made some subsequent quality of life improvements to the recommender system, after the first ~25 physician feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grading module was prototyped in R stats language and subsequently a more robust test driven python module was used to automatically score from inputs from three clinical experts. The grading module treats each physician id and clinical case as a key which the subsequent orders inside the key have an associated grade and confidence. From the key groups, we can sum the values to derive a score for each doctor's case.\n",
    "\n",
    "This provides insight on physician decision-making and a quantitative score associated with each decision.\n",
    "\n",
    "This process was an iterated delphi method where a panel of three clinical experts grade separately on each unique clinical order, and reconvened to discuss guidelines, grading and clinical confidence in treatments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Trial Setup: How Were Cases Randomized: \n",
    "\n",
    "<pre>\n",
    "Purpose:  \n",
    "    Join sim_state_id and clinical_item_id to Grading Sheet\n",
    "        Then: \n",
    "    Generate Deterministic Random Numbers: \n",
    "        Reproducible: \n",
    "            pseudorandom (deterministic) based on an internal state \n",
    "        Set.Seed\n",
    "            \n",
    "\n",
    "</pre>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get pandas data from postgree sql using python\n",
    "# psycopg2 is a module designed to read dataframes from databases \n",
    "# pandas is a module that is R-like Magic for data manipulation \n",
    "\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Headache', 'Fever B', 'Shortness of Breath', 'Hematemesis', 'Palpitations'], [False, True, False, True])\n",
      "(['Fever B', 'Hematemesis', 'Shortness of Breath', 'Headache', 'Palpitations'], [True, False, True, False])\n",
      "(['Headache', 'Fever B', 'Shortness of Breath', 'Hematemesis', 'Palpitations'], [True, False, False, True])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "'''\n",
    "--------------------------------------------------\n",
    "sample() is an inbuilt function of random module \n",
    "in Python that returns a particular length list \n",
    "of items chosen from the sequence i.e. list, tuple, \n",
    "string or set\n",
    "--------------------------------------------------\n",
    "Used for random sampling without replacement\n",
    "--------------------------------------------------\n",
    "x denotes: \n",
    "    expects: \n",
    "        - list \n",
    "        - cases that you want to randomize \n",
    "y denotes:\n",
    "    - list of boolean values that indicate whether or not \n",
    "          the recommender is turned on \n",
    "n denotes:\n",
    "    - the number of times you want to sample without replacement\n",
    "    - should equal the length of x and y (should I make this explicit?) \n",
    "Purpose of Script:\n",
    "    - writing a function that accepts a list of physician cases and randomly orders them\n",
    "    - making it reproducible (can run again) (may need to review documentation on seed) \n",
    "    \n",
    "Learning Points to Incorporate: \n",
    "    - more test driven development\n",
    "    - functional programming versus Object Oriented Programming \n",
    "    - Less Script-Like   \n",
    "----------------------------------------------------        \n",
    "'''\n",
    "\n",
    "\n",
    "def testRandomizeCase(x, y):\n",
    "    assert type(x) == list\n",
    "    assert len(x) == len(y)\n",
    "\n",
    "\n",
    "def randomizeCase(x,y):\n",
    "    # set the seed \n",
    "    random.seed(a=1)\n",
    "    # initialize an empty list \n",
    "    output = []\n",
    "    # construct for loop for number of physicians in your study\n",
    "    for _ in range(50):\n",
    "        a = random.sample(x, 5)\n",
    "        b = random.sample(y, 4)\n",
    "        #c = [] \n",
    "        #c.append(\"True\")\n",
    "        output.append((a,b))\n",
    "    return(output)\n",
    "\n",
    "# p1 denotes the cases represented by letters in an alphabet     \n",
    "cases = ['Fever B','Headache','Palpitations', 'Hematemesis', 'Shortness of Breath']\n",
    "\n",
    "# TRUE or FALSE (True means recommender is turned on) \n",
    "booleanList = [True,True, False, False]\n",
    "\n",
    "# running script: \n",
    "t = randomizeCase(cases, booleanList)\n",
    "# assumes first case recommender is on\n",
    "print(t[0])\n",
    "print(t[1])\n",
    "print(t[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign Paths for Pipeline: \n",
    "\n",
    "<pre>\n",
    "Purpose:  \n",
    "    Treat Recommender Path as Configuration Folder File\n",
    "        Then: \n",
    "            Assign Appropriate Paths for Clinical Recommender Pipeline     \n",
    "\n",
    "</pre>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "physician_grading = recommender_path + \"physician_grading/\"\n",
    "physician_response = recommender_path + \"physician_response/\"\n",
    "tracker_data = recommender_path + \"tracker_data/\"\n",
    "unit_test = recommender_path + \"unit_test/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse Github API for Open Issues with Associated Hash Tag Dates: \n",
    "\n",
    "<pre>\n",
    "Purpose: List Issues from Github with Deadlines: \n",
    "    Parse Github API: \n",
    "            Then:\n",
    "                Convert Json file Format to Pandas DataFrame\n",
    "            Then: \n",
    "                Parse for Due Date Hashtag \n",
    "            Then: \n",
    "                Drop NA values (no due date)\n",
    "            Then: \n",
    "                Create Column Names:\n",
    "            Then: \n",
    "                Sort By Date \n",
    "\n",
    "</pre>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  112k  100  112k    0     0   114k      0 --:--:-- --:--:-- --:--:--  114k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merge case data  UI usage, grading, survey res...</td>\n",
       "      <td>6/21/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Expand Recruitment Process  - Send out recruit...</td>\n",
       "      <td>6/24/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automated UI Test Grader that accounts for gro...</td>\n",
       "      <td>6/26/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manual validation of a couple data rows from m...</td>\n",
       "      <td>6/26/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Get individual expert panel to deliver their f...</td>\n",
       "      <td>6/28/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analysis - Define analysis plan of which ...</td>\n",
       "      <td>7/12/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Convene expert panel to reconcile grading for ...</td>\n",
       "      <td>7/20/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Paper - Methods Description of Grading Process...</td>\n",
       "      <td>7/25/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Completing remaining UI tests with physicians ...</td>\n",
       "      <td>7/30/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Second round expert panel review once collecte...</td>\n",
       "      <td>8/10/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMIA Informatics Summits Submission: Aspire fo...</td>\n",
       "      <td>8/15/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Paper Results: Data analysis - Associations / ...</td>\n",
       "      <td>8/15/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paper - Intro to motivate (based on prior) + D...</td>\n",
       "      <td>8/30/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paper internal reviews and revisions - #Estima...</td>\n",
       "      <td>9/15/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Paper submission on all results:</td>\n",
       "      <td>9/20/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                issue        date\n",
       "13  Merge case data  UI usage, grading, survey res...   6/21/2019\n",
       "22  Expand Recruitment Process  - Send out recruit...   6/24/2019\n",
       "4   Automated UI Test Grader that accounts for gro...   6/26/2019\n",
       "11  Manual validation of a couple data rows from m...   6/26/2019\n",
       "10  Get individual expert panel to deliver their f...   6/28/2019\n",
       "8   Data Analysis - Define analysis plan of which ...   7/12/2019\n",
       "9   Convene expert panel to reconcile grading for ...   7/20/2019\n",
       "7   Paper - Methods Description of Grading Process...   7/25/2019\n",
       "12  Completing remaining UI tests with physicians ...   7/30/2019\n",
       "3   Second round expert panel review once collecte...   8/10/2019\n",
       "2   AMIA Informatics Summits Submission: Aspire fo...   8/15/2019\n",
       "14  Paper Results: Data analysis - Associations / ...   8/15/2019\n",
       "6   Paper - Intro to motivate (based on prior) + D...   8/30/2019\n",
       "5   Paper internal reviews and revisions - #Estima...   9/15/2019\n",
       "1           Journal Paper submission on all results:    9/20/2019"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parses due dates on github \n",
    "!curl -i \"https://api.github.com/repos/HealthRex/CDSS/issues?state=open\" | tail -n +25  > 'issues3.json'\n",
    "github_issues = pd.read_json('/Users/jonc101/Documents/Biomedical_Data_Science/issues3.json')['title']\n",
    "due_date = github_issues.str.split(\"#Due:\", n = 1, expand = True) \n",
    "c = pd.DataFrame(due_date.dropna())\n",
    "c.columns = ['issue', 'date']\n",
    "c.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data from Database into Memory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pg.connect(\"host='localhost' dbname=stride_inpatient_2014 user=postgres password='MANUAL PASSWORD'\")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# to do :\n",
    "#         Feature: Generate Grading Scheme\n",
    "#             1) help visualize processes\n",
    "#             2) introduce best grading schemes for each case\n",
    "#             3) create a list of common errors seen\n",
    "#\n",
    "#             4) clean up exploratory analysis\n",
    "#             5) convert to python module\n",
    "#\n",
    "#\n",
    "#\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# reading in data from different tables \n",
    "\n",
    "clinical_item = pd.read_sql_query('select * from clinical_item', con=connection)\n",
    "sim_patient_order = pd.read_sql_query('select * from sim_patient_order',con=connection)\n",
    "sim_state = pd.read_sql_query('select * from sim_state',con=connection)\n",
    "sim_user = pd.read_sql_query('select * from sim_user',con=connection)\n",
    "sim_state_transition = pd.read_sql_query('select * from sim_state_transition',con=connection)\n",
    "\n",
    "sim_state['sim_state_name'] = sim_state['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Read Sim State Data into Memory: \n",
    "    Then: \n",
    "        join the sim_state with the sim_patient orders \n",
    "    Then:\n",
    "        find all the unique clinical item orders \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_order = sim_patient_order.merge(sim_state, left_on='sim_state_id', right_on='sim_state_id')\n",
    "clinical_items_list = merged_order['clinical_item_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Create vector of unique sim states (sim_state_id):\n",
    "    Then: \n",
    "        filter vector of unique orders from clinical item table \n",
    "    Then: \n",
    "        create a description based table for orders and clinical items \n",
    "    Then: \n",
    "        split by sim_states into group by object \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_state_list = merged_order['sim_state_id'].unique()\n",
    "ordered_clinical_item_table = clinical_item[clinical_item['clinical_item_id'].isin(clinical_items_list)]\n",
    "remerged_order = merged_order.merge(ordered_clinical_item_table, left_on='clinical_item_id', right_on='clinical_item_id')\n",
    "split_state = remerged_order.groupby('sim_state_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicitly write the lists of objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# afib\n",
    "#--------------------------------------------------------------------------------\n",
    "# \"Afib-RVR Initial\"\n",
    "# \"Afib-RVR Stabilized\"\n",
    "# \"Afib-RVR Worse\"\n",
    "#--------------------------------------------------------------------------------\n",
    "afib_states = [\"Afib-RVR Initial\",\n",
    "                \"Afib-RVR Stabilized\" ,\n",
    "                \"Afib-RVR Worse\" ]\n",
    "#--------------------------------------------------------------------------------\n",
    "# meningitis\n",
    "#--------------------------------------------------------------------------------\n",
    "# \"Mening Active\"\n",
    "# \"Meningitis Adequately Treated\"\n",
    "# \"Meningits Worsens\"\n",
    "#--------------------------------------------------------------------------------\n",
    "mening_states =  [\"Mening Active\",\n",
    "                   \"Meningitis Adequately Treated\",\n",
    "                   \"Meningits Worsens\"]\n",
    "# -------------------------------------------------------------------------------\n",
    "# pulmonary embolism\n",
    "# -------------------------------------------------------------------------------\n",
    "# \"PE-COPD-LungCA\"\n",
    "# \"PE-COPD-LungCA + Anticoagulation\"\n",
    "# \"PE-COPD-LungCA + O2\"\n",
    "# \"PE-COPD-LungCA + O2 + Anticoagulation\"\n",
    "# -------------------------------------------------------------------------------\n",
    "pulmonary_emolism_states = [\"PE-COPD-LungCA\",\n",
    "                              \"PE-COPD-LungCA + Anticoagulation\",\n",
    "                              \"PE-COPD-LungCA + O2\",\n",
    "                              \"PE-COPD-LungCA + O2 + Anticoagulation\"]\n",
    "# -------------------------------------------------------------------------------\n",
    "# neutropenic fever\n",
    "# -------------------------------------------------------------------------------\n",
    "#  \"Neutropenic Fever Treated with IVF\"\n",
    "#  \"Neutropenic Fever Treated with IVF + ABX\"\n",
    "#  \"Neutropenic Fever v2\"\n",
    "#  \"NFever\"\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "neutropenic_fever_states = [\"Neutropenic Fever Treated with IVF\",\n",
    "                              \"Neutropenic Fever Treated with IVF + ABX\",\n",
    "                              \"Neutropenic Fever v2\"]\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# GIBLEED\n",
    "# -------------------------------------------------------------------------------\n",
    "# \"EtOH-GIBleed Active\"\n",
    "# \"EtOH-GIBleed Bleeding Out\"\n",
    "# \"EtOH-GIBleed Coag Stabilized\"\n",
    "# \"EtOH-GIBleed Post-EGD\"\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "gi_bleed_states = [\"EtOH-GIBleed Active\",\n",
    "                      \"EtOH-GIBleed Bleeding Out\",\n",
    "                      \"EtOH-GIBleed Coag Stabilized\",\n",
    "                      \"EtOH-GIBleed Post-EGD\" ]\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# DKA\n",
    "# -------------------------------------------------------------------------------\n",
    "# \"DKA Euglycemic\"\n",
    "# \"DKA Hyperglycemic\"\n",
    "# \"DKA Onset\"\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "dka_states = [\"DKA Euglycemic\" ,\n",
    "                \"DKA Hyperglycemic\" ,\n",
    "                \"DKA Onset\"]\n",
    "\n",
    "list_of_states = [gi_bleed_states,\n",
    "                       mening_states,\n",
    "                       pulmonary_emolism_states,\n",
    "                       afib_states,\n",
    "                       neutropenic_fever_states]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "    Split the states into separate dataframes:\n",
    "        Then: \n",
    "            explicitly add a label for the case name \n",
    "        Then: \n",
    "            select features for grading \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sim_state_id  clinical_item_id  sim_user_id  sim_patient_id  \\\n",
      "55              14             45763           26             134   \n",
      "67              15             45763           26             123   \n",
      "68              15             45763            0             126   \n",
      "69              15             45763            0             153   \n",
      "70               2             45763           31             141   \n",
      "71               2             45763           13              39   \n",
      "72               2             45763           53             293   \n",
      "99              14             45801           48             248   \n",
      "177             14             45866           10              23   \n",
      "178             14             45866           11              31   \n",
      "179             14             45866           13              39   \n",
      "180             14             45866           15              75   \n",
      "181             14             45866           17              79   \n",
      "182             14             45866           21               5   \n",
      "183             14             45866           26             108   \n",
      "184             14             45866           27             113   \n",
      "185             14             45866           29             120   \n",
      "186             14             45866           33             148   \n",
      "187             14             45866            0             153   \n",
      "188             14             45866           39             172   \n",
      "189             14             45866           40             180   \n",
      "190             14             45866           43             205   \n",
      "191             14             45866           46             230   \n",
      "192             14             45866           47             238   \n",
      "193             14             45866           48             248   \n",
      "194             14             45866           51             277   \n",
      "195             14             45866           53             293   \n",
      "198             15             45866           29             120   \n",
      "199             15             45866            0             126   \n",
      "290             15             45838           29             120   \n",
      "...            ...               ...          ...             ...   \n",
      "3164          5000             41759            0             256   \n",
      "3165          5000             41759            0             257   \n",
      "3166          5000             41759            0             267   \n",
      "3167          5000             41759            0             275   \n",
      "3168          5000             41759            0             282   \n",
      "3169          5000             41759            0             290   \n",
      "3170          5000             41759            0             291   \n",
      "3171          5000             41759            0             299   \n",
      "3172          5000             62023           17              77   \n",
      "3173          5000             62023           39             170   \n",
      "3174          5000             62023           42             192   \n",
      "3175          5000             62023           44             210   \n",
      "3176          5000             62023           49             257   \n",
      "3178          5000             46000           29             118   \n",
      "3180          5000             48775           31             139   \n",
      "3181          5000             44237           31             139   \n",
      "3182          5000             48686           40             177   \n",
      "3183          5003             48686           30             129   \n",
      "3184          5003             48686           46             227   \n",
      "3185          5003             48686           52             282   \n",
      "3186          5003             48686           53             291   \n",
      "3187          5000             45903           47             236   \n",
      "3188          5000             45995           47             236   \n",
      "3189          5002             46291           39             170   \n",
      "3190          5002             63735           46             227   \n",
      "3191          5003             63735           46             227   \n",
      "3192          5003             48980           41             184   \n",
      "3196          5003             44395           44             210   \n",
      "3197          5003             52757           53             291   \n",
      "3198          5003             48711           53             291   \n",
      "\n",
      "                                        name_x  \\\n",
      "55                         EtOH-GIBleed Active   \n",
      "67                   EtOH-GIBleed Bleeding Out   \n",
      "68                   EtOH-GIBleed Bleeding Out   \n",
      "69                   EtOH-GIBleed Bleeding Out   \n",
      "70                       EtOH-GIBleed Post-EGD   \n",
      "71                       EtOH-GIBleed Post-EGD   \n",
      "72                       EtOH-GIBleed Post-EGD   \n",
      "99                         EtOH-GIBleed Active   \n",
      "177                        EtOH-GIBleed Active   \n",
      "178                        EtOH-GIBleed Active   \n",
      "179                        EtOH-GIBleed Active   \n",
      "180                        EtOH-GIBleed Active   \n",
      "181                        EtOH-GIBleed Active   \n",
      "182                        EtOH-GIBleed Active   \n",
      "183                        EtOH-GIBleed Active   \n",
      "184                        EtOH-GIBleed Active   \n",
      "185                        EtOH-GIBleed Active   \n",
      "186                        EtOH-GIBleed Active   \n",
      "187                        EtOH-GIBleed Active   \n",
      "188                        EtOH-GIBleed Active   \n",
      "189                        EtOH-GIBleed Active   \n",
      "190                        EtOH-GIBleed Active   \n",
      "191                        EtOH-GIBleed Active   \n",
      "192                        EtOH-GIBleed Active   \n",
      "193                        EtOH-GIBleed Active   \n",
      "194                        EtOH-GIBleed Active   \n",
      "195                        EtOH-GIBleed Active   \n",
      "198                  EtOH-GIBleed Bleeding Out   \n",
      "199                  EtOH-GIBleed Bleeding Out   \n",
      "290                  EtOH-GIBleed Bleeding Out   \n",
      "...                                        ...   \n",
      "3164                      Neutropenic Fever v2   \n",
      "3165                      Neutropenic Fever v2   \n",
      "3166                      Neutropenic Fever v2   \n",
      "3167                      Neutropenic Fever v2   \n",
      "3168                      Neutropenic Fever v2   \n",
      "3169                      Neutropenic Fever v2   \n",
      "3170                      Neutropenic Fever v2   \n",
      "3171                      Neutropenic Fever v2   \n",
      "3172                      Neutropenic Fever v2   \n",
      "3173                      Neutropenic Fever v2   \n",
      "3174                      Neutropenic Fever v2   \n",
      "3175                      Neutropenic Fever v2   \n",
      "3176                      Neutropenic Fever v2   \n",
      "3178                      Neutropenic Fever v2   \n",
      "3180                      Neutropenic Fever v2   \n",
      "3181                      Neutropenic Fever v2   \n",
      "3182                      Neutropenic Fever v2   \n",
      "3183  Neutropenic Fever Treated with IVF + ABX   \n",
      "3184  Neutropenic Fever Treated with IVF + ABX   \n",
      "3185  Neutropenic Fever Treated with IVF + ABX   \n",
      "3186  Neutropenic Fever Treated with IVF + ABX   \n",
      "3187                      Neutropenic Fever v2   \n",
      "3188                      Neutropenic Fever v2   \n",
      "3189        Neutropenic Fever Treated with IVF   \n",
      "3190        Neutropenic Fever Treated with IVF   \n",
      "3191  Neutropenic Fever Treated with IVF + ABX   \n",
      "3192  Neutropenic Fever Treated with IVF + ABX   \n",
      "3196  Neutropenic Fever Treated with IVF + ABX   \n",
      "3197  Neutropenic Fever Treated with IVF + ABX   \n",
      "3198  Neutropenic Fever Treated with IVF + ABX   \n",
      "\n",
      "                                     description_x  \\\n",
      "55           Alcoholic Hepatitis - GI Bleed Active   \n",
      "67     Alcoholic Hepatitis - GI Bleed Bleeding Out   \n",
      "68     Alcoholic Hepatitis - GI Bleed Bleeding Out   \n",
      "69     Alcoholic Hepatitis - GI Bleed Bleeding Out   \n",
      "70         Alcoholic Hepatitis - GI Bleed EGD Done   \n",
      "71         Alcoholic Hepatitis - GI Bleed EGD Done   \n",
      "72         Alcoholic Hepatitis - GI Bleed EGD Done   \n",
      "99           Alcoholic Hepatitis - GI Bleed Active   \n",
      "177          Alcoholic Hepatitis - GI Bleed Active   \n",
      "178          Alcoholic Hepatitis - GI Bleed Active   \n",
      "179          Alcoholic Hepatitis - GI Bleed Active   \n",
      "180          Alcoholic Hepatitis - GI Bleed Active   \n",
      "181          Alcoholic Hepatitis - GI Bleed Active   \n",
      "182          Alcoholic Hepatitis - GI Bleed Active   \n",
      "183          Alcoholic Hepatitis - GI Bleed Active   \n",
      "184          Alcoholic Hepatitis - GI Bleed Active   \n",
      "185          Alcoholic Hepatitis - GI Bleed Active   \n",
      "186          Alcoholic Hepatitis - GI Bleed Active   \n",
      "187          Alcoholic Hepatitis - GI Bleed Active   \n",
      "188          Alcoholic Hepatitis - GI Bleed Active   \n",
      "189          Alcoholic Hepatitis - GI Bleed Active   \n",
      "190          Alcoholic Hepatitis - GI Bleed Active   \n",
      "191          Alcoholic Hepatitis - GI Bleed Active   \n",
      "192          Alcoholic Hepatitis - GI Bleed Active   \n",
      "193          Alcoholic Hepatitis - GI Bleed Active   \n",
      "194          Alcoholic Hepatitis - GI Bleed Active   \n",
      "195          Alcoholic Hepatitis - GI Bleed Active   \n",
      "198    Alcoholic Hepatitis - GI Bleed Bleeding Out   \n",
      "199    Alcoholic Hepatitis - GI Bleed Bleeding Out   \n",
      "290    Alcoholic Hepatitis - GI Bleed Bleeding Out   \n",
      "...                                            ...   \n",
      "3164  Neutropenic Fever (v2 example) Initial State   \n",
      "3165  Neutropenic Fever (v2 example) Initial State   \n",
      "3166  Neutropenic Fever (v2 example) Initial State   \n",
      "3167  Neutropenic Fever (v2 example) Initial State   \n",
      "3168  Neutropenic Fever (v2 example) Initial State   \n",
      "3169  Neutropenic Fever (v2 example) Initial State   \n",
      "3170  Neutropenic Fever (v2 example) Initial State   \n",
      "3171  Neutropenic Fever (v2 example) Initial State   \n",
      "3172  Neutropenic Fever (v2 example) Initial State   \n",
      "3173  Neutropenic Fever (v2 example) Initial State   \n",
      "3174  Neutropenic Fever (v2 example) Initial State   \n",
      "3175  Neutropenic Fever (v2 example) Initial State   \n",
      "3176  Neutropenic Fever (v2 example) Initial State   \n",
      "3178  Neutropenic Fever (v2 example) Initial State   \n",
      "3180  Neutropenic Fever (v2 example) Initial State   \n",
      "3181  Neutropenic Fever (v2 example) Initial State   \n",
      "3182  Neutropenic Fever (v2 example) Initial State   \n",
      "3183  Appropriate Treatments for patient condition   \n",
      "3184  Appropriate Treatments for patient condition   \n",
      "3185  Appropriate Treatments for patient condition   \n",
      "3186  Appropriate Treatments for patient condition   \n",
      "3187  Neutropenic Fever (v2 example) Initial State   \n",
      "3188  Neutropenic Fever (v2 example) Initial State   \n",
      "3189     Appropriate IVF improve patient condition   \n",
      "3190     Appropriate IVF improve patient condition   \n",
      "3191  Appropriate Treatments for patient condition   \n",
      "3192  Appropriate Treatments for patient condition   \n",
      "3196  Appropriate Treatments for patient condition   \n",
      "3197  Appropriate Treatments for patient condition   \n",
      "3198  Appropriate Treatments for patient condition   \n",
      "\n",
      "                                          description_y         case  \n",
      "55                         METABOLIC PANEL, BASIC [BMP]     gi_bleed  \n",
      "67                         METABOLIC PANEL, BASIC [BMP]     gi_bleed  \n",
      "68                         METABOLIC PANEL, BASIC [BMP]     gi_bleed  \n",
      "69                         METABOLIC PANEL, BASIC [BMP]     gi_bleed  \n",
      "70                         METABOLIC PANEL, BASIC [BMP]     gi_bleed  \n",
      "71                         METABOLIC PANEL, BASIC [BMP]     gi_bleed  \n",
      "72                         METABOLIC PANEL, BASIC [BMP]     gi_bleed  \n",
      "99                                    XR CHEST 2V [CXR]     gi_bleed  \n",
      "177                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "178                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "179                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "180                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "181                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "182                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "183                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "184                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "185                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "186                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "187                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "188                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "189                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "190                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "191                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "192                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "193                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "194                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "195                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "198                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "199                                   ECG 12-LEAD [EKG]     gi_bleed  \n",
      "290                                    ISTAT TROPONIN I     gi_bleed  \n",
      "...                                                 ...          ...  \n",
      "3164  Fever and other physiologic disturbances of te...  neutropenic  \n",
      "3165  Fever and other physiologic disturbances of te...  neutropenic  \n",
      "3166  Fever and other physiologic disturbances of te...  neutropenic  \n",
      "3167  Fever and other physiologic disturbances of te...  neutropenic  \n",
      "3168  Fever and other physiologic disturbances of te...  neutropenic  \n",
      "3169  Fever and other physiologic disturbances of te...  neutropenic  \n",
      "3170  Fever and other physiologic disturbances of te...  neutropenic  \n",
      "3171  Fever and other physiologic disturbances of te...  neutropenic  \n",
      "3172                              RESPIRATORY DFA PANEL  neutropenic  \n",
      "3173                              RESPIRATORY DFA PANEL  neutropenic  \n",
      "3174                              RESPIRATORY DFA PANEL  neutropenic  \n",
      "3175                              RESPIRATORY DFA PANEL  neutropenic  \n",
      "3176                              RESPIRATORY DFA PANEL  neutropenic  \n",
      "3178                                 POC URINE DIPSTICK  neutropenic  \n",
      "3180                                       BLADDER SCAN  neutropenic  \n",
      "3181      Glucose-Piperacillin-Tazobactam (Intravenous)  neutropenic  \n",
      "3182                                 DIET LOW MICROBIAL  neutropenic  \n",
      "3183                                 DIET LOW MICROBIAL  neutropenic  \n",
      "3184                                 DIET LOW MICROBIAL  neutropenic  \n",
      "3185                                 DIET LOW MICROBIAL  neutropenic  \n",
      "3186                                 DIET LOW MICROBIAL  neutropenic  \n",
      "3187                          LDH TOTAL, SERUM / PLASMA  neutropenic  \n",
      "3188                          URIC ACID, SERUM / PLASMA  neutropenic  \n",
      "3189             BLOOD CULT - FIRST SET, VIA PHLEBOTOMY  neutropenic  \n",
      "3190                         VIRAL CULTURE, RESPIRATORY  neutropenic  \n",
      "3191                         VIRAL CULTURE, RESPIRATORY  neutropenic  \n",
      "3192                      CONSULT TO INFECTIOUS DISEASE  neutropenic  \n",
      "3196  Calcium Chloride-Glucose-Lactate-Potassium Chl...  neutropenic  \n",
      "3197                       REFERRAL TO PHYSICAL THERAPY  neutropenic  \n",
      "3198                                  CONTACT ISOLATION  neutropenic  \n",
      "\n",
      "[2664 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonc101/Documents/Biomedical_Data_Science/venv/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/jonc101/Documents/Biomedical_Data_Science/venv/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/jonc101/Documents/Biomedical_Data_Science/venv/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/jonc101/Documents/Biomedical_Data_Science/venv/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/jonc101/Documents/Biomedical_Data_Science/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def state_split(state_names, df):\n",
    "    df2 = df[df['name_x'].isin(state_names)]\n",
    "    return(df2)\n",
    "\n",
    "gi_test = state_split(gi_bleed_states, remerged_order)\n",
    "mening_test = state_split(mening_states, remerged_order)\n",
    "pulmonary_embolism_test = state_split(pulmonary_emolism_states, remerged_order)\n",
    "afib_test = state_split(afib_states, remerged_order)\n",
    "neutropenic_test = state_split(neutropenic_fever_states, remerged_order)\n",
    "\n",
    "gi_test['case'] = \"gi_bleed\"\n",
    "mening_test['case'] = \"meningitis\"\n",
    "pulmonary_embolism_test['case'] = \"pulmonary_embolism\"\n",
    "afib_test['case'] = \"atrial_fibrillation\"\n",
    "neutropenic_test['case'] = \"neutropenic\"\n",
    "\n",
    "df_grading_pre = pd.concat([gi_test,\n",
    "                        mening_test,\n",
    "                        pulmonary_embolism_test,\n",
    "                        afib_test,\n",
    "                        neutropenic_test])\n",
    "\n",
    "\n",
    "df_grading = pd.DataFrame(df_grading_pre[['sim_state_id',\n",
    "                                        'clinical_item_id',\n",
    "                                        'sim_user_id',\n",
    "                                        'sim_patient_id',\n",
    "                                        'name_x',\n",
    "                                        'description_x',\n",
    "                                        'description_y',\n",
    "                                        'case']])\n",
    "\n",
    "\n",
    "print(df_grading)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Purpose:  \n",
    "    Split: sim states and get unique orders \n",
    "        Then: \n",
    "            each list/dictionary \n",
    "            key = sim_state_id \n",
    "            value = all orders \n",
    "        Then: \n",
    "            for each key: \n",
    "                get unique orders: \n",
    "        Then: \n",
    "            convert list/groupby object into dataframe\n",
    "</pre>                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_state_list = df_grading.groupby(['sim_state_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_grading.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert groupby object to dictionary of dataframes:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grading_folder = '/Users/jonc101/Documents/Biomedical_Data_Science/physician_grading/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Purpose:  \n",
    "    Read Grade Data from Grading Folder \n",
    "        Then: \n",
    "            Append each score as column labeled from Physician \n",
    "        Then: \n",
    "            Concat to a Dataframe of All Grades \n",
    "</pre>                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak = pd.read_excel(physician_grading + 'andre_kumar_v4.xlsx', index_col=0)\n",
    "ls = pd.read_excel(physician_grading + 'lisa_shieh_v4.xlsx', index_col=0)\n",
    "jh = pd.read_excel(physician_grading + 'jason_hom_v4.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak['grade'] = 3\n",
    "#ls['grade'] = 30\n",
    "jh['grade'] = 300\n",
    "# reassign grade terms \n",
    "ak['grade_ak'] = ak['grade']\n",
    "ls['grade_ls'] = ls['grade']\n",
    "jh['grade_jh'] = jh['grade']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the column grades \n",
    "# write tests for grading columns TO DO \n",
    "# grading_delphi\n",
    "\n",
    "gd = pd.DataFrame(pd.concat([ak,  ls['grade_ls'], jh['grade_jh']], axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd['grade_mean'] = (gd['grade_ak'].values + gd['grade_ls'].values + gd['grade_jh'].values )/ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grading['sim_state_name'] = df_grading['description_x']\n",
    "gd['sim_state_name'] = gd['name.x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Purpose:  \n",
    "    Join sim_state_id and clinical_item_id to Grading Sheet\n",
    "        Then: \n",
    "             \n",
    "            key = sim_state_id \n",
    "            value = all orders \n",
    "        Then: \n",
    "            for each key: \n",
    "                get unique orders: \n",
    "        Then: \n",
    "            convert list/groupby object into dataframe\n",
    "</pre>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_item_key = pd.DataFrame(ordered_clinical_item_table[['clinical_item_id', 'description']])\n",
    "clinical_item_key['clinical_order'] = clinical_item_key['description']\n",
    "df_grading2 = pd.merge(df_grading_pre, clinical_item_key, how='left', on=['clinical_item_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd2 = pd.merge(gd, clinical_item_key, how='left', on=['clinical_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd2['sim_state_name'] = gd2['name.x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_grade = pd.merge(gd2, df_grading2, how='outer', on=['clinical_item_id', 'sim_state_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grading2['sim_state_clinical_order_id'] = df_grading2['sim_state_id'].apply(str) + '_' + df_grading2['clinical_item_id'].apply(str)\n",
    "sim_clinical_orders = df_grading2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gd2['sim_state_clinical_order_id'] = gd2['sim_state_id'].apply(str) + '_' + gd2['clinical_item_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_state_link = sim_state[['sim_state_id', 'name']]\n",
    "gd2['name'] = gd2['sim_state_name']\n",
    "gd3 = pd.merge(gd2, sim_state_link, how='left', on=['name'])\n",
    "gd3['sim_state_clinical_order_id'] = gd3['sim_state_id'].apply(str) + '_' + gd3['clinical_item_id'].apply(str)\n",
    "physician_grading_key = gd3 \n",
    "sim_orders_grade = pd.merge(sim_clinical_orders, physician_grading_key, how='left', on=['sim_state_clinical_order_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Def: \n",
    "    Sum Values of Each Score\n",
    "    \n",
    "Generate Scores for Each Case: \n",
    "    Then: \n",
    "        Split by each case \n",
    "    Then: \n",
    "        Group By Each \n",
    "    Then: \n",
    "        split by sim_states into group by object \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE TEST FUNCTION \n",
    "\n",
    "def grade_sum(case):\n",
    "    return case['grade_mean'].sum(axis = 0, skipna = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gk = sim_orders_grade.groupby('sim_patient_id') \n",
    "ctd = gk.apply(grade_sum)\n",
    "sim_grade_groups = sim_orders_grade.groupby('sim_patient_id').groups\n",
    "sim_grade_group_list = list(sim_grade_groups.keys())\n",
    "sim_grades_list = list(ctd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Def: \n",
    "    Sum Values of Each Score\n",
    "        Use Merged Total Score have a list of total scores for each case \n",
    "    Then: \n",
    "        split for each case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_total_score = pd.DataFrame(zip(sim_grade_group_list, sim_grades_list))\n",
    "merged_total_score.columns = ['sim_patient_id', 'case_grade']\n",
    "#merged_total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_orders_grade.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET STAR: TO RUN v4_data Script \n",
    "# RUN SCRIPT HERE TO GENERATE OUTPUT IN TRACKER OUTPUT\n",
    "tracker_data_out = pd.read_csv(tracker_data + 'tracker_output/output.csv')\n",
    "\n",
    "# preprocessing data columns \n",
    "\n",
    "tracker_data_out['sim_patient_id'] = tracker_data_out['patient']\n",
    "tracker_data_out['sim_user_id'] = tracker_data_out['user']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on grade orders \n",
    "sim_user['sim_name'] = sim_user['name']\n",
    "tracker_user_join = pd.merge(tracker_data_out, sim_user, how='left', on=['sim_user_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read out physician response \n",
    "\n",
    "physician_response_out = pd.read_csv(physician_response + 'physician_responses2.csv')\n",
    "physician_response_join = pd.merge(physician_response_out, sim_user, how='left', on=['sim_name'])\n",
    "tracker_response_join = pd.merge(tracker_user_join, physician_response_join,  how='left', on=['sim_user_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sim_user_id', 'sim_name']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tracker_response_merge = pd.merge(tracker_user_join, physician_response_out, how='left', on=['name'])\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "intersection(tracker_user_join.columns, physician_response_join.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_response_score_join = pd.merge(tracker_response_join, merged_total_score,  how='left', on=['sim_patient_id'])\n",
    "#tracker_response_score_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to folder \n",
    "tracker_response_score_join.to_csv(recommender_path + 'recommender_generated_outputs/tracker_response_grade.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
