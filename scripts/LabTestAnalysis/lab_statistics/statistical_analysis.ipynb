{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of the Lab Normality Paper\n",
    "\n",
    "### Author: Song Xu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stats_utils.py:111: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'agg' by the following code:\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ef4d40fc70e5>\", line 1, in <module>\n",
      "    import stats_utils\n",
      "  File \"stats_utils.py\", line 17, in <module>\n",
      "    from scripts.LabTestAnalysis.machine_learning.LabNormalityPredictionPipeline import NON_PANEL_TESTS_WITH_GT_500_ORDERS, STRIDE_COMPONENT_TESTS\n",
      "  File \"/Users/songxu/healthrex/CDSS/scripts/LabTestAnalysis/machine_learning/LabNormalityPredictionPipeline.py\", line 20, in <module>\n",
      "    from medinfo.ml.SupervisedLearningPipeline import SupervisedLearningPipeline\n",
      "  File \"/Users/songxu/healthrex/CDSS/medinfo/ml/SupervisedLearningPipeline.py\", line 35, in <module>\n",
      "    from medinfo.ml.ClassifierAnalyzer import ClassifierAnalyzer\n",
      "  File \"/Users/songxu/healthrex/CDSS/medinfo/ml/ClassifierAnalyzer.py\", line 9, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/Users/songxu/healthrex/CDSS/env/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 17, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('TkAgg')\n"
     ]
    }
   ],
   "source": [
    "import stats_utils\n",
    "from scripts.LabTestAnalysis.machine_learning import LabNormalityLearner_Legacy as LNL\n",
    "from scripts.LabTestAnalysis.machine_learning.ml_utils import map_lab\n",
    "\n",
    "import LocalEnv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assign Data Set and Type here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'Stanford'\n",
    "lab_type = 'component'\n",
    "curr_version = '10000-episodes-lastnormal'\n",
    "inverse01 = True # Setting 'True' to interpret 'Normal' as 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folderpath = os.path.join(LocalEnv.PATH_TO_CDSS, 'scripts/LabTestAnalysis')\n",
    "stats_folderpath = os.path.join(project_folderpath, 'lab_statistics')\n",
    "ML_folderpath = os.path.join(project_folderpath, 'machine_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_maker = '_inversed01' if inverse01 else ''\n",
    "\n",
    "dataSet_foldername = 'data-%s-%s-%s'%(data_source, \n",
    "                                      lab_type, \n",
    "                                      curr_version)\n",
    "dataML_folderpath = os.path.join(ML_folderpath, dataSet_foldername)\n",
    "dataStats_folderpath = os.path.join(stats_folderpath, dataSet_foldername)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labs = stats_utils.get_all_labs(data_source, lab_type)\n",
    "\n",
    "labDescriptions = stats_utils.get_lab_descriptions(data_source=data_source, \n",
    "                                                   lab_type=lab_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1: plot_full_cartoon of LABLDH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = 'LABLDH'\n",
    "score_thres = 0.756\n",
    "include_threshold_colors = True\n",
    "\n",
    "figure1_folderpath = os.path.join(stats_folderpath, 'Fig1_cartoon')\n",
    "if not os.path.exists(figure1_folderpath):\n",
    "    os.mkdir(figure1_folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal_base, yVal_base, score_base, xVal_best, yVal_best, score_best, p_val \\\n",
    "            = stats_utils.get_curve_onelab(lab,\n",
    "                                           all_algs=['random-forest'],\n",
    "                                           data_folder=dataML_folderpath,\n",
    "                                           curve_type='ROC',\n",
    "                                           get_pval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity 0.636603028308\n",
      "specificity 0.96447467876\n",
      "score_thres 0.756\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "# plt.plot(xVal_base, yVal_base, label='baseline model, %0.2f' % (score_base), linewidth=2)\n",
    "'''Representative ROC of LABLDH'''\n",
    "if not inverse01:\n",
    "    plt.plot(xVal_best, yVal_best, color='orange', linewidth=2) #, label='random forest', AUROC=%0.2f  % (score_best)\n",
    "else:\n",
    "    plt.plot(1-yVal_best, 1-xVal_best, color='orange', linewidth=2)\n",
    "\n",
    "if include_threshold_colors:\n",
    "    df_directcompare_rf = pd.read_csv(os.path.join(dataML_folderpath, lab, 'random-forest', 'direct_comparisons.csv'))\n",
    "    actual_labels = df_directcompare_rf['actual'].values\n",
    "    predict_probas = df_directcompare_rf['predict'].values\n",
    "\n",
    "    sensitivity, specificity, LR_p, LR_n, PPV, NPV = stats_utils.get_confusion_metrics(actual_labels, predict_probas, score_thres, also_return_cnts=False)\n",
    "    print \"sensitivity\", sensitivity\n",
    "    print \"specificity\", specificity\n",
    "    print \"score_thres\", score_thres\n",
    "\n",
    "    '''The POINT of PPV=0.95'''\n",
    "    if not inverse01:\n",
    "        plt.scatter(1-specificity, sensitivity, s=50, color='orange')\n",
    "    else:\n",
    "        plt.scatter(1-sensitivity, specificity, s=50, color='orange')\n",
    "\n",
    "    '''Reference line of AUC=0.5'''\n",
    "    dash_num = 20\n",
    "    # plt.plot([1-specificity]*dash_num, np.linspace(0,1,num=dash_num), 'k--')\n",
    "    plt.plot(np.linspace(0,1,num=dash_num),np.linspace(0,1,num=dash_num), color='lightblue', linestyle='--')\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.ylabel('Sensitivity', fontsize=16) #lab_descriptions.get(lab, lab)\n",
    "plt.xlabel('1-Specificity', fontsize=16)\n",
    "# plt.legend(fontsize=12)\n",
    "plt.savefig(os.path.join(figure1_folderpath, 'ROC_%s%s.png'%(lab,inverse_maker)))\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "df = pd.read_csv(dataML_folderpath + \"/%s/baseline_comparisons.csv\"\n",
    "                 % (lab), keep_default_na=False)\n",
    "scores_actual_0 = df.ix[df['actual'] == 0, 'predict'].values\n",
    "scores_actual_1 = df.ix[df['actual'] == 1, 'predict'].values\n",
    "\n",
    "plot_baseline = False\n",
    "if plot_baseline:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "\n",
    "\n",
    "    plt.hist(scores_actual_0, bins=30, alpha=0.8, color='b', label=\"Abnormal\")\n",
    "    plt.hist(scores_actual_1, bins=30, alpha=0.8, color='g', label=\"Normal\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 500])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # plt.xlabel(lab_descriptions[lab] + 'auroc=%.2f' % auc)\n",
    "    # plt.xlabel('baseline', fontsize=16)\n",
    "    plt.xlabel('Score, baseline', fontsize=16)\n",
    "    plt.ylabel('num of orders', fontsize=16)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.savefig(os.path.join(figure1_folderpath, 'cartoon_baseline_%s.png'%lab))\n",
    "    plt.clf()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "alg = 'random-forest'\n",
    "df = pd.read_csv(dataML_folderpath + \"/%s/%s/direct_comparisons.csv\"\n",
    "                 % (lab, alg), keep_default_na=False)\n",
    "\n",
    "df1 = pd.read_csv(dataML_folderpath + \"/%s/%s/%s-normality-prediction-%s-report.tab\"\n",
    "                  % (lab, alg, lab, alg), sep='\\t', keep_default_na=False)\n",
    "auc = df1['roc_auc'].values[0]\n",
    "\n",
    "if include_threshold_colors:\n",
    "    scores_actual_trueNega = df.ix[(df['actual']==0) & (df['predict']<score_thres), 'predict'].values\n",
    "    scores_actual_falsPosi = df.ix[(df['actual'] == 0) & (df['predict'] >= score_thres), 'predict'].values\n",
    "\n",
    "    scores_actual_falsNega = df.ix[(df['actual'] == 1) & (df['predict'] < score_thres), 'predict'].values\n",
    "    scores_actual_truePosi = df.ix[(df['actual'] == 1) & (df['predict'] >= score_thres), 'predict'].values\n",
    "\n",
    "    if not inverse01:\n",
    "        plt.hist(scores_actual_trueNega, bins=22, alpha=0.8, color='royalblue', label=\"true negatives\")\n",
    "        plt.hist(scores_actual_falsNega, bins=22, alpha=0.8, color='gold', label=\"false negatives\")\n",
    "        plt.hist(scores_actual_truePosi, bins=7, alpha=0.8, color='forestgreen', label=\"true positives\")\n",
    "        plt.hist(scores_actual_falsPosi, bins=7, alpha=0.8, color='orangered', label=\"false positives\")\n",
    "\n",
    "        plt.plot([score_thres] * dash_num, np.linspace(0, 800, num=dash_num), 'k--')\n",
    "    else:\n",
    "        plt.hist(1-scores_actual_trueNega, bins=22, alpha=0.8, color='royalblue', label=\"true positives\")\n",
    "        plt.hist(1-scores_actual_falsNega, bins=22, alpha=0.8, color='gold', label=\"false positives\")\n",
    "        plt.hist(1-scores_actual_truePosi, bins=7, alpha=0.8, color='forestgreen', label=\"true negatives\")\n",
    "        plt.hist(1-scores_actual_falsPosi, bins=7, alpha=0.8, color='orangered', label=\"false negatives\")\n",
    "\n",
    "        plt.plot([1-score_thres] * dash_num, np.linspace(0, 800, num=dash_num), 'k--')\n",
    "\n",
    "\n",
    "\n",
    "    plt.legend(loc=(0.45,0.6), fontsize=12)\n",
    "\n",
    "else:\n",
    "\n",
    "    scores_actual_0 = df.ix[df['actual'] == 0, 'predict'].values\n",
    "    scores_actual_1 = df.ix[df['actual'] == 1, 'predict'].values\n",
    "\n",
    "    if not inverse01:\n",
    "        plt.hist(scores_actual_0, bins=30, alpha=0.8, color='gray', label=\"Abnormal\") #gray red\n",
    "        plt.hist(scores_actual_1, bins=30, alpha=0.8, color='black', label=\"Normal\") #black green\n",
    "    else:\n",
    "        plt.hist(1-scores_actual_0, bins=30, alpha=0.8, color='gray', label=\"Positive\")\n",
    "        plt.hist(1-scores_actual_1, bins=30, alpha=0.8, color='black', label=\"Negative\")\n",
    "\n",
    "    plt.legend(fontsize=12)\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 800])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "# plt.xlabel(lab_descriptions[lab])\n",
    "# plt.xlabel('random forest', fontsize=16)\n",
    "plt.xlabel('Score', fontsize=16)\n",
    "plt.ylabel('Number of orders', fontsize=16)\n",
    "\n",
    "if include_threshold_colors:\n",
    "    plt.savefig(os.path.join(figure1_folderpath, 'cartoon_%s_thres%s.png' % (lab, inverse_maker)))\n",
    "else:\n",
    "    plt.savefig(os.path.join(figure1_folderpath, 'cartoon_%s%s.png' % (lab, inverse_maker)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Stats of overuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cached_result_foldername' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d1e358dec58d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure2_folderpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'lab2cnt.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlab2cnt_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_result_foldername\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'lab2cnt.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlab2cnt_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab2cnt_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlab2cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab2cnt_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cached_result_foldername' is not defined"
     ]
    }
   ],
   "source": [
    "figure2_folderpath = os.path.join(stats_folderpath, 'Fig2_Order_Intensities')\n",
    "\n",
    "max_repeat = 5\n",
    "labs=['K', 'CR', 'NA', 'WBC', 'HGB']\n",
    "\n",
    "if not os.path.exists(figure2_folderpath):\n",
    "    os.mkdir(cached_result_foldername)\n",
    "\n",
    "if os.path.exists(figure2_folderpath + 'lab2cnt.csv'):\n",
    "    lab2cnt_pd = pd.read_csv(cached_result_foldername + 'lab2cnt.csv', keep_default_na=False)\\\n",
    "        .set_index('lab')\n",
    "    lab2cnt_pd.columns = lab2cnt_pd.columns.astype(int)\n",
    "    lab2cnt = lab2cnt_pd.to_dict(orient='index')\n",
    "\n",
    "    lab2frac_pd = pd.read_csv(cached_result_foldername + 'lab2frac.csv', keep_default_na=False).set_index('lab')\n",
    "    lab2frac_pd.columns = lab2frac_pd.columns.astype(int)\n",
    "    lab2frac = lab2frac_pd.to_dict(orient='index')\n",
    "else:\n",
    "\n",
    "    lab2cnt, lab2frac = {}, {}\n",
    "    import pickle\n",
    "    cur_cnt_folderpath = 'Normality_Saturations_Cnts'\n",
    "    if not os.path.exists(cur_cnt_folderpath):\n",
    "        os.mkdir(cur_cnt_folderpath)\n",
    "\n",
    "    def save_obj(obj, path):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load_obj(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    for lab in labs:\n",
    "        print 'Getting Normality Saturations for %s..' % lab\n",
    "\n",
    "        cur_dict_name = \"cur_dict_%s.pkl\"%lab\n",
    "        cur_dict_path = os.path.join(cur_cnt_folderpath, cur_dict_name)\n",
    "        if not os.path.exists(cur_dict_path):\n",
    "            df_lab = stats_utils.get_queried_lab(lab, lab_type, time_limit=stats_utils.DEFAULT_TIMELIMIT)\n",
    "\n",
    "            if lab_type=='panel':\n",
    "                df_lab = df_lab[df_lab['order_status'] == 'Completed']\n",
    "\n",
    "            cur_dict = stats_utils.get_prevweek_normal__dict(df_lab, lab_type)\n",
    "\n",
    "            save_obj(cur_dict, cur_dict_path)\n",
    "        else:\n",
    "            cur_dict = load_obj(cur_dict_path)\n",
    "\n",
    "        normal_fractions = {}\n",
    "        record_counts = {}\n",
    "        for x in range(0, max_repeat + 1):\n",
    "            if x in cur_dict:\n",
    "                record_count = len(cur_dict[x])\n",
    "                normal_fraction = np.divide(sum(cur_dict[x]), float(record_count))\n",
    "            else:\n",
    "                record_count = 0\n",
    "                normal_fraction = float('nan')\n",
    "\n",
    "            record_counts[x] = record_count\n",
    "            normal_fractions[x] = (normal_fraction)\n",
    "        lab2cnt[lab] = record_counts\n",
    "        lab2frac[lab] = normal_fractions\n",
    "\n",
    "    df_cnts = pd.DataFrame.from_dict(lab2cnt, orient='index').reset_index().rename(columns={'index': 'lab'})\n",
    "    df_fracs = pd.DataFrame.from_dict(lab2frac, orient='index').reset_index().rename(columns={'index': 'lab'})\n",
    "    #\n",
    "    # print df_cnts\n",
    "    # print df_fracs\n",
    "    # quit()\n",
    "\n",
    "    df_cnts.to_csv(figure2_folderpath + 'lab2cnt.csv', index=False)\n",
    "    df_fracs.to_csv(figure2_folderpath + 'lab2frac.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALB': 'Albumin',\n",
       " 'ALKP': 'Alk Phos',\n",
       " 'ALT': 'ALT (SGPT)',\n",
       " 'AST': 'AST (SGOT)',\n",
       " 'BUN': 'Urea Nitrogen',\n",
       " 'CA': 'Calcium',\n",
       " 'CL': 'Chloride',\n",
       " 'CO2': 'CO2',\n",
       " 'CR': 'Creatinine',\n",
       " 'DBIL': 'Conjugated Bili',\n",
       " 'GLU': 'Glucose',\n",
       " 'HGB': 'Hemoglobin',\n",
       " 'IBIL': 'Bilirubin',\n",
       " 'K': 'Potassium',\n",
       " 'NA': 'Sodium',\n",
       " 'PCO2A': 'PCO2',\n",
       " 'PHA': 'PH (A)',\n",
       " 'PLT': 'Platelet Count',\n",
       " 'PO2A': 'PO2',\n",
       " 'TBIL': 'Total Bilirubin',\n",
       " 'TP': 'Protein',\n",
       " 'WBC': 'White Blood Cells'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labDescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab, y_s K [0.685076521616475, 0.8401300202584382, 0.8842465860564064, 0.9054178529559538, 0.9187139986604153, 0.9240356473412477]\n",
      "lab, y_s CR [0.25605016591420665, 0.8610904098842911, 0.9235285971472095, 0.9444551294380121, 0.9531478770131772, 0.9588342670107635]\n",
      "lab, y_s NA [0.4074169752289101, 0.7886118397923033, 0.8531846872694483, 0.8751483855650523, 0.8889757623143081, 0.8940932416202643]\n",
      "lab, y_s WBC [0.3003706487206641, 0.7865127958172813, 0.8594942228035753, 0.8804809911332443, 0.8983913898854299, 0.9033718389010302]\n",
      "lab, y_s HGB [0.07035260138626022, 0.5437370317789669, 0.6757539614925882, 0.7615794735088304, 0.8041447752481028, 0.8341165413533834]\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5, 3.25)) #6, 4.5 # 7, 2.565 #6.5, 3.75\n",
    "\n",
    "#, '<', '>'\n",
    "marker_types = ('o', 'v', '^', '8', 's', 'P', '*', 'X', 'D', 'd')\n",
    "\n",
    "for k, lab in enumerate(labs):  # :\n",
    "\n",
    "    non_empty_inds = []\n",
    "    for i in range(0,max_repeat+1):\n",
    "        if lab2frac[lab][i]=='':\n",
    "            break\n",
    "        non_empty_inds.append(i)\n",
    "    y_s = [float(lab2frac[lab][i]) for i in non_empty_inds]\n",
    "    print 'lab, y_s', lab, y_s\n",
    "    plt.plot(non_empty_inds, y_s, '-'+marker_types[k], label=labDescriptions[lab])\n",
    "    # l2, = plt.scatter(non_empty_inds, y_s, marker=marker_types[k])\n",
    "    # plt.plot(y_s[0], '-'+marker_types[k], color=l2.get_color(), markerfacecolor=l1.get_color(), label='My plots')\n",
    "\n",
    "plt.xticks(range(0, max_repeat + 1))\n",
    "plt.xlabel('Consecutive normal results in the past 7 days', fontsize=14)\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1], ['0%', '20%', '40%', '60%', '80%', '100%'])\n",
    "plt.tick_params('x', labelsize=15)  # 12\n",
    "plt.tick_params('y', labelsize=13)  # 10\n",
    "plt.ylabel(\"Normal rate\", fontsize=14)\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.legend(fontsize=13)\n",
    "ax.yaxis.tick_right()\n",
    "ax.yaxis.set_label_position(\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(figure2_folderpath + 'Negative_Saturations_%s'%(lab_type))\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Transfer Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_analysis(lab, dataset_folder):\n",
    "    \n",
    "\n",
    "    direct_comparisons = pd.read_csv(os.path.join(dataset_folder, 'direct_comparisons.csv'))\n",
    "    # print direct_comparisons\n",
    "    prev = direct_comparisons[direct_comparisons['actual']==0].shape[0]/float(direct_comparisons.shape[0])\n",
    "    AUC = metrics.roc_auc_score(direct_comparisons['actual'].values, direct_comparisons['predict'].values)\n",
    "    return prev, AUC\n",
    "\n",
    "lab_type = 'component'\n",
    "\n",
    "all_sites = ['Stanford', 'UCSF', 'UMich']\n",
    "\n",
    "res_folderpath = 'data-transferring-component-%s/'%curr_version\n",
    "if not os.path.exists(res_folderpath):\n",
    "    os.mkdir(res_folderpath)\n",
    "\n",
    "res_filepath = res_folderpath + 'all_transfers_new.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(res_filepath):\n",
    "    df_res = pd.read_csv(res_filepath, keep_default_na=False)\n",
    "\n",
    "else:\n",
    "\n",
    "    labs = stats_utils.get_important_labs(lab_type='component')\n",
    "\n",
    "\n",
    "    all_res_dicts = {}\n",
    "    all_res_dicts['lab'] = labs\n",
    "\n",
    "    diagonals = []\n",
    "    off_diags = []\n",
    "\n",
    "    columns = ['lab']\n",
    "    for i in range(3): # Training sources\n",
    "        for j in range(3): # Testing sources\n",
    "            src = all_sites[i]\n",
    "            dst = all_sites[j]\n",
    "\n",
    "\n",
    "            '''\n",
    "            '''\n",
    "        \n",
    "            LNL.transfer_labs(src_dataset=src, dst_dataset=dst, lab_type=lab_type,\n",
    "                                              cur_version=curr_version)\n",
    "            transfer_result_folderpath = ML_folderpath + '/data-%s-src-%s-dst-%s-%s/' \\\n",
    "                                         % (lab_type, src, dst, curr_version)\n",
    "            AUCs = []\n",
    "            Prevs = []\n",
    "            for lab in labs:\n",
    "                direct_comparisons_folderpath = os.path.join(transfer_result_folderpath, lab)\n",
    "\n",
    "                if i!=j:\n",
    "                    cur_prev, cur_AUC = statistic_analysis(lab=lab, dataset_folder=direct_comparisons_folderpath)\n",
    "                    off_diags.append(cur_AUC)\n",
    "                else:\n",
    "                    tmp_df = pd.read_csv('data-%s-component-10000-episodes-lastnormal' % src\n",
    "                                    + '/' + 'summary-stats-bestalg-fixTrainPPV.csv', keep_default_na=False)\n",
    "                    mapped_lab = map_lab(lab=lab, data_source=src, lab_type=lab_type)\n",
    "                    cur_df = tmp_df[(tmp_df['lab'] == mapped_lab) & (tmp_df['fixTrainPPV'] == 0.95)]\n",
    "                    cur_AUC = cur_df['AUC'].values[0]\n",
    "                    cur_prev = (cur_df['TP']+cur_df['FN']).values[0]\n",
    "                    diagonals.append(cur_AUC)\n",
    "                AUCs.append(cur_AUC)\n",
    "                Prevs.append(cur_prev)\n",
    "\n",
    "            col = '%s ->\\n %s' % (src, dst)\n",
    "            all_res_dicts[col] = AUCs\n",
    "            \n",
    "            all_res_dicts['prev'] = Prevs\n",
    "\n",
    "            columns.append(col)\n",
    "    import numpy as np\n",
    "    print \"diagonals avg:\", np.mean(diagonals)\n",
    "    print \"off_diags avg:\", np.mean(off_diags)\n",
    "\n",
    "    df_res = pd.DataFrame.from_dict(all_res_dicts)\n",
    "\n",
    "    descriptions = stats_utils.get_lab_descriptions(lab_type='component')\n",
    "    df_res['lab'] = df_res['lab'].apply(lambda x:descriptions[x])\n",
    "    df_res = df_res[columns]\n",
    "    df_res.to_csv(res_filepath, index=False, float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_res.columns.values\n",
    "df_res_show = df_res.copy()\n",
    "\n",
    "for col in cols:\n",
    "    if col=='lab' or col=='prev':\n",
    "        continue\n",
    "    df_res_show[col] = df_res_show[col].apply(lambda x: '%.2f'%x)\n",
    "\n",
    "def shorten_site(site):\n",
    "    return site.replace('Stanford','S').replace('UCSF','UC').replace('UMich','UM')\n",
    "cols_map = dict(zip(cols, (shorten_site(x) for x in cols)))\n",
    "df_res_show = df_res_show.rename(columns=cols_map)\n",
    "\n",
    "df_res_show.drop(['prev'], axis=1).to_csv('transfer_table_basic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this stats part away\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "col = 5\n",
    "for ind in range(df_res.shape[0]):\n",
    "    cur_row = df_res.iloc[ind].values\n",
    "    print cur_row\n",
    "    cur_lab = cur_row[0]\n",
    "    cur_aucs = cur_row[1:].astype(float).reshape(3,3)\n",
    "\n",
    "    i, j = ind/col, ind%col\n",
    "    plt.subplot2grid((3, col), (i, j))\n",
    "    ax = sns.heatmap(cur_aucs, vmin=0, vmax=1, cbar=False, annot=True, cmap='ocean',\n",
    "                     annot_kws={\"size\": 18},\n",
    "                     xticklabels=['S', 'UC', 'UM'], yticklabels=['S', 'UC', 'UM'])\n",
    "    plt.xlabel(cur_lab, fontsize=20)\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.set_tick_params(labelsize=18)\n",
    "    ax.yaxis.set_tick_params(labelsize=18)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "\n",
    "plt.savefig(res_folderpath + 'transfer_heatmap.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
