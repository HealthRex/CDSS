{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMOP Outpatient Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Setting up Google sdk environment\n",
    "import os \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/wui/.config/gcloud/application_default_credentials.json' \n",
    "os.environ['GCLOUD_PROJECT'] = 'som-nero-phi-jonc101' \n",
    "\n",
    "##Setting up BQ API\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "project_id = 'som-nero-phi-jonc101'\n",
    "dataset_id = 'wui_omop_peds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import getopt\n",
    "import operator\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import pdb\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from statistics import mean\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from IPython.display import clear_output;\n",
    "\n",
    " \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class Recommender:\n",
    "    \"\"\"\n",
    "    Recommender works with OMOP-CDM data to predict outpatient specialty orders (lab, procedure, drugs)\n",
    "    based on features from referring primary care visit (condition, drug, labs, phrases extract from notes)\n",
    "    \n",
    "    ***Inputs***\n",
    "    \n",
    "    1) Patient Cohort\n",
    "    self.Cohort -> read a patient cohort table from Bigquery that contains the following columns:\n",
    "    - person_id\n",
    "    - primary care_visit ID\n",
    "    - primary care visit DATETIME\n",
    "    - specialty care visit ID\n",
    "    - specialty care visit DATETIME\n",
    "    \n",
    "    2) Features\n",
    "    self.features contains tuples of ('feature category','feature table')\n",
    "    Feature tables contain features (condition, drug, measurement, procedure)\n",
    "    associated with either primary care or specialty care visits in the patient cohort\n",
    "    \n",
    "    Pipeline Overview:\n",
    "    1) preProcessing:\n",
    "       - treat each feature occurrence (a row in the Bigquery table) as an instance \n",
    "       - each unique feature is a clinical item\n",
    "       - self.items is a dictionary to store all instances associated with a clinical item\n",
    "       - self.feature_dict is a dictionary to store the OMOP concept ID of a clinical item by its category \n",
    "       a) label clinical items to filter such as vital signs, vaccine that was on a filter list (bq table)\n",
    "       b) label rare items if instances are too few\n",
    "       c) categorize labs as normal or abnormal based on reference range values\n",
    "       d) add demograph data as items (for age: three categories -> infant age 0-2, child 2-12, teen 12-18)\n",
    "    \n",
    "    2) build patient items timeline (buildPatientItemPrePost):\n",
    "       - two ways to place clinical items \n",
    "       a) associted with visit ID (primary care visit as Pre -> special care visit as Post)\n",
    "       b) use primary care visit DATETIME as index time, look back a window period as Pre, \n",
    "          look forward a window period as Post\n",
    "       c) filter previously labelled items (e.g. rare or on filter list)\n",
    "       \n",
    "    3) training:\n",
    "        a) import training patients \n",
    "        b) for each patient, going through items based on the above pre-post timeline\n",
    "        c) build co-occurence matrix based item-item association \n",
    "           - could count distinct item per patient or repeat items\n",
    "        \n",
    "    4) testing:\n",
    "        a) import testing patients\n",
    "        b) use query items to generate metrics from the above co-occurence table\n",
    "           - PPV\n",
    "        c) rank candidate items based on metric score\n",
    "        \n",
    "    5) evaluation:\n",
    "        a) get precision and recall at k recommendation \n",
    "        b) get AUROC \n",
    "        \n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.k = 5\n",
    "        self.nlpRR = 1\n",
    "        self.nlpNeglogP = 2\n",
    "        self.itemRR = 1\n",
    "        self.itemNeglogP = 2\n",
    "        self.inspectPredictedItems = False\n",
    "        self.isFilterNLP = False\n",
    "        self.isPlotRankedScore = False\n",
    "        \n",
    "        self.inputFeatures = {'condition','drug','measurement','procedure'}\n",
    "        self.outputFeatures = {'measurement','procedure'}\n",
    "        \n",
    "        self.project_id = 'som-nero-phi-jonc101'\n",
    "        self.dataset_id = 'wui_omop_peds'\n",
    "        self.prefix = \"V2_test_\"\n",
    "        self.cohort_file = self.prefix + \"cohort\"\n",
    "        self.demographic_file = self.prefix + \"demographic\"\n",
    "    \n",
    "        self.feature_dict = {\"age\":{},\n",
    "                            \"gender\":{},\n",
    "                            \"race\":{},\n",
    "                            \"condition\":{},\n",
    "                            \"drug\":{},\n",
    "                            \"measurement\":{},\n",
    "                            \"derived_measurement\":{},\n",
    "                            \"procedure\":{},\n",
    "                            \"nlp\":{}\n",
    "                             }\n",
    "        \n",
    "        with open('sameItemMap.json', 'r') as fp:\n",
    "            self.sameItemMap = json.load(fp)\n",
    "        \n",
    "        # load baseline prevalence metrics for items phrases\n",
    "        with open('item_prevalence_map.json', 'r') as fp:\n",
    "            self.item_prevalence_map = json.load(fp)\n",
    "            \n",
    "        \n",
    "        self.nlp_prevalence_map = {}\n",
    "        self.nlpPC_notfound = 0\n",
    "        self.nlpSC_notfound = 0\n",
    "        self.nlpPC_found = 0\n",
    "        self.nlpSC_found = 0\n",
    "        \n",
    "        prevMap = {'PrimaryCare':'PC',\n",
    "                   'SpecialtyCare':'SC',\n",
    "                   'Cohort_PrimaryCare':'CohortPC',\n",
    "                   'Cohort_SpecialtyCare':'CohortSC',\n",
    "                   'All':'All'}\n",
    "        \n",
    "        for p in prevMap:\n",
    "            with open('nlp_prevMap_' + prevMap[p] +'.json','r') as fp:\n",
    "                self.nlp_prevalence_map[p] = json.load(fp)\n",
    "\n",
    "        \n",
    "        \n",
    "        categoryList = ['condition','drug','measurement','procedure']\n",
    "        suffixList = ['CohortPC','CohortSC']\n",
    "        self.rrMap = {}\n",
    "        for c in categoryList:\n",
    "            for suffix in suffixList:\n",
    "                with open(c + '_rrMap_' + suffix +'.json','r') as fp:\n",
    "                    self.rrMap[(c,suffix)] = json.load(fp)\n",
    "        \n",
    "        \n",
    "     \n",
    "        self.patients = {}\n",
    "        self.trainPatients = []\n",
    "        self.items = {}\n",
    "        self.trainingItems = {}\n",
    "        self.trainingInputItems = set()\n",
    "        self.candidateItems = set()\n",
    "        self.coMatrix = []\n",
    "        self.coMatrix_RepeatItems = []\n",
    "        self.instanceDF = pd.DataFrame()\n",
    "        self.instance_count = 0\n",
    "        self.item_count = 0\n",
    "        self.invalid_AUC_count = 0\n",
    "        self.valid_AUC_count = 0        \n",
    "\n",
    "    def readBQFile(self, tableName):\n",
    "        # reading a table from BiqQuery \n",
    "        sql = \"\"\" \n",
    "            SELECT * FROM \n",
    "                `{project_id}.{dataset_id}.{table_id}`\n",
    "            \"\"\".format_map(\n",
    "                {'project_id':self.project_id, \n",
    "                 'dataset_id':self.dataset_id, \n",
    "                 'table_id':tableName})\n",
    "        query_job = client.query(sql)\n",
    "        dataFrame = query_job.to_dataframe()\n",
    "        return dataFrame\n",
    "    \n",
    "    def preProcessing(self, count_cutoff):\n",
    "        print(\"preprocessing...\")\n",
    "        \n",
    "        # load the person table with demographic data\n",
    "        self.demographic = self.readBQFile(self.demographic_file)\n",
    "        self.addDemographicToPatient(self.demographic)\n",
    "        \n",
    "        # load the patient cohort and add pre/post visit \n",
    "        self.cohort = self.readBQFile(self.cohort_file)\n",
    "        self.addIndexTimeToPatient(self.cohort)\n",
    "        \n",
    "        self.addAgeToPatient()\n",
    "                \n",
    "        instances = []\n",
    "        for feature_category in self.inputFeatures:\n",
    "            # feature including drug, condition, measurement, procedure etc\n",
    "            feature_tablename = self.prefix + feature_category\n",
    "            featureDF = self.readBQFile(feature_tablename)\n",
    "            \n",
    "            # looping through each row of the table \n",
    "            for index, row in featureDF.iterrows():\n",
    "                \n",
    "                person_id = row[\"person_id\"]\n",
    "                visit_id = row[\"visit_id\"]\n",
    "                item_datetime = row[feature_category + \"_DATETIME\"]\n",
    "                \n",
    "                # use source value if concept ID = 0\n",
    "                item_concept_id, item_name = self.redefineConceptID(row, feature_category)\n",
    "                \n",
    "                # assign item value for lab as \"normal\" vs \"abnormal\" if value and ref range exists\n",
    "                item_value = self.assignItemValue(row, feature_category)\n",
    "                \n",
    "                # generate a unique item code for each unique clinical item\n",
    "                item_code = self.addItem(feature_category, item_concept_id, item_name, person_id)\n",
    "                \n",
    "                if item_value is not None:\n",
    "                    derived_category = \"derived_\" + feature_category \n",
    "                    derived_id = item_value + \"_\" + item_concept_id\n",
    "                    derived_name = item_value + \" \" + item_name\n",
    "                    item_code_derived = self.addItem(derived_category, derived_id, derived_name, person_id)\n",
    "                else:\n",
    "                    item_code_derived = item_code\n",
    "                \n",
    "                # add instance to patient \n",
    "                self.patients[person_id][\"instances\"].append(self.instance_count)\n",
    "                \n",
    "                # instances table store each instance with corresponding item code, person_id, visit_id, time\n",
    "                instances.append([self.instance_count, item_code, item_code_derived, \n",
    "                                  person_id, visit_id, item_datetime, item_value]) \n",
    "                self.instance_count += 1\n",
    "        \n",
    "        # instances is a list of lists --> convert to dataframe        \n",
    "        self.instanceDF = pd.DataFrame.from_records(\n",
    "                                        instances, columns = [\n",
    "                                            \"instance\",\"item\",\"item_derived\",\"person_id\",\n",
    "                                            \"visit_id\",\"item_datetime\",\"item_value\"] )\n",
    "        \n",
    "        \n",
    "        # label rare items in the item dictionary \n",
    "        self.labelRareItems(count_cutoff)\n",
    "        \n",
    "        # label filter items found in the filter list\n",
    "        self.labelFilterItems()\n",
    "        \n",
    "        self.getItemPrevalence()\n",
    "    \n",
    "        \n",
    "    def assignItemValue(self, featureRow, featureCategory):\n",
    "        \n",
    "        def isValid(ref_h, ref_l, v):\n",
    "            if ref_h and ref_l and v and not (math.isnan(ref_h) or math.isnan(ref_l) or math.isnan(v)):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "        if featureCategory == \"measurement\":\n",
    "            refRange_high = featureRow[\"range_high\"]\n",
    "            refRange_low = featureRow[\"range_low\"]\n",
    "            value = featureRow[\"value_as_number\"]\n",
    "            if isValid(refRange_high, refRange_low, value):\n",
    "                \n",
    "#                 print(\"concept ID: {}\".format(featureRow[featureCategory + \"_concept_id\"]))\n",
    "#                 print(\"item name: {}\".format(featureRow[\"concept_name\"]))\n",
    "#                 print(\"value: {}\".format(value))\n",
    "#                 print(\"ref high: {}\".format(refRange_high))\n",
    "#                 print(\"ref low: {}\".format(refRange_low))\n",
    "#                 print(\"---------------------------------------\")\n",
    "                \n",
    "                if value >= refRange_low and value <= refRange_high:\n",
    "                    return \"normal\"\n",
    "                elif value > refRange_high:\n",
    "                    return \"high\"\n",
    "                elif value < refRange_low:\n",
    "                    return \"low\"\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def redefineConceptID(self, featureRow, featureCategory):\n",
    "        \"\"\"for items with no matching concept, use source concept id as concept id\n",
    "        if no source concept id available, use source_value\"\"\"\n",
    "        \n",
    "        item_concept_id = str(featureRow[featureCategory + \"_concept_id\"])\n",
    "        item_name = featureRow[\"concept_name\"]\n",
    "        \n",
    "#         if item_concept_id in self.sameItemMap.keys():\n",
    "#             item_name = self.sameItemMap[item_concept_id][1]\n",
    "#             item_concept_id = self.sameItemMap[item_concept_id][0]\n",
    "           \n",
    "        return item_concept_id, item_name\n",
    "        \n",
    "    def addItem(self, category, ID, item_name, person_id):\n",
    "        \"\"\" \n",
    "            self.items serve as an inventory of clinical items\n",
    "            self.items also store the instances that happened in each item \n",
    "            self.feature_dict is like a feature catolog storing the clinical item name\n",
    "            and links to self.items by item_code \n",
    "            ID is OMOP concept ID or ID from function redefineConceptID\n",
    "        \"\"\"    \n",
    "        if isinstance(ID, int):\n",
    "            ID = str(ID)\n",
    "            \n",
    "        # check if a clinical item exists:\n",
    "        # else establish a new clinical item in self.items and self.feature_dict    \n",
    "        \n",
    "        if ID in self.feature_dict[category]:            \n",
    "            item_code = self.feature_dict[category][ID][0]\n",
    "            self.items[item_code][\"instances\"].append(self.instance_count)\n",
    "            self.items[item_code][\"patients\"].add(person_id)\n",
    "        else:\n",
    "            item_code = self.item_count\n",
    "            self.feature_dict[category][ID] = (item_code, item_name)\n",
    "            self.items[item_code] = {\"category\": category,\n",
    "                                      \"ID\": ID,\n",
    "                                     \"patients\":set([person_id]),\n",
    "                                     \"instances\":[self.instance_count],\n",
    "                                     \"rare\": False,\n",
    "                                     \"filter\": False}\n",
    "            \n",
    "            if category not in ['gender','race','age','nlp','derived_measurement'] and ID != '0':\n",
    "                self.items[item_code][\"baselinePrevalence\"] = self.item_prevalence_map[ID]\n",
    "            elif category == 'nlp': \n",
    "                self.items[item_code][\"baselinePrevalence\"] = self.nlp_prevalence_map['All'][ID]\n",
    "                \n",
    "            self.item_count += 1\n",
    "        \n",
    "        if category in ['gender','race','age']:\n",
    "            self.items[item_code][\"instances\"] = []\n",
    "        \n",
    "        return item_code\n",
    "    \n",
    "       \n",
    "    def addIndexTimeToPatient(self, cohortDF):\n",
    "        for index, row in cohortDF.iterrows():\n",
    "            person_id = row[\"person_id\"]\n",
    "            if  \"IndexTime_Exist\" not in self.patients[person_id].keys():\n",
    "                self.patients[person_id][\"primaryVisitID\"] = row[\"PrimaryCare_visit_id\"]\n",
    "                self.patients[person_id][\"specialtyVisitID\"] = row[\"Specialty_visit_id\"]\n",
    "                self.patients[person_id][\"primaryVisitTime\"] = row[\"PrimaryCare_DATETIME\"]\n",
    "                self.patients[person_id][\"specialtyVisitTime\"] = row[\"Specialty_DATETIME\"]\n",
    "                self.patients[person_id][\"IndexTime_Exist\"] = True\n",
    "                self.patients[person_id][\"instances\"] = []\n",
    "    \n",
    "    def addDemographicToPatient(self, demographicDF):\n",
    "        for index, row in demographicDF.iterrows():\n",
    "            person_id = row[\"person_id\"]\n",
    "            if person_id not in self.patients:\n",
    "                gender_item_code = self.addItem('gender', row[\"gender_concept_id\"], row[\"gender\"],person_id)\n",
    "                race_item_code = self.addItem('race', row[\"race_concept_id\"], row[\"race\"],person_id)\n",
    "                self.patients[person_id] = {\"birthdate\": row[\"birth_DATETIME\"],\n",
    "                                            \"gender\": row[\"gender\"],\n",
    "                                            \"gender_item_code\": gender_item_code,\n",
    "                                            \"race\": row[\"race\"],\n",
    "                                            \"race_item_code\": race_item_code,\n",
    "                                            }\n",
    "    \n",
    "    def addAgeToPatient(self):\n",
    "     \n",
    "        for person_id in self.patients:\n",
    "            birthdate = self.patients[person_id][\"birthdate\"] \n",
    "            primaryvisitdate = self.patients[person_id][\"primaryVisitTime\"]\n",
    "            age = relativedelta(primaryvisitdate, birthdate).years\n",
    "            self.patients[person_id][\"age\"] = age\n",
    "            if age < 2:\n",
    "                infant_item_code = self.addItem('age','infant','infant', person_id)\n",
    "                self.patients[person_id]['age_item_code'] = infant_item_code\n",
    "            elif age >= 2 and age <12:\n",
    "                child_item_code = self.addItem('age','child','child', person_id)\n",
    "                self.patients[person_id]['age_item_code'] = child_item_code                \n",
    "            else:\n",
    "                teen_item_code = self.addItem('age','teen','teen', person_id)\n",
    "                self.patients[person_id]['age_item_code'] = teen_item_code\n",
    "    \n",
    "    def labelRareItems(self, count_cutoff):\n",
    "\n",
    "        for i in self.items:\n",
    "            if len(self.items[i][\"patients\"]) < count_cutoff:\n",
    "                   self.items[i][\"rare\"] = True\n",
    "            else:\n",
    "                   self.items[i][\"rare\"] = False\n",
    "            if self.items[i][\"category\"] in [\"gender\",\"race\",\"age\"]:\n",
    "                self.items[i][\"rare\"] = False\n",
    "    \n",
    "    def labelFilterItems(self):\n",
    "        filterItemList = list(self.readBQFile(\"concepts_tofilter\")[\"concept_id\"])\n",
    "        filterList = list(map(str, filterItemList))\n",
    "        filterList.append('0')\n",
    "        \n",
    "        for i in self.items:\n",
    "            \n",
    "            item_conceptID = self.items[i][\"ID\"].replace(\"high_\",\"\").replace(\"low_\",\"\").replace(\"normal_\",\"\")\n",
    "            \n",
    "            if self.items[i][\"category\"] not in [\"gender\",\"race\",\"age\"]:\n",
    "                \n",
    "                assert item_conceptID.isdigit(), 'concept ID %r is not all digit' % item_conceptID\n",
    "\n",
    "                if item_conceptID in filterList:\n",
    "                    self.items[i][\"filter\"] = True\n",
    "                else: \n",
    "                    self.items[i][\"filter\"] = False\n",
    "                    \n",
    "            elif item_conceptID == '0':\n",
    "                self.items[i][\"filter\"] = True\n",
    "    \n",
    "    def getItemPrevalence(self):\n",
    "        N = len(self.patients)\n",
    "        for i in self.items:\n",
    "            self.items[i][\"prevalence\"] = len(self.items[i][\"patients\"])*100/N        \n",
    " \n",
    "    \n",
    "    def buildPatientItemPrePost(self, person_id, useVisitID):\n",
    "        \n",
    "        def setPrePostThreshold(person_id):\n",
    "            \"\"\"default is to use datetime to set a threshold (Index time) to determine item-item co-occurrence  \n",
    "            otherwise we can use primary care/specialty care visit ID to determine item-item co-occurrence \n",
    "            \"\"\"\n",
    "            if useVisitID:\n",
    "                preThreshold = self.patients[person_id][\"primaryVisitID\"]\n",
    "                postThreshold = self.patients[person_id][\"specialtyVisitID\"]\n",
    "            else: \n",
    "                preThreshold = self.patients[person_id][\"primaryVisitTime\"]\n",
    "                postThreshold = self.patients[person_id][\"specialtyVisitID\"]\n",
    "                #postThreshold = self.patients[person_id][\"specialtyVisitTime\"]\n",
    "            return preThreshold, postThreshold\n",
    "        \n",
    "        def groupItems(i):\n",
    "            # group same items using sameItemMap, i is the item ID from instance \n",
    "            item_concept_id = self.items[i]['ID']\n",
    "            item_category = self.items[i]['category']\n",
    "            if (item_concept_id in self.sameItemMap.keys()) & (item_category not in {'nlp'}):\n",
    "                new_item_concept_id = self.sameItemMap[item_concept_id][0]\n",
    "                itemID = self.feature_dict[item_category][new_item_concept_id][0]\n",
    "            else:\n",
    "                itemID = i\n",
    "            return itemID\n",
    "        \n",
    "        def addItemPre(instance):\n",
    "            if instance[\"item_value\"] is not None:\n",
    "                itemsPre.append(instance[\"item_derived\"])\n",
    "            else:\n",
    "                itemsPre.append(instance[\"item\"])\n",
    "            self.patients[person_id][\"instancePre\"].append(instance['instance'])\n",
    "            \n",
    "        def addItemPost(instance):\n",
    "            i = instance[\"item\"]\n",
    "            itemID = groupItems(i)\n",
    "            itemsPost.append(itemID)\n",
    "            self.patients[person_id][\"instancePost\"].append(instance['instance'])\n",
    "            \n",
    "        def addDemographicItem(person_id):\n",
    "            itemsPre.append(self.patients[person_id][\"gender_item_code\"])\n",
    "            itemsPre.append(self.patients[person_id][\"race_item_code\"])\n",
    "            itemsPre.append(self.patients[person_id][\"age_item_code\"])\n",
    "        \n",
    "        def sendItemPrePost(instance, preThreshold, postThreshold):\n",
    "            if useVisitID == False:\n",
    "                # collect items in pre-post threshold lists\n",
    "                lookbackWindow = datetime.timedelta(days = 180)\n",
    "                lookforwardWindow = datetime.timedelta(days = 1)\n",
    "                if (instance.item_datetime >= preThreshold - lookbackWindow) & (instance.item_datetime < preThreshold + lookforwardWindow):\n",
    "                        addItemPre(instance)\n",
    "                elif instance.visit_id == postThreshold:\n",
    "                    addItemPost(instance)\n",
    "#                 elif (instance.item_datetime >= postThreshold - window) & (instance.item_datetime < postThreshold + window):\n",
    "#                         addItemPost(instance)\n",
    "            else:\n",
    "                if instance.visit_id == preThreshold:\n",
    "                    addItemPre(instance)\n",
    "                elif instance.visit_id == postThreshold:\n",
    "                    addItemPost(instance)\n",
    "                       \n",
    "        \"main part of buildPatientItemPrePost\"            \n",
    "        preThreshold, postThreshold = setPrePostThreshold(person_id)\n",
    "        \n",
    "        itemsPre = []\n",
    "        itemsPost = []\n",
    "        \n",
    "        addDemographicItem(person_id)\n",
    "        self.patients[person_id][\"instancePre\"] = []\n",
    "        self.patients[person_id][\"instancePost\"] = []\n",
    "        \n",
    "        for i in self.patients[person_id][\"instances\"]:\n",
    "   \n",
    "            # instance is a row of the instance dataFrame\n",
    "            instance = self.instanceDF.iloc[i]\n",
    "            \n",
    "            \n",
    "            # check if instance should be removed based on the items\n",
    "            sendItemPrePost(instance, preThreshold, postThreshold)\n",
    "        \n",
    "        return itemsPre, itemsPost\n",
    "\n",
    "    \n",
    "    \"\"\"functions use for training \"\"\"\n",
    "    def processItems(self, items, mode):\n",
    "        \n",
    "        def filterItems(items):\n",
    "            newItems = []\n",
    "            for i in items:\n",
    "                isRareItem = self.items[i][\"rare\"]\n",
    "                isFilterItem = self.items[i][\"filter\"]\n",
    "                if not (isRareItem | isFilterItem):\n",
    "                     newItems.append(i)\n",
    "            return newItems \n",
    "        \n",
    "        def excludeOutputCategory(items):        \n",
    "        \n",
    "            exclude_category = self.inputFeatures.difference(self.outputFeatures)\n",
    "            items_after_exclusion = []\n",
    "            for i in items:\n",
    "                if self.items[i][\"category\"] not in exclude_category:\n",
    "                    items_after_exclusion.append(i)\n",
    "            return items_after_exclusion\n",
    "                   \n",
    "        \n",
    "        def filterNLP(items, mode):\n",
    "            items_after_filter = []\n",
    "            for i in items:\n",
    "                if self.items[i]['category'] == 'nlp' and mode == 'input':\n",
    "                    neglogP, RR = self.getRR_Item(i, mode)                     \n",
    "                    if RR >= self.nlpRR and neglogP >= self.nlpNeglogP:\n",
    "                        items_after_filter.append(i)\n",
    "                else:\n",
    "                    items_after_filter.append(i)\n",
    "            return items_after_filter\n",
    "        \n",
    "        '''main part of processItems'''\n",
    "        ItemsFiltered = filterItems(items)\n",
    "        if self.isFilterNLP:\n",
    "            ItemsProcessed = filterNLP(ItemsFiltered, mode)\n",
    "        else:\n",
    "            ItemsProcessed = ItemsFiltered\n",
    "        \n",
    "        if mode == \"output\":\n",
    "            if ItemsProcessed:\n",
    "                ItemsProcessed = excludeOutputCategory(ItemsProcessed)\n",
    "        \n",
    "        return ItemsProcessed \n",
    "    \n",
    "    def getRR_Item(self, item, mode):\n",
    "        if mode == 'input':\n",
    "            tag = 'CohortPC'\n",
    "        elif mode == 'output':\n",
    "            tag = 'CohortSC'\n",
    "        ID = self.items[item]['ID']\n",
    "        ID = re.compile(r'\\d+').search(ID).group(0)\n",
    "        category = self.items[item][\"category\"]\n",
    "        category = str.replace(category,'derived_','')\n",
    "        \n",
    "        if ID in self.rrMap[(category, tag)]:\n",
    "            neglogP, RR = self.rrMap[(category, tag)][ID]\n",
    "            return neglogP, RR\n",
    "        else:\n",
    "            print(ID, ' not found in rrMap ', category, 'with tag: ', tag)\n",
    "            return 0,0\n",
    "     \n",
    "    def buildCoMatrix(self, itemsPre, itemsPost):        \n",
    "        # allow repeat item counts\n",
    "        if itemsPre and itemsPost:\n",
    "            for i in itemsPre:\n",
    "                for j in itemsPost:\n",
    "                    self.coMatrix_RepeatItems[i][j] += 1\n",
    "                \n",
    "            itemsPre = set(itemsPre)\n",
    "            itemsPost = set(itemsPost)\n",
    "         \n",
    "            # each item only count once \n",
    "            for i in itemsPre:\n",
    "                for j in itemsPost:\n",
    "                    self.coMatrix[i][j] += 1 \n",
    "\n",
    "    \n",
    "    def buildTrainingItems(self, itemsPre, itemsPost, person_id):\n",
    "        if itemsPre or itemsPost:\n",
    "            for i in itemsPre + itemsPost:\n",
    "                if i in self.trainingItems:\n",
    "                    self.trainingItems[i][\"instance_count\"] += 1\n",
    "                    self.trainingItems[i][\"patients\"].add(person_id)\n",
    "                else: \n",
    "                    self.trainingItems[i] = {\"instance_count\": 1,\n",
    "                                             \"patients\":{person_id}}\n",
    "            # record the training input items\n",
    "            self.trainingInputItems = self.trainingInputItems.union(itemsPre)\n",
    "            self.candidateItems = self.candidateItems.union(itemsPost)\n",
    "        \n",
    "    \n",
    "    def buildMetricsTrainingItems(self, trainPatients):\n",
    "        N = len(trainPatients)\n",
    "        for i in self.trainingItems.keys():\n",
    "            self.trainingItems[i][\"baselinefreq\"] = self.trainingItems[i][\"instance_count\"]/N\n",
    "            self.trainingItems[i][\"prevalence\"] = len(self.trainingItems[i][\"patients\"])/N\n",
    "            \n",
    "            \n",
    "    def training(self, trainPatients, useVisitID = False):\n",
    "        print(\"building co-occurrence matrix...\")\n",
    "        self.trainPatients = trainPatients\n",
    "        self.coMatrix = np.zeros((self.item_count,self.item_count))\n",
    "        self.coMatrix_RepeatItems = np.zeros((self.item_count,self.item_count))\n",
    "        self.candidateItems = set()\n",
    "        \n",
    "        for person_id in trainPatients:\n",
    "            itemsPre, itemsPost = self.buildPatientItemPrePost(person_id, useVisitID)\n",
    "            itemsPre = self.processItems(itemsPre, mode = \"input\")\n",
    "            itemsPost = self.processItems(itemsPost, mode = \"output\")\n",
    "            self.buildCoMatrix(itemsPre, itemsPost)\n",
    "            self.buildTrainingItems(itemsPre, itemsPost, person_id)\n",
    "            self.patients[person_id][\"itemsPre\"] = itemsPre\n",
    "            self.patients[person_id][\"itemsPost\"] = itemsPost\n",
    "        self.buildMetricsTrainingItems(trainPatients)\n",
    "        \n",
    "    def testing(self, testPatients, method, k, useVisitID = False, returnMean = True):\n",
    "        \n",
    "        def printItems():\n",
    "            print(person_id)\n",
    "            print(\"------------------------------------------------------\")\n",
    "            print(\"Input Items: \", list(map(self.findItemName, inputItems)))\n",
    "            print(\"------------------------------------------------------\")\n",
    "            print(\"Predicted Items: \", list(map(self.findItemName, rankedItems[:k])))\n",
    "            print(\"------------------------------------------------------\")\n",
    "            print(\"Actual Items: \", list(map(self.findItemName, outputItems)))\n",
    "            print(\"------------------------------------------------------\") \n",
    "        \n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        auc_list = []\n",
    "        valid_test = 0\n",
    "        print(\"testing method: {}\".format(method))\n",
    "        \n",
    "        for person_id in testPatients:\n",
    "            itemsPre, itemsPost = self.buildPatientItemPrePost(person_id, useVisitID)\n",
    "            itemsPre = self.processItems(itemsPre, mode = \"input\")\n",
    "            itemsPost = self.processItems(itemsPost, mode = \"output\")\n",
    "            \n",
    "            if itemsPre and itemsPost:\n",
    "                inputItems = list(set(itemsPre))\n",
    "                outputItems = list(set(itemsPost))\n",
    "     \n",
    "                self.patients[person_id][\"itemsPre\"] = itemsPre\n",
    "                self.patients[person_id][\"itemsPost\"] = itemsPost\n",
    "            \n",
    "                if len(outputItems) != 0 and len(inputItems)!=0:\n",
    "                    rankedItems, rankedScore = self.rankingItems(inputItems, method)\n",
    "\n",
    "                    precision, recall = self.evaluate(rankedItems, inputItems, outputItems, k)\n",
    "                    if self.inspectPredictedItems:\n",
    "                        if precision >= 0.5 and recall >= 0.5:\n",
    "                            printItems()\n",
    "                    auc = self.getAUC(rankedItems, rankedScore, outputItems)\n",
    "                    \n",
    "                    if self.isPlotRankedScore:\n",
    "                        self.plotRankedScore(rankedScore, outputItems, precision, recall)\n",
    "\n",
    "                    precision_list.append(precision)\n",
    "                    recall_list.append(recall)\n",
    "                    auc_list.append(auc)\n",
    "                    valid_test += 1\n",
    "        if valid_test > 0:\n",
    "            if returnMean:\n",
    "                return mean(precision_list), mean(recall_list), mean(auc_list)\n",
    "            else:\n",
    "                return precision_list, recall_list, auc_list\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def rankingItems(self, inputItems, method):\n",
    "        # possible candidate Items, not including the query inputItems \n",
    "        #candidateItems = np.array(list(self.candidateItems.difference(inputItems)))\n",
    "        candidateItems = np.array(list(self.candidateItems))\n",
    "        queryItems = np.array(list(self.trainingInputItems.intersection(inputItems)))\n",
    "\n",
    "        score = self.aggStats(candidateItems, queryItems, method)\n",
    "        # sort based on rankedScore\n",
    "        sortedIndex = score.argsort()[::-1]\n",
    "        rankedItems = candidateItems[sortedIndex].tolist()\n",
    "        rankedScore = score[sortedIndex].tolist()\n",
    "        return rankedItems, rankedScore\n",
    "    \n",
    "    def plotRankedScore(self, rankedScore, outputItems, precision, recall):\n",
    "        x = np.arange(0,len(rankedScore))\n",
    "        y = rankedScore\n",
    "        l = len(outputItems)\n",
    "        precision = round(precision,2)\n",
    "        recall = round(recall,2)\n",
    "        plt.plot(x,y,linewidth = 2, color = 'red')\n",
    "        plt.axvline(x = l)\n",
    "        plt.title('precision = {p} ; recall = {r}; output = {l}'.format_map({'p':precision, 'r':recall, 'l':l}))\n",
    "        plt.show()\n",
    "    \n",
    "    def aggStats(self, candidateItems, queryItems, method):\n",
    "        \n",
    "        # this apply statMetrics over queryItems\n",
    "        getStats = np.vectorize(self.statMetrics) \n",
    "                \n",
    "        def PPV(item):\n",
    "            sumStats = sum(getStats(item, queryItems, 'ppv'))\n",
    "            sumN = sum(getStats(item, queryItems, 'numA_pts'))\n",
    "            return sumStats/sumN\n",
    "        \n",
    "        def PPV_mod(item):\n",
    "            sumStats = sum(getStats(item, queryItems, 'ppv_mod'))\n",
    "            sumN = sum(getStats(item, queryItems, 'numA_pts'))\n",
    "            return sumStats/sumN\n",
    "        \n",
    "        def PPV_mod2(item):\n",
    "            sumStats = sum(getStats(item, queryItems, 'ppv_mod2'))\n",
    "            sumN = sum(getStats(item, queryItems, 'numA_pts'))\n",
    "            return sumStats/sumN\n",
    "        \n",
    "        def PPV_wt(item):\n",
    "            sumStats = sum(getStats(item, queryItems, 'ppv_wt'))\n",
    "            sumN = sum(getStats(item, queryItems, 'numA_pts'))\n",
    "            return sumStats/sumN\n",
    "        \n",
    "        def PPV_mod_wt(item):\n",
    "            sumStats = sum(getStats(item, queryItems, 'ppv_mod_wt'))\n",
    "            sumN = sum(getStats(item, queryItems, 'numA_pts'))\n",
    "            return sumStats/sumN\n",
    "        \n",
    "        def PPV_mod2_wt(item):\n",
    "            sumStats = sum(getStats(item, queryItems, 'ppv_mod2_wt'))\n",
    "            sumN = sum(getStats(item, queryItems, 'numA_pts'))\n",
    "            return sumStats/sumN\n",
    "        \n",
    "        def RR(item):\n",
    "            prodStats = np.prod(getStats(item, queryItems, 'rr'))\n",
    "            return prodStats\n",
    "        \n",
    "        def Fisher(item):\n",
    "            sumStats = sum(getStats(item, queryItems, 'fisher_neglog'))\n",
    "            return sumStats \n",
    "        \n",
    "        def Prevalence(item):\n",
    "            #return self.trainingItems[item][\"prevalence\"]\n",
    "            return self.items[item][\"prevalence\"]\n",
    "        \n",
    "        def BaselinePrevalence(item):\n",
    "            return self.items[item][\"baselinePrevalence\"]\n",
    "        \n",
    "        def Random(item):\n",
    "            return np.random.random_sample()\n",
    "                      \n",
    "       \n",
    "        switcher = {                   \n",
    "                    'PPV':PPV,\n",
    "                    'PPV_WT':PPV_wt,\n",
    "                    'PPV_MOD':PPV_mod,\n",
    "                    'PPV_MOD_WT':PPV_mod_wt,\n",
    "                    'PPV_MOD2':PPV_mod2,\n",
    "                    'PPV_MOD2_WT':PPV_mod2_wt,\n",
    "                    'RR':RR,\n",
    "                    'FISHER': Fisher,\n",
    "                    'PREVALENCE':Prevalence,\n",
    "                    'BASELINEPREVALENCE':BaselinePrevalence,\n",
    "                    'RANDOM':Random\n",
    "                    }\n",
    "    \n",
    "        applyMethod = switcher.get(method.upper())          \n",
    "        score = np.vectorize(applyMethod)(candidateItems)\n",
    "        return score       \n",
    "        \n",
    "    def statMetrics(self, itemB, itemA, metric):\n",
    "        # item B is the candidate item\n",
    "        # item A is the query item\n",
    "        AB_pts = self.coMatrix[itemA][itemB]\n",
    "        A_pts = len(self.trainingItems[itemA][\"patients\"])\n",
    "        B_pts = len(self.trainingItems[itemB][\"patients\"])\n",
    "\n",
    "        N = len(self.trainPatients)\n",
    "        contingencyTable = [[AB_pts, A_pts - AB_pts],\n",
    "              [B_pts - AB_pts, N - A_pts - B_pts + AB_pts]]\n",
    "        \n",
    "        def modifier(itemA, itemB):\n",
    "            modifierA = 1;\n",
    "            modifierB = 1;\n",
    "            itemA_category = self.items[itemA]['category']\n",
    "            itemA_category = str.replace(itemA_category,'derived_','')\n",
    "            itemB_category = self.items[itemB]['category']\n",
    "            itemB_category = str.replace(itemB_category,'derived_','')\n",
    "            \n",
    "            if itemA_category in self.inputFeatures:\n",
    "                neglogP, rr = self.getRR_Item(itemA, mode = 'input')\n",
    "                modifierA = rr\n",
    "            return modifierA, modifierB\n",
    "        \n",
    "        modifierA,modifierB = modifier(itemA, itemB)\n",
    "        \n",
    "        def numA_pts():\n",
    "            return A_pts\n",
    "        def prevalence():\n",
    "            return B_pts/N\n",
    "        def PPV():\n",
    "            return AB_pts\n",
    "        def PPV_wt():\n",
    "            return AB_pts/A_pts\n",
    "        def PPV_mod():\n",
    "            return modifierA * AB_pts \n",
    "        def PPV_mod_wt():\n",
    "            return (modifierA * AB_pts) / A_pts\n",
    "        def PPV_mod2():\n",
    "            return (modifierA**2) * AB_pts\n",
    "        def PPV_mod2_wt():\n",
    "            return ((modifierA**2) * AB_pts) / A_pts \n",
    "        def RR():\n",
    "            if B_pts == AB_pts:\n",
    "                adj = 1\n",
    "            else:\n",
    "                adj = 0\n",
    "            return (AB_pts/A_pts) / ((B_pts - AB_pts + adj)/(N - A_pts + adj))\n",
    "        \n",
    "        def Fisher_NegLog():\n",
    "            try:\n",
    "                (oddsRatio, fisherP) = stats.fisher_exact(contingencyTable)\n",
    "                logP = -sys.float_info.max\n",
    "                if fisherP > 0.0:\n",
    "                    logP = math.log(fisherP,10)\n",
    "\n",
    "                if oddsRatio > 1.0:\n",
    "                    return -logP\n",
    "                else:\n",
    "                    return logP\n",
    "            except ValueError as exc:\n",
    "                # Likely from negative table values.  Return default / uncertain value\n",
    "                return 0.0\n",
    "   \n",
    "        switcher = {\n",
    "                'numA_pts': numA_pts,\n",
    "                'prevalence': prevalence,\n",
    "                'ppv': PPV,\n",
    "                'ppv_wt':PPV_wt,\n",
    "                'ppv_mod': PPV_mod,\n",
    "                'ppv_mod_wt':PPV_mod_wt,\n",
    "                'ppv_mod2': PPV_mod2,\n",
    "                'ppv_mod2_wt': PPV_mod2_wt,\n",
    "                'rr': RR,\n",
    "                'fisher_neglog': Fisher_NegLog\n",
    "                }\n",
    "    \n",
    "        func = switcher.get(metric, lambda: 'invalid')    \n",
    "        \n",
    "        return func()\n",
    "\n",
    "    def evaluate(self, rankedItems, inputItems, outputItems, k):\n",
    "        # return precision and recall\n",
    "        classPos = len(outputItems)\n",
    "        classNeg = len(rankedItems) - len(outputItems) \n",
    "        predictPos = k \n",
    "        predictNeg = len(rankedItems) - k\n",
    "        TruePos = 0\n",
    "        FalsePos = 0\n",
    "        \n",
    "        for item in rankedItems[:k]:\n",
    "            if item in outputItems:        \n",
    "                TruePos += 1 \n",
    "            else:\n",
    "                FalsePos += 1\n",
    "            \n",
    "        FalseNeg = classPos - TruePos\n",
    "        TrueNeg = classNeg - FalsePos\n",
    "        \n",
    "        precision = TruePos / predictPos \n",
    "        recall = TruePos / classPos\n",
    "        \n",
    "        return precision, recall\n",
    "        \n",
    "    def getAUC(self, rankedItems, rankedScore, outputItems):\n",
    "        addLabel = lambda x: 1 if x in outputItems else 0\n",
    "        itemLabel = list(map(addLabel, rankedItems))\n",
    "        if sum(itemLabel) > 0:\n",
    "            auc = roc_auc_score(itemLabel, rankedScore)\n",
    "            self.valid_AUC_count += 1\n",
    "        else:\n",
    "            auc = 0.5\n",
    "            self.invalid_AUC_count += 1\n",
    "        return auc\n",
    "    \n",
    "    def findItemName(self, itemID, nameOnly = True):\n",
    "        category = self.items[itemID][\"category\"]\n",
    "        conceptID = self.items[itemID][\"ID\"]\n",
    "        # itemCode and itemID should be the same\n",
    "        (itemCode, itemName) = self.feature_dict[category][conceptID]\n",
    "        if nameOnly:\n",
    "            return itemName\n",
    "        else:\n",
    "            return (conceptID, itemName)\n",
    "        \n",
    "\n",
    "# def main():\n",
    "\n",
    "# if __name__== \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"show patient instances at primary care or specialty visits \"\"\"\n",
    "def showInstancePerPatient(testR, person_id, instanceType = 'Pre'):\n",
    "    if instanceType == 'Pre':\n",
    "        instanceList = testR.patients[person_id]['instancePre']\n",
    "    else:\n",
    "        instanceList = testR.patients[person_id]['instancePost']\n",
    "             \n",
    "    DF = testR.instanceDF.loc[instanceList, ['item','item_derived','item_datetime','visit_id','item_value']]\n",
    "    DF['name'] = DF['item'].apply(testR.findItemName)\n",
    "    DF['category'] = DF['item'].apply(lambda x:testR.items[x]['category'])\n",
    "    DF['filter'] = DF['item'].apply(lambda x:testR.items[x]['filter'])\n",
    "    DF['rare'] = DF['item'].apply(lambda x:testR.items[x]['rare'])\n",
    "    DF['date'] = DF['item_datetime'].apply(datetime.datetime.date) \n",
    "    DF = DF.sort_values(by=['item','item_value'])\n",
    "    DF = DF.drop_duplicates(subset=['item'],keep='first')\n",
    "    DF = DF[(DF['filter'] == False) & (DF['rare'] == False)]\n",
    "    DF = DF.sort_values(by=['item'])\n",
    "    DF = DF[['date','name','item_value','category']]\n",
    "    return DF\n",
    "\n",
    "# DF = showInstancePerPatient(testR2, 31552010, 'Pre')\n",
    "# DF[DF['category'] == 'measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of top RR in training input items:\n",
    "\n",
    "\n",
    "def showItemRR(testR):\n",
    "    item_list = []\n",
    "    for i in testR.trainingInputItems:\n",
    "        if testR.items[i]['category'] in testR.inputFeatures:\n",
    "            neglogP, RR = testR.getRR_Item(i, mode = 'input')\n",
    "            item_list.append([i, testR.findItemName(i), RR, neglogP])\n",
    "    df = pd.DataFrame(item_list)\n",
    "    df.columns = [\"item\",'name','RR','neglogP']\n",
    "    df = df.sort_values(by = ['RR'], ascending = False)\n",
    "    return df\n",
    "\n",
    "df = showItemRR(testR2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"main functions\"\"\"\n",
    "def trainSplit(patient_dict, train_pct = 0.8): \n",
    "    personIDs = list(patient_dict.keys())\n",
    "    trainSize = round(len(personIDs) * train_pct)\n",
    "    shuffleIDs = random.sample(personIDs, len(personIDs))\n",
    "    trainPatients = shuffleIDs[:trainSize]\n",
    "    testPatients = shuffleIDs[trainSize:]\n",
    "    return trainPatients, testPatients \n",
    "\n",
    "def trainSplitbyYear(patient_dict):\n",
    "    trainPatients = []\n",
    "    testPatients = []\n",
    "    for personID, value in patient_dict.items():\n",
    "        if value['primaryVisitTime'].year >= 2019:\n",
    "            testPatients.append(personID) \n",
    "        else:\n",
    "            trainPatients.append(personID)\n",
    "    return trainPatients, testPatients\n",
    "    \n",
    "    \n",
    "def comparePrecisionRecall(recommenderInstance, testPatients, steps):\n",
    "    ri = recommenderInstance\n",
    "    methodChoice = ['PPV_mod2_wt','PPV','Prevalence','BaselinePrevalence','Random']\n",
    "    labels = ['PPV_weighted','PPV','Endocrine_Prevalence','Outpatient_Prevalence','Random']\n",
    "    colorChoice = ['orange','lightgreen','skyblue','pink','lightgrey']\n",
    "    plotChoice = list(zip(methodChoice, colorChoice))\n",
    "    \n",
    "    def plotPrecisionRecall(method, linecolor):\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        for k in range(1,120,steps):\n",
    "            print('k = ',k)\n",
    "            precision, recall, auc = ri.testing(testPatients, method, k)\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "        plt.plot(recall_list, precision_list, color = linecolor, linestyle = ':', linewidth = 4)\n",
    "  \n",
    "    for method, color in plotChoice:\n",
    "        plotPrecisionRecall(method, color)\n",
    "    \n",
    "    plt.legend(labels)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve at various k')\n",
    "    plt.xlim([0.15, 1.0])\n",
    "    plt.ylim([0.0, 0.8])\n",
    "    plt.show()\n",
    "\n",
    "def topOrdersPrevalence(recommenderInstance):\n",
    "    RI = recommenderInstance\n",
    "    DF = pd.DataFrame.from_dict(RI.trainingItems, orient = 'index')\n",
    "    DF = DF.sort_values(by = [\"prevalence\"],ascending=False)\n",
    "    DF[\"patients\"] = DF[\"patients\"].map(lambda x:len(x))\n",
    "    DF[\"name\"] = DF.index.map(lambda x:testRecommender.findItemName(x))\n",
    "    DF = DF.reset_index()\n",
    "    DF = DF[[\"name\",\"instance_count\",\"patients\",\"prevalence\",\"baselinefreq\"]]\n",
    "    return DF\n",
    "    \n",
    "\n",
    "def showDescriptiveStats(recommenderInstance):\n",
    "    ri = recommenderInstance\n",
    "    print(\"------------Data overview -------------\")\n",
    "    print(\"Patients: \", len(ri.patients))\n",
    "    print(\"Instances : \", ri.instance_count)\n",
    "    print(\"Items: \", ri.item_count) \n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"Training patients: \", len(ri.trainPatients))\n",
    "    print(\"Training items: \", len(ri.trainingItems))\n",
    "    print(\"Candidate items: \", len(ri.candidateItems))\n",
    "    print(\"---------------------------------------\")        \n",
    "    def countItems():\n",
    "        InputItems = []\n",
    "        OutputItems = []\n",
    "        for p in ri.patients.values():\n",
    "            if \"itemsPre\" in p:\n",
    "                InputItems.append(len(set(p[\"itemsPre\"])))\n",
    "            if \"itemsPost\" in p:\n",
    "                OutputItems.append(len(set(p[\"itemsPost\"])))\n",
    "        return InputItems, OutputItems\n",
    "    InputItems, OutputItems = countItems()\n",
    "    print(\"Avg number of query items: \", np.mean(InputItems))\n",
    "    print(\"Median number of query items: \", np.median(InputItems))\n",
    "    print(\"Avg number of output items: \", np.mean(OutputItems))\n",
    "    print(\"Median number of output items: \", np.median(OutputItems))\n",
    "    plt.hist(OutputItems, bins= 'auto')\n",
    "    plt.show()\n",
    "    \n",
    "def topItemsGivenQuery(recommenderInstance, queryItems, n=20, method = 'PPV_mod2_wt'):\n",
    "    \n",
    "    col = [\"PPV\",\"RR\",\"Prevalence\",\"Baseline_Prevalence\",\"Fisher\"]\n",
    "    RI = recommenderInstance\n",
    "    queryItemNames = list(map(RI.findItemName, queryItems))\n",
    "    print(\"clinical items for query: {}\".format(queryItemNames))\n",
    "    \n",
    "    rankedItems, rankScore = RI.rankingItems(set(queryItems), method)\n",
    "    \n",
    "    if n+10 <= len(RI.candidateItems):\n",
    "           k = n + 10\n",
    "    else:\n",
    "           k = n \n",
    "            \n",
    "    df = pd.DataFrame(rankedItems[:k], columns=[\"Item\"])\n",
    "    df[\"Name\"] = df[\"Item\"].map(RI.findItemName)\n",
    "    \n",
    "    formatFunc1 = lambda x:round(x*100,1)\n",
    "    formatFunc2 = lambda x:round(x,1)\n",
    "    formatFunc3 = lambda x:format(10**(-x),'.2e')\n",
    "    \n",
    "    methodMap = {'ppv': ('ppv', formatFunc1),\n",
    "                 'rr': ('RR',formatFunc2),\n",
    "                 'prevalence':('prevalence',formatFunc2),\n",
    "                 'baseline_prevalence':('baselineprevalence',formatFunc2),\n",
    "                 'conditional_freq':('conditionalfreq',formatFunc2),\n",
    "                 'fisher':('fisher',formatFunc3)}\n",
    "    \n",
    "    for c in col:\n",
    "        df[c] = df[\"Item\"].apply(RI.aggStats, args = (queryItems, methodMap[c.lower()][0]))\n",
    "    \n",
    "    \n",
    "    # format/rounding\n",
    "    for c in col:\n",
    "        df[c] = df[c].apply(methodMap[c.lower()][1])\n",
    "    \n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot to compare different recommender method\n",
    "def CompareRecommender(recommenderInstanceList, recommenderInstanceName, testPatients, \n",
    "                        plotlist = ['auc','precision','recall'],\n",
    "                        #methodChoice = ['PPV_mod2_wt','PPV','Prevalence','BaselinePrevalence','Random'],\n",
    "                        #labels = ['PPV_weighted','PPV','Endocrine_Prevalence','Outpatient_Prevalence','Random']):\n",
    "                        methodChoice = ['PPV_mod2_wt','PPV_mod2','PPV_mod_wt','PPV_mod','PPV_wt','PPV','Prevalence','BaselinePrevalence','Random'],\n",
    "                        labels = ['PPV_mod2_wt','PPV_mod2','PPV_mod_wt','PPV_mod','PPV_wt','PPV','Endocrine_Prevalence','Outpatient_Prevalence','Random']):\n",
    "    \n",
    "    # Set the colors\n",
    "    colors = ['red','orange','blue','lightblue','green','lightgreen','skyblue','pink','lightgrey']\n",
    "    \n",
    "    def autolabel(bars, margin):\n",
    "        # attach some text labels\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + margin, bar.get_y() + bar.get_height()/2,\n",
    "                    '{:.2f}'.format(width),\n",
    "                    ha='right', va='center')\n",
    "    \n",
    "    # construct DF to store result of different methods as rows, different recommender instance as columns)\n",
    "    precisionDF = pd.DataFrame(columns=recommenderInstanceName, index = methodChoice)\n",
    "    recallDF = pd.DataFrame(columns=recommenderInstanceName, index = methodChoice)\n",
    "    aucDF = pd.DataFrame(columns=recommenderInstanceName, index = methodChoice)\n",
    "    \n",
    "    for i, ri in enumerate(recommenderInstanceList):        \n",
    "        k = ri.k\n",
    "        name = recommenderInstanceName[i]\n",
    "        \n",
    "        for method in methodChoice:\n",
    "            precision, recall, auc = ri.testing(testPatients, method, k, returnMean = False)\n",
    "            f = lambda x:x*100            \n",
    "            precisionDF.loc[method, name] = list(map(f,precision))\n",
    "            recallDF.loc[method, name] = list(map(f,recall))\n",
    "            aucDF.loc[method, name] = auc\n",
    "            \n",
    "#         \"\"\"paired t-test\"\"\"\n",
    "#         for m, method in enumerate(methodChoice):\n",
    "#             if m == 0:\n",
    "#                 ref_precision = precisionDF.loc[method, name]\n",
    "#                 ref_recall = recallDF.loc[method, name]\n",
    "#                 ref_auc = aucDF.loc[method, name]\n",
    "#             else:\n",
    "#                 print(\"paired t-test for \",methodChoice[0], \" and \", method, \" :\")\n",
    "#                 t_precision, pval_precision = stats.ttest_rel(ref_precision, precisionDF.loc[method, name])\n",
    "#                 t_recall, pval_recall = stats.ttest_rel(ref_recall, recallDF.loc[method, name])\n",
    "#                 t_auc, pval_auc = stats.ttest_rel(ref_auc, aucDF.loc[method, name])\n",
    "#                 print(\"precision: \", t_precision, pval_precision)\n",
    "#                 print(\"recall: \", t_recall,  pval_recall)\n",
    "#                 print(\"auc: \", t_auc, pval_auc)\n",
    "#                 print(\"-----------------------------------------------\")\n",
    "    \n",
    "\n",
    "    resultDict = {'auc':aucDF.applymap(mean),\n",
    "                  'precision': precisionDF.applymap(mean),\n",
    "                  'recall': recallDF.applymap(mean)}\n",
    "    \n",
    "    xlimDict = {'auc':[0.5, 1.0],\n",
    "                'precision':[0,50],\n",
    "                'recall':[0,50]}\n",
    "                          \n",
    "    formatDict = {'auc':'{:.2f}',\n",
    "                  'precision':'{:.2f}%',\n",
    "                  'recall':'{:.2f}%'}    \n",
    "    \n",
    "    for pl in plotlist:\n",
    "        resultDF = resultDict[pl]\n",
    "        ind = np.arange(resultDF.shape[0])\n",
    "\n",
    "        # make the plots\n",
    "        fig, ax = plt.subplots()\n",
    "        bars = ax.barh(ind, resultDF[name], color = colors) # plot a vals\n",
    "        ax.set_yticks(ind)  # position axis ticks\n",
    "        ax.set_yticklabels(labels)  # set them to the names\n",
    "\n",
    "        if pl == 'auc':\n",
    "            plt.title('Different Recommender Ranking Methods')\n",
    "            margin = 0.04\n",
    "        else:\n",
    "            plt.title('Different Recommender Ranking Methods (k = {})'.format(k))\n",
    "            margin = 4\n",
    "        plt.xlabel(pl)\n",
    "        plt.xlim(xlimDict[pl])  \n",
    "        autolabel(bars, margin)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossVal(recommenderInstance, Patients, methodChoice, fold):\n",
    "    Patients = np.asarray(Patients)\n",
    "    ri = recommenderInstance\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=fold, random_state=None, shuffle=True)\n",
    "    \n",
    "    resultDF = pd.DataFrame(index = ['precision','recall','auc'], columns=methodChoice)\n",
    "    resultDF = resultDF.applymap(lambda x:[])\n",
    "    \n",
    "    for train_index, test_index in kf.split(Patients): \n",
    "        ri.training(list(Patients[train_index]))\n",
    "        for method in methodChoice:\n",
    "            precision, recall, auc = ri.testing(list(Patients[test_index]), method, k=5, returnMean = True)\n",
    "            resultDF.loc['precision', method].append(precision*100)\n",
    "            resultDF.loc['recall', method].append(recall*100) \n",
    "            resultDF.loc['auc', method].append(auc)\n",
    "    \n",
    "    resultDF = resultDF.applymap(lambda x:mean(x))\n",
    "    return resultDF\n",
    "\n",
    "testR = Recommender()\n",
    "testR.inputFeatures = {'measurement','procedure','condition','drug'}\n",
    "testR.preProcessing(count_cutoff = 10)\n",
    "testR.inspectPredictedItems = False\n",
    "trainPatients, testPatients = trainSplitbyYear(testR.patients)\n",
    "methodChoice = ['PPV_mod2_wt','PPV_mod2','PPV_mod_wt','PPV_mod','PPV_wt','PPV','Prevalence','BaselinePrevalence','Random']\n",
    "resultDF = CrossVal(testR, trainPatients, methodChoice, fold = 5)\n",
    "resultDF.columns = [['PPV (RR^2/N)','PPV (RR^2)','PPV (RR/N)','PPV (RR)',\n",
    "                     'PPV (1/N)','PPV','Endocrine_Prevalence','Outpatient_Prevalence','Random']]\n",
    "resultDF.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDF.columns = [['PPV (RR^2/N)','PPV (RR^2)','PPV (RR/N)','PPV (RR)',\n",
    "                     'PPV (1/N)','PPV','Endocrine_Prevalence','Outpatient_Prevalence','Random']]\n",
    "resultDF.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
