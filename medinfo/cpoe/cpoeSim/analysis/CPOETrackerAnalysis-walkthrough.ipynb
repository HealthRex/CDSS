{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and environment setup\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from CPOETrackerAnalysis import SimulationAnalyzer, aggregate_simulation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SimulationAnalyzer class is meant to be an analyitical wrapper for the JSON files created by the tracking module of the CPOE recommender simulation. It takes care of parsing through the nested elements of the JSON and computing several useful statistics on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll run through some of the exisiting functionality of the SimulationAnalyzer on a single case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data source for a single case\n",
    "data_file = 'sim_data/34_156_data_v4.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation analyzer is instantiated by providing the path to the json file containing the recorded events during the simulation of a case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Instantiate SimulationAnalyzer on source data file\n",
    "sim_analyzer = SimulationAnalyzer(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the simulation analyzer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer components:\n",
    "When instantiated with a particular data source, the simulation analyzer object will parse the data into several attributes that can be operated on to report metrics of interest. Some of these attributes are defined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User, patient, start time, and end time\n",
    "Included in the analyzer are some general attributes about the case from which the source data was derived. The `user` attribute gives the id of the user that completed the case. The `patient` attribute gives the id of the case. The `start_time` and `end_time` attributes give the absolute times when the case began (when the simulation window was opened) and when the case ended (when the simulation was saved), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = sim_analyzer.user\n",
    "patient = sim_analyzer.patient\n",
    "start_time = sim_analyzer.start_time\n",
    "end_time = sim_analyzer.end_time\n",
    "print(\"user: {}\\npatient: {}\\nstart_time: {}\\nend_time: {}\".format(user, patient, start_time, end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event tracker\n",
    "The `event_tracker_data` attribute is an object that keeps track of interactions with the simulation interface. Specifically, for the elements that have been interacted with in the interface (such as the search bar and the various search modes, any results on the page, or the notes selection), there is list of items containing the interaction timestamp as well as information about the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show event tracker data for current data source\n",
    "event_tracker_data = sim_analyzer.event_tracker_data\n",
    "event_tracker_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results tracker\n",
    "The `results_tracker_data` attribute is an object that contains the results that appeared throughout the simulation, for each search mode (results from the recommender correspond to the `''` key). The results are further grouped by the section in which they appear. Along with each section of results, there is also a state object that contains information of the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results tracker data for current data source\n",
    "results_tracker_data = sim_analyzer.results_tracker_data\n",
    "results_tracker_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signed item tracker\n",
    "The `signed_item_tracker_data` attribute is an object that contains information for clinical orders signed during the simulation. These signed items are grouped by the timestamp of when they were signed. The information is in the format `clinical_item_id|source|search_query|search_mode|list_index`. These attributes are defined below:\n",
    "\n",
    "|Attribute|Description|\n",
    "|---------|:-----------|\n",
    "|clinical_item_id|The database id associated with the signed item|\n",
    "|source|The result source from wich the item was selected - _'resultSpace1' or 'resultSpace2' for recommender items, 'non-recommender' otherwise_|\n",
    "|search_query|The query used that generated the signed item - _empty for recommender items_|\n",
    "|search_mode|What type of search was used with the query (Find Orders, Order Sets, Diagnoses) - _empty for recommender items_|\n",
    "|list_index|The index of the list that contained the signed item|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show signed item tracker data for current data source\n",
    "signed_item_tracker_data = sim_analyzer.signed_item_tracker_data\n",
    "signed_item_tracker_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results and sgined orders collections\n",
    "To simplify certain operations on the data collected, the hierarchical `results_tracker_data` and `signed_item_tracker_data` have been flattened into the collections `results_collection` and `signed_orders_collection`, respectively. These collections represent each item as an item dictionary containing the item's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results collection for current data source\n",
    "results_collection = sim_analyzer.results_collection\n",
    "results_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show signed orders collection for current data source\n",
    "signed_orders_collection = sim_analyzer.signed_orders_collection\n",
    "signed_orders_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Metrics:\n",
    "Below are a few implemented summary metrics that make use of the attributes discussed above. For details on how these are implemented, please refer to the source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elapsed Time\n",
    "One of the first things we might be interested in about a user's behavior is the amount of time they spend on a particular case. This metric is retrieved as follows and is presented in the form __hours:minutes:seconds__. Note that this elapsed time does not filter out idle time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve elapsed time from the base data\n",
    "elapsed_time = sim_analyzer.elapsed_time()\n",
    "elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mouse clicks\n",
    "There are several ways to retrieve information about mouse clicks during the simulation. The first is to retrieve all the clicks made during the duration of the simulation through `number_mouse_clicks_all()`. The second is to retrieve the number of mouse clicks over certain buttons and inputs on the simulation page through `number_mouse_clicks()`. And the final way is to retrieve a dict summary of clicks through `click_summary()` , where the key of the dict is the event and the value is the number of clicks. Note that the latter two of these methods have an option to return the frequency of clicks as a percentage of all clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve number of total mouse clicks made:\n",
    "clicks_all = sim_analyzer.number_mouse_clicks_all()\n",
    "\n",
    "# Retrieve number of mouse clicks made over the Results and Results Review sections:\n",
    "clicks_notes_results = sim_analyzer.number_mouse_clicks(filters=['ResultInteraction', 'ResultsReview'], perc=True)\n",
    "\n",
    "# Retrieve dict of mouse click summary\n",
    "click_summary = sim_analyzer.click_summary(perc=False)\n",
    "\n",
    "print(\"Total number of clicks: {}\".format(clicks_all))\n",
    "print(\"Percent of clicks over Results and Results Review sections: {}\".format(clicks_notes_results))\n",
    "print(\"Mouse click summary:\\n {}\".format(click_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Metrics:\n",
    "There are also several implemented metrics for result items and signed items that use the attributes discussed above and other helpful utilities. Again, for more details about the implementations, please refer to the source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "There exists utility functions for retrieving the item options that appeared from manual searches and those that appeared from the recommender. These functions can be used to retreive the number of items from both sources, as well as for doing any other specific operations on the collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get item options that were results from a manual search\n",
    "manually_search_options = sim_analyzer.get_manually_searched_options()\n",
    "print(\"Number of manually searched options: {}\\nManually searched options: {}\".format(len(manually_search_options), manually_search_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get item options that were results from recommender\n",
    "recommended_options = sim_analyzer.get_recommended_options()\n",
    "print(\"Number of recommended options: {}\\nRecommended options: {}\".format(len(recommended_options), recommended_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since identical items may appear multiple times throughout searches, or by the recommender,\n",
    "# it may be useful to only retreive unique options. This can be done by definining a uniqueness\n",
    "# comparison function and applying it with the `get_unique` helper method.\n",
    "def clinical_item_id_key_fn(item):\n",
    "    \"\"\"Returns clinical item value from item object\"\"\"\n",
    "    return item['clinicalItemId']\n",
    "\n",
    "unique_results = sim_analyzer.get_unique(sim_analyzer.results_collection, key_fn=clinical_item_id_key_fn)\n",
    "print(\"Number of unique results: {}\\nUnique results: {}\".format(len(unique_results), unique_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signed orders\n",
    "Similar to results, there exists utility functions for retrieving signed items that appeared from manual searches or from the recommender. These functions are useful for metrics evaluating how the recommender influences the order behavior of users. These functions can be used to retreive the number of items from both sources, as well as for doing any other specific operations on the collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get signed items that appeared from manual searches\n",
    "signed_from_manual_search = sim_analyzer.get_signed_from_manual_search()\n",
    "print(\"Number signed from manual searches: {}\\nItems signed from manual searches: {}\".format(len(signed_from_manual_search), signed_from_manual_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get signed items that appeared from the recommender\n",
    "signed_from_recommender = sim_analyzer.get_signed_from_recommended()\n",
    "print(\"Number signed from recommender: {}\\nItems signed from recommender: {}\".format(len(signed_from_recommender), signed_from_recommender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One metric that is interesting to see is the orders that appeared from the recommender\n",
    "# but were ultimately signed during a manual search. These signed items are essentially those\n",
    "# that were 'missed' by the user.\n",
    "signed_missed = sim_analyzer.get_signed_missed_recommended()\n",
    "print(\"Number signed that were originally missed: {}\\nSigned items that were originally missed: {}\".format(len(signed_missed), signed_missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation\n",
    "There are several ways of aggregating the data captured by the simulation analyzer object, whether it be for visualization purposes or for constructing data reports on multiple data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeline\n",
    "One visualization that is useful is a timeline of events. This visualization allows us to note any clusters(or lack of clusters) of behaviour during the simulation. To visualize the timeline, we first construct the collection of sorted events using `construct_timeline()`. We can then pass this collection of events into the `visualize_timeline()` method as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort events by their timestamp\n",
    "sorted_events = sim_analyzer.construct_timeline()\n",
    "\n",
    "# Visualize timeline\n",
    "sim_analyzer.visualize_timeline(sorted_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data dump\n",
    "Although not part of the SimulationAnalyzer class, there exists functionality in `CPOETrackerAnalysis.py` for running an analyzer instance on a set of json-stored data sources and creating (or appending to an existing) csv of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flat CSV from data\n",
    "out_file = 'sim_data/out.csv'\n",
    "data_home = 'sim_data'\n",
    "aggregate_simulation_data(data_home, output_path=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show csv\n",
    "csv = pd.read_csv('sim_data/out.csv')\n",
    "display(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "Below are a few implementation exercises to test your understanding of the different components of the `SimulationAnalyzer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SimulationAnalyzer on source data file\n",
    "sim_analyzer = SimulationAnalyzer('sim_data/48_244_data_v4.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "One of the things we want to track for a simulation case is whether a user ordered appropriate items. These items must also be ordered in a particular sequence (i.e. ordering antibiotics before a particular lab test could interfere with the results of the lab test). For this exercise, we will write a function that validates the 'correctness' of a case, according to a reference sequence of orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the function below according to the docstring\n",
    "def case_orders_valid(sim_analyzer, expected_orders):\n",
    "    \"\"\" Validate that the case represented by sim_analyzer adheres to the expected sequence of orders.\n",
    "    \n",
    "    Args:\n",
    "        sim_analyzer (SimulationAnalyzer): The SimulationAnalyzer instance representing the case being validated\n",
    "        expected_orders (list): List of clinical id strings representing the expected sequence of orders. \n",
    "        This means that the clinical item expected_orders[i] should have been ordered before clinical items \n",
    "        expected_orders[j] for j > i.\n",
    "    \"\"\"\n",
    "    is_valid = False\n",
    "    # ****** START YOUR IMPLEMENTATION HERE ******\n",
    "    \n",
    "    # ****** END YOUR IMPLEMENTATION HERE ******\n",
    "    return is_valid\n",
    "\n",
    "expected_orders = ['45771', '45838', '45866', '45818']\n",
    "case_orders_valid(sim_analyzer, expected_orders)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
